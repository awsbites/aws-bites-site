{
  "speakers": {
    "spk_0": "spk_0",
    "spk_1": "spk_1"
  },
  "segments": [
    {
      "speakerLabel": "spk_0",
      "start": 0,
      "end": 2.8000000000000003,
      "text": " The hype around generative AI is dying down now,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 2.8000000000000003,
      "end": 5.8,
      "text": " but we are beginning to see a growing ecosystem"
    },
    {
      "speakerLabel": "spk_0",
      "start": 5.8,
      "end": 8.72,
      "text": " and lots of real-world use cases for the technology."
    },
    {
      "speakerLabel": "spk_0",
      "start": 8.72,
      "end": 10.88,
      "text": " We've just built some features using Amazon Bedrock"
    },
    {
      "speakerLabel": "spk_0",
      "start": 10.88,
      "end": 12.64,
      "text": " that help us to produce this podcast"
    },
    {
      "speakerLabel": "spk_0",
      "start": 12.64,
      "end": 14.4,
      "text": " and save some manual effort."
    },
    {
      "speakerLabel": "spk_0",
      "start": 14.4,
      "end": 15.68,
      "text": " So today we're going to talk about"
    },
    {
      "speakerLabel": "spk_0",
      "start": 15.68,
      "end": 18,
      "text": " how we automate the process with Bedrock,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 18,
      "end": 20.6,
      "text": " and we'll give you an overview of Bedrock's features."
    },
    {
      "speakerLabel": "spk_0",
      "start": 20.6,
      "end": 22,
      "text": " We'll also talk about how to use it"
    },
    {
      "speakerLabel": "spk_0",
      "start": 22,
      "end": 25.8,
      "text": " and share some tips and code on cost monitoring."
    },
    {
      "speakerLabel": "spk_0",
      "start": 25.8,
      "end": 27.72,
      "text": " My name is Eoin, I'm here with Luciano,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 27.88,
      "end": 31,
      "text": " and this is the latest episode of the AWS Bites podcast."
    },
    {
      "speakerLabel": "spk_0",
      "start": 39,
      "end": 41.64,
      "text": " This episode is sponsored by fourTheorem."
    },
    {
      "speakerLabel": "spk_0",
      "start": 41.64,
      "end": 43.36,
      "text": " If you're looking for somebody to accompany you"
    },
    {
      "speakerLabel": "spk_0",
      "start": 43.36,
      "end": 46.72,
      "text": " on your cloud journey and need an AWS advanced partner,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 46.72,
      "end": 48.68,
      "text": " check us out at fourtherem.com."
    },
    {
      "speakerLabel": "spk_0",
      "start": 49.92,
      "end": 52.36,
      "text": " Now, before we get started and talk about Bedrock"
    },
    {
      "speakerLabel": "spk_0",
      "start": 52.36,
      "end": 55.56,
      "text": " and how we use it, let's talk about the manual process"
    },
    {
      "speakerLabel": "spk_0",
      "start": 55.6,
      "end": 58.56,
      "text": " or semiannual process we did before Luciano."
    },
    {
      "speakerLabel": "spk_0",
      "start": 58.56,
      "end": 61.28,
      "text": " What was the drudge work we wanted to remove?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 61.28,
      "end": 65.04,
      "text": " Yes, so we are talking about the work that is involved"
    },
    {
      "speakerLabel": "spk_1",
      "start": 65.04,
      "end": 67.24000000000001,
      "text": " when you create, in this case, a podcast,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 67.24000000000001,
      "end": 69.2,
      "text": " but I think it applies to any video"
    },
    {
      "speakerLabel": "spk_1",
      "start": 69.2,
      "end": 70.96000000000001,
      "text": " that you want to publish on YouTube."
    },
    {
      "speakerLabel": "spk_1",
      "start": 70.96000000000001,
      "end": 73.64,
      "text": " So you create this video and when you upload it,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 73.64,
      "end": 75.92,
      "text": " you need to provide a bunch of additional information,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 75.92,
      "end": 78.76,
      "text": " effectively metadata that makes your content"
    },
    {
      "speakerLabel": "spk_1",
      "start": 78.76,
      "end": 81,
      "text": " more discoverable and provides all the necessary"
    },
    {
      "speakerLabel": "spk_1",
      "start": 81,
      "end": 83.44,
      "text": " context information to your viewers,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 83.44,
      "end": 86.84,
      "text": " but also YouTube to make the content searchable."
    },
    {
      "speakerLabel": "spk_1",
      "start": 86.84,
      "end": 90.12,
      "text": " So we are talking, of course, about descriptions, tags,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 90.12,
      "end": 93.88,
      "text": " but also other things like the chapters that you can add."
    },
    {
      "speakerLabel": "spk_1",
      "start": 93.88,
      "end": 95.64,
      "text": " You probably have seen these in our videos"
    },
    {
      "speakerLabel": "spk_1",
      "start": 95.64,
      "end": 99.2,
      "text": " or in other YouTube channels where you can add"
    },
    {
      "speakerLabel": "spk_1",
      "start": 99.2,
      "end": 101.84,
      "text": " a specific type of text that says this section,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 101.84,
      "end": 104.96,
      "text": " starting at this point, is about, I don't know, introduction."
    },
    {
      "speakerLabel": "spk_1",
      "start": 104.96,
      "end": 108.47999999999999,
      "text": " This other section is about why do we need serverless?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 108.47999999999999,
      "end": 111,
      "text": " And what happens is that YouTube is gonna use"
    },
    {
      "speakerLabel": "spk_1",
      "start": 111,
      "end": 113,
      "text": " that text information in the description"
    },
    {
      "speakerLabel": "spk_1",
      "start": 113.44,
      "end": 115.28,
      "text": " to split your video into chapters"
    },
    {
      "speakerLabel": "spk_1",
      "start": 115.28,
      "end": 118.04,
      "text": " and you will have those chapters as an easy way"
    },
    {
      "speakerLabel": "spk_1",
      "start": 118.04,
      "end": 120.36,
      "text": " of jumping through different parts of the video."
    },
    {
      "speakerLabel": "spk_1",
      "start": 120.36,
      "end": 122.2,
      "text": " So all of this information is something"
    },
    {
      "speakerLabel": "spk_1",
      "start": 122.2,
      "end": 124.24,
      "text": " we take the time to create for every single video"
    },
    {
      "speakerLabel": "spk_1",
      "start": 124.24,
      "end": 126.72,
      "text": " we upload because I think it makes them more discoverable"
    },
    {
      "speakerLabel": "spk_1",
      "start": 126.72,
      "end": 129.48,
      "text": " and it gives our viewer a better experience,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 129.48,
      "end": 131.36,
      "text": " but of course there's a lot of extra work"
    },
    {
      "speakerLabel": "spk_1",
      "start": 131.36,
      "end": 133.44,
      "text": " that we have to do for every single episode."
    },
    {
      "speakerLabel": "spk_1",
      "start": 133.44,
      "end": 135.44,
      "text": " And the process that we have been doing so far"
    },
    {
      "speakerLabel": "spk_1",
      "start": 135.44,
      "end": 139.04,
      "text": " before the feature that we are gonna be talking about today"
    },
    {
      "speakerLabel": "spk_1",
      "start": 139.04,
      "end": 140.36,
      "text": " more or less looks like this."
    },
    {
      "speakerLabel": "spk_1",
      "start": 140.4,
      "end": 143.56,
      "text": " So we have already some automation,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 143.56,
      "end": 144.72000000000003,
      "text": " which is called PodWhisperer."
    },
    {
      "speakerLabel": "spk_1",
      "start": 144.72000000000003,
      "end": 146.48000000000002,
      "text": " We talked about that before and we'll link"
    },
    {
      "speakerLabel": "spk_1",
      "start": 146.48000000000002,
      "end": 148.76000000000002,
      "text": " to the previous episode talking about that."
    },
    {
      "speakerLabel": "spk_1",
      "start": 148.76000000000002,
      "end": 151.4,
      "text": " And PodWhisperer, in short, what it does is able"
    },
    {
      "speakerLabel": "spk_1",
      "start": 151.4,
      "end": 154.72000000000003,
      "text": " to extract a transcript of everything we said"
    },
    {
      "speakerLabel": "spk_1",
      "start": 154.72000000000003,
      "end": 156.36,
      "text": " during a specific episode."
    },
    {
      "speakerLabel": "spk_1",
      "start": 156.36,
      "end": 158.4,
      "text": " And that information is something we can use"
    },
    {
      "speakerLabel": "spk_1",
      "start": 158.4,
      "end": 159.36,
      "text": " in different ways."
    },
    {
      "speakerLabel": "spk_1",
      "start": 159.36,
      "end": 164,
      "text": " So all of that stuff is done through a step function."
    },
    {
      "speakerLabel": "spk_1",
      "start": 164,
      "end": 166.16000000000003,
      "text": " And again, you can check out that video."
    },
    {
      "speakerLabel": "spk_1",
      "start": 166.16000000000003,
      "end": 168,
      "text": " We'll give you some other details later."
    },
    {
      "speakerLabel": "spk_1",
      "start": 168,
      "end": 170.8,
      "text": " But other than that, the other piece of information we have"
    },
    {
      "speakerLabel": "spk_1",
      "start": 170.8,
      "end": 173.44,
      "text": " is our notes that we keep in Notion."
    },
    {
      "speakerLabel": "spk_1",
      "start": 173.44,
      "end": 176.04,
      "text": " So we have already some kind of groundwork"
    },
    {
      "speakerLabel": "spk_1",
      "start": 176.04,
      "end": 180.44,
      "text": " that we can use as every time we want to create a title"
    },
    {
      "speakerLabel": "spk_1",
      "start": 180.44,
      "end": 181.88,
      "text": " or a description or tags,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 181.88,
      "end": 183.56,
      "text": " we can look at all of this information"
    },
    {
      "speakerLabel": "spk_1",
      "start": 183.56,
      "end": 185.88,
      "text": " without having to watch the entire video again"
    },
    {
      "speakerLabel": "spk_1",
      "start": 185.88,
      "end": 187.72,
      "text": " and decide, okay, what kind of title do we need?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 187.72,
      "end": 190.12,
      "text": " What kind of description and so on."
    },
    {
      "speakerLabel": "spk_1",
      "start": 190.12,
      "end": 193.68,
      "text": " I admit that sometimes we use ChatGPT just to summarize,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 193.68,
      "end": 196.28,
      "text": " for instance, all our notes and give us maybe a draft"
    },
    {
      "speakerLabel": "spk_1",
      "start": 196.28,
      "end": 198.72,
      "text": " of the description or some ideas for titles."
    },
    {
      "speakerLabel": "spk_1",
      "start": 198.72,
      "end": 200.4,
      "text": " But then there is still a lot of manual work"
    },
    {
      "speakerLabel": "spk_1",
      "start": 200.4,
      "end": 202.76,
      "text": " in trying to adjust that result"
    },
    {
      "speakerLabel": "spk_1",
      "start": 202.76,
      "end": 205.6,
      "text": " until we are happy with the final outcome."
    },
    {
      "speakerLabel": "spk_1",
      "start": 205.6,
      "end": 208.44,
      "text": " And when it comes to creating YouTube chapters,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 208.44,
      "end": 210.64,
      "text": " it is a very manual process."
    },
    {
      "speakerLabel": "spk_1",
      "start": 210.64,
      "end": 214.16,
      "text": " What I used to do so far is I just watch the final version"
    },
    {
      "speakerLabel": "spk_1",
      "start": 214.16,
      "end": 215.8,
      "text": " of the episode at 2X,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 215.8,
      "end": 218.28,
      "text": " and then I keep track of all the points where I see,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 218.28,
      "end": 219.64,
      "text": " okay, now we are changing topic,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 219.64,
      "end": 222.04,
      "text": " and this is probably worked a dedicated chapter."
    },
    {
      "speakerLabel": "spk_1",
      "start": 222.04,
      "end": 224.84,
      "text": " So I take track of the timestamp"
    },
    {
      "speakerLabel": "spk_1",
      "start": 224.84,
      "end": 227.52,
      "text": " and I create the format that YouTube expects."
    },
    {
      "speakerLabel": "spk_1",
      "start": 227.52,
      "end": 228.96,
      "text": " So we do all of this stuff,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 228.96,
      "end": 231.04,
      "text": " and then when we upload the video on YouTube,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 231.04,
      "end": 234.4,
      "text": " we need to copy paste all of that information correctly."
    },
    {
      "speakerLabel": "spk_1",
      "start": 234.4,
      "end": 237.88,
      "text": " And some of this work, I think it's nice to do it manually"
    },
    {
      "speakerLabel": "spk_1",
      "start": 237.88,
      "end": 239.4,
      "text": " because it's good that you can add"
    },
    {
      "speakerLabel": "spk_1",
      "start": 239.4,
      "end": 241.04,
      "text": " a bit of a personal touch."
    },
    {
      "speakerLabel": "spk_1",
      "start": 241.04,
      "end": 242.84,
      "text": " And you might have seen that we are taking"
    },
    {
      "speakerLabel": "spk_1",
      "start": 242.84,
      "end": 244.92000000000002,
      "text": " a bit of creative license when it comes."
    },
    {
      "speakerLabel": "spk_1",
      "start": 244.92000000000002,
      "end": 246.52,
      "text": " I don't know, sometimes we take a style"
    },
    {
      "speakerLabel": "spk_1",
      "start": 246.52,
      "end": 249.04,
      "text": " that looks like Tesla, the scientist."
    },
    {
      "speakerLabel": "spk_1",
      "start": 249.04,
      "end": 251,
      "text": " Sometimes we think about, I don't know,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 251,
      "end": 252.6,
      "text": " let's give it a medieval touch"
    },
    {
      "speakerLabel": "spk_1",
      "start": 252.64,
      "end": 254.92,
      "text": " because maybe we are using some medieval artwork."
    },
    {
      "speakerLabel": "spk_1",
      "start": 254.92,
      "end": 256.92,
      "text": " So it is nice that you can take the kind of freedom"
    },
    {
      "speakerLabel": "spk_1",
      "start": 256.92,
      "end": 258.6,
      "text": " and make it a little bit more original."
    },
    {
      "speakerLabel": "spk_1",
      "start": 258.6,
      "end": 259.8,
      "text": " But at the same time,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 259.8,
      "end": 262.15999999999997,
      "text": " we thought that using some generative AI"
    },
    {
      "speakerLabel": "spk_1",
      "start": 262.15999999999997,
      "end": 264.96,
      "text": " can help us to do all of that work faster"
    },
    {
      "speakerLabel": "spk_1",
      "start": 264.96,
      "end": 266.76,
      "text": " and with less manual work."
    },
    {
      "speakerLabel": "spk_0",
      "start": 266.76,
      "end": 268.48,
      "text": " When Bedrock came out recently,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 268.48,
      "end": 270.24,
      "text": " this kind of was the inspiration."
    },
    {
      "speakerLabel": "spk_0",
      "start": 270.24,
      "end": 273.15999999999997,
      "text": " And especially, I'm gonna link some tutorials"
    },
    {
      "speakerLabel": "spk_0",
      "start": 273.15999999999997,
      "end": 276.71999999999997,
      "text": " in the show notes because one of the notable things"
    },
    {
      "speakerLabel": "spk_0",
      "start": 276.71999999999997,
      "end": 279.2,
      "text": " about Bedrock is that when Amazon announced it,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 279.2,
      "end": 282.4,
      "text": " they created lots of really good tutorials"
    },
    {
      "speakerLabel": "spk_0",
      "start": 283.03999999999996,
      "end": 284.12,
      "text": " and workshops and example repos,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 284.12,
      "end": 287.12,
      "text": " some of which are like really, really impressive content."
    },
    {
      "speakerLabel": "spk_0",
      "start": 287.12,
      "end": 290.47999999999996,
      "text": " I don't think I've ever seen that for a new service before."
    },
    {
      "speakerLabel": "spk_0",
      "start": 290.47999999999996,
      "end": 292.2,
      "text": " But let's first talk about Bedrock."
    },
    {
      "speakerLabel": "spk_0",
      "start": 292.2,
      "end": 294.71999999999997,
      "text": " So Bedrock is Amazon's new service"
    },
    {
      "speakerLabel": "spk_0",
      "start": 294.71999999999997,
      "end": 296.91999999999996,
      "text": " for building generative AI applications."
    },
    {
      "speakerLabel": "spk_0",
      "start": 296.91999999999996,
      "end": 299.79999999999995,
      "text": " It's quite a bit different to SageMaker"
    },
    {
      "speakerLabel": "spk_0",
      "start": 299.79999999999995,
      "end": 302.59999999999997,
      "text": " in terms of experience where SageMaker"
    },
    {
      "speakerLabel": "spk_0",
      "start": 302.59999999999997,
      "end": 304.96,
      "text": " is designed to remove some heavy lifting,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 304.96,
      "end": 307.2,
      "text": " but you still have to understand about containers"
    },
    {
      "speakerLabel": "spk_0",
      "start": 307.2,
      "end": 311.23999999999995,
      "text": " and models and the model libraries like PyTorch, et cetera."
    },
    {
      "speakerLabel": "spk_0",
      "start": 311.24,
      "end": 314.52,
      "text": " With Bedrock, it's a lot more managed high level service."
    },
    {
      "speakerLabel": "spk_0",
      "start": 314.52,
      "end": 317.28000000000003,
      "text": " And the idea of Bedrock is that it gives you access"
    },
    {
      "speakerLabel": "spk_0",
      "start": 317.28000000000003,
      "end": 320.04,
      "text": " to third party foundation models"
    },
    {
      "speakerLabel": "spk_0",
      "start": 320.04,
      "end": 323.04,
      "text": " from lots of different companies through a single API."
    },
    {
      "speakerLabel": "spk_0",
      "start": 323.04,
      "end": 325.56,
      "text": " And you just use one API to get a response"
    },
    {
      "speakerLabel": "spk_0",
      "start": 325.56,
      "end": 328.08,
      "text": " to an instruction or a prompt."
    },
    {
      "speakerLabel": "spk_0",
      "start": 328.08,
      "end": 331.24,
      "text": " And the models that are available on Bedrock right now"
    },
    {
      "speakerLabel": "spk_0",
      "start": 331.24,
      "end": 334.40000000000003,
      "text": " are from Anthropic, the Claude large language model."
    },
    {
      "speakerLabel": "spk_0",
      "start": 334.40000000000003,
      "end": 337.24,
      "text": " So that's like a good one with a focus on safety,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 337.84000000000003,
      "end": 342.24,
      "text": " safety and security and non-toxic data"
    },
    {
      "speakerLabel": "spk_0",
      "start": 342.24,
      "end": 346.2,
      "text": " and safe data from reliable sources is their focus there."
    },
    {
      "speakerLabel": "spk_0",
      "start": 346.2,
      "end": 348.28000000000003,
      "text": " And then you've got Cohere command model"
    },
    {
      "speakerLabel": "spk_0",
      "start": 348.28000000000003,
      "end": 351.44,
      "text": " for cases like customer support and business scenarios."
    },
    {
      "speakerLabel": "spk_0",
      "start": 351.44,
      "end": 355.52,
      "text": " You have the AI21 Jurassic large language model,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 355.52,
      "end": 358.40000000000003,
      "text": " and then you have Amazon's own Titan models,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 358.40000000000003,
      "end": 361.44,
      "text": " which are like general purpose large language models."
    },
    {
      "speakerLabel": "spk_0",
      "start": 361.44,
      "end": 364.96000000000004,
      "text": " And those ones are really aiming to be the lower cost ones"
    },
    {
      "speakerLabel": "spk_0",
      "start": 364.96,
      "end": 367.32,
      "text": " where you're just really trying to cost optimize."
    },
    {
      "speakerLabel": "spk_0",
      "start": 367.32,
      "end": 368.44,
      "text": " They're not fully available yet."
    },
    {
      "speakerLabel": "spk_0",
      "start": 368.44,
      "end": 371,
      "text": " Not all of the models are available yet."
    },
    {
      "speakerLabel": "spk_0",
      "start": 371,
      "end": 373.76,
      "text": " And then if you're doing image generation,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 373.76,
      "end": 376.88,
      "text": " you have the stable diffusion models available there as well."
    },
    {
      "speakerLabel": "spk_0",
      "start": 377.91999999999996,
      "end": 379.91999999999996,
      "text": " There are also other models planned"
    },
    {
      "speakerLabel": "spk_0",
      "start": 379.91999999999996,
      "end": 382.28,
      "text": " like the Facebook meta llama2 model"
    },
    {
      "speakerLabel": "spk_0",
      "start": 382.28,
      "end": 384.28,
      "text": " is also supposed to be coming soon"
    },
    {
      "speakerLabel": "spk_0",
      "start": 384.28,
      "end": 386.91999999999996,
      "text": " and a lot more expected to arrive."
    },
    {
      "speakerLabel": "spk_0",
      "start": 386.91999999999996,
      "end": 389.88,
      "text": " So if you want to use a model that isn't on Bedrock,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 389.88,
      "end": 392.64,
      "text": " but is available elsewhere, like on Hugging Face,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 392.64,
      "end": 394.56,
      "text": " you would need to really host the model somewhere else"
    },
    {
      "speakerLabel": "spk_0",
      "start": 395.04,
      "end": 398.08,
      "text": " like on SageMaker in the more traditional way."
    },
    {
      "speakerLabel": "spk_0",
      "start": 398.08,
      "end": 400.44,
      "text": " But going back to the ones that are available on Bedrock,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 400.44,
      "end": 403.4,
      "text": " then if you're just trying to start to build practical,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 403.4,
      "end": 405.96,
      "text": " like chat features or text summarization,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 405.96,
      "end": 409.32,
      "text": " image generation features, build it into your application,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 409.32,
      "end": 411.12,
      "text": " I would just say to people"
    },
    {
      "speakerLabel": "spk_0",
      "start": 411.12,
      "end": 413.32,
      "text": " that I think it's a lot easier than you would expect."
    },
    {
      "speakerLabel": "spk_0",
      "start": 413.32,
      "end": 414.96,
      "text": " And there's very little work you have to do."
    },
    {
      "speakerLabel": "spk_0",
      "start": 414.96,
      "end": 417.56,
      "text": " It ultimately depends on your use case."
    },
    {
      "speakerLabel": "spk_0",
      "start": 417.56,
      "end": 420.6,
      "text": " And if you need to pull in additional data,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 420.6,
      "end": 422,
      "text": " but generally for the kind of use case"
    },
    {
      "speakerLabel": "spk_0",
      "start": 422,
      "end": 423.32,
      "text": " we're describing here,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 423.32,
      "end": 425.44,
      "text": " it's really quite a simple addition."
    },
    {
      "speakerLabel": "spk_0",
      "start": 425.44,
      "end": 428.08,
      "text": " So it allows you to quickly use these models"
    },
    {
      "speakerLabel": "spk_0",
      "start": 428.08,
      "end": 430.76,
      "text": " and then add things like chat applications,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 430.76,
      "end": 433.59999999999997,
      "text": " text summarization, knowledge search"
    },
    {
      "speakerLabel": "spk_0",
      "start": 433.59999999999997,
      "end": 437.15999999999997,
      "text": " based on additional data you might have in documents,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 437.15999999999997,
      "end": 439,
      "text": " doing text to image creation"
    },
    {
      "speakerLabel": "spk_0",
      "start": 439,
      "end": 441.2,
      "text": " or image to image creation as well."
    },
    {
      "speakerLabel": "spk_0",
      "start": 441.2,
      "end": 442.71999999999997,
      "text": " Now there's a very small bit of setup,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 442.71999999999997,
      "end": 445.8,
      "text": " which is that because you're using these third party models"
    },
    {
      "speakerLabel": "spk_0",
      "start": 445.8,
      "end": 447.32,
      "text": " before you go and use them,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 447.32,
      "end": 448.88,
      "text": " you have to go into the console"
    },
    {
      "speakerLabel": "spk_0",
      "start": 448.88,
      "end": 451,
      "text": " and go into Bedrock model settings"
    },
    {
      "speakerLabel": "spk_0",
      "start": 451.04,
      "end": 454.12,
      "text": " and explicitly enable each model"
    },
    {
      "speakerLabel": "spk_0",
      "start": 454.12,
      "end": 457.04,
      "text": " and agree to their end user license agreement."
    },
    {
      "speakerLabel": "spk_0",
      "start": 457.04,
      "end": 459.04,
      "text": " So I guess there's because of the nature"
    },
    {
      "speakerLabel": "spk_0",
      "start": 459.04,
      "end": 460.64,
      "text": " of these applications,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 460.64,
      "end": 462.28,
      "text": " the fact that they're non-deterministic"
    },
    {
      "speakerLabel": "spk_0",
      "start": 462.28,
      "end": 464.56,
      "text": " when you're using models and there's impact there,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 464.56,
      "end": 468.2,
      "text": " you just have to get the legal sign off on those pieces."
    },
    {
      "speakerLabel": "spk_0",
      "start": 468.2,
      "end": 470.32,
      "text": " Once you've done that, it's basically serverless."
    },
    {
      "speakerLabel": "spk_0",
      "start": 470.32,
      "end": 472.84,
      "text": " So you can start making requests without having to wait"
    },
    {
      "speakerLabel": "spk_0",
      "start": 472.84,
      "end": 474.68,
      "text": " for any infrastructure to be set up."
    },
    {
      "speakerLabel": "spk_0",
      "start": 475.88,
      "end": 478.28,
      "text": " Now, if you're comparing Bedrock to other things"
    },
    {
      "speakerLabel": "spk_0",
      "start": 478.32,
      "end": 481.88,
      "text": " like maybe OpenAI APIs, for example,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 481.88,
      "end": 483.59999999999997,
      "text": " the idea here is that with Bedrock,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 483.59999999999997,
      "end": 486.59999999999997,
      "text": " there's more of a focus on privacy and security."
    },
    {
      "speakerLabel": "spk_0",
      "start": 486.59999999999997,
      "end": 489.32,
      "text": " So the big difference compared to other alternatives"
    },
    {
      "speakerLabel": "spk_0",
      "start": 489.32,
      "end": 491.23999999999995,
      "text": " is that your data is encrypted."
    },
    {
      "speakerLabel": "spk_0",
      "start": 491.23999999999995,
      "end": 493.4,
      "text": " It's not shared with other model providers."
    },
    {
      "speakerLabel": "spk_0",
      "start": 494.44,
      "end": 497.84,
      "text": " You can keep your data and traffic within your VPC as well"
    },
    {
      "speakerLabel": "spk_0",
      "start": 497.84,
      "end": 498.71999999999997,
      "text": " using PrivateLink."
    },
    {
      "speakerLabel": "spk_0",
      "start": 498.71999999999997,
      "end": 502.55999999999995,
      "text": " So you've got encryption and your data isn't gonna be used"
    },
    {
      "speakerLabel": "spk_0",
      "start": 502.55999999999995,
      "end": 504.35999999999996,
      "text": " to train the models further"
    },
    {
      "speakerLabel": "spk_0",
      "start": 504.35999999999996,
      "end": 506.91999999999996,
      "text": " and that's part of the agreement that you get."
    },
    {
      "speakerLabel": "spk_0",
      "start": 506.96000000000004,
      "end": 509,
      "text": " So you can use those models all as is,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 509,
      "end": 511.28000000000003,
      "text": " but there's also a whole other set of APIs there"
    },
    {
      "speakerLabel": "spk_0",
      "start": 511.28000000000003,
      "end": 513.4,
      "text": " for fine tuning them if you need to"
    },
    {
      "speakerLabel": "spk_0",
      "start": 513.4,
      "end": 515.6800000000001,
      "text": " using your own training data on S3"
    },
    {
      "speakerLabel": "spk_0",
      "start": 515.6800000000001,
      "end": 516.76,
      "text": " and simplifying that as well."
    },
    {
      "speakerLabel": "spk_0",
      "start": 516.76,
      "end": 520.5600000000001,
      "text": " But we're just talking really about using foundation models"
    },
    {
      "speakerLabel": "spk_0",
      "start": 520.5600000000001,
      "end": 523.28,
      "text": " for inference, just for getting a response back"
    },
    {
      "speakerLabel": "spk_0",
      "start": 523.28,
      "end": 527.2,
      "text": " and without any special training or any kind of fine tuning."
    },
    {
      "speakerLabel": "spk_0",
      "start": 527.2,
      "end": 528.24,
      "text": " So for our use case,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 528.24,
      "end": 532.48,
      "text": " we decided to use the Anthropic Claude V2 model"
    },
    {
      "speakerLabel": "spk_0",
      "start": 532.48,
      "end": 535.9200000000001,
      "text": " because it supports the largest input size by far."
    },
    {
      "speakerLabel": "spk_0",
      "start": 535.92,
      "end": 538.68,
      "text": " It supports up to 100,000 tokens,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 538.68,
      "end": 541.92,
      "text": " which usually equates to around 75,000 words."
    },
    {
      "speakerLabel": "spk_0",
      "start": 541.92,
      "end": 544.9599999999999,
      "text": " And we want to be able to give it a full episode transcript"
    },
    {
      "speakerLabel": "spk_0",
      "start": 544.9599999999999,
      "end": 546.92,
      "text": " and our episodes can be anything"
    },
    {
      "speakerLabel": "spk_0",
      "start": 546.92,
      "end": 551.7199999999999,
      "text": " based on a historical evidence between 2000 and 30,000 words."
    },
    {
      "speakerLabel": "spk_0",
      "start": 551.7199999999999,
      "end": 554.16,
      "text": " So that might be 40,000 tokens."
    },
    {
      "speakerLabel": "spk_0",
      "start": 555.1999999999999,
      "end": 556.28,
      "text": " So that's what we started with."
    },
    {
      "speakerLabel": "spk_0",
      "start": 556.28,
      "end": 559.76,
      "text": " Luciano, what's then the goal of the design of the system?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 559.76,
      "end": 560.76,
      "text": " What do we want it to do?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 560.76,
      "end": 563.5999999999999,
      "text": " We've got the problem, we've got the model."
    },
    {
      "speakerLabel": "spk_0",
      "start": 563.5999999999999,
      "end": 565.76,
      "text": " What was our thinking from that point?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 566.4399999999999,
      "end": 567.92,
      "text": " We already had a piece of automation."
    },
    {
      "speakerLabel": "spk_1",
      "start": 567.92,
      "end": 570.52,
      "text": " We already mentioned PodWhisperer a couple of times"
    },
    {
      "speakerLabel": "spk_1",
      "start": 570.52,
      "end": 572.76,
      "text": " and PodWhisperer is effectively a step function."
    },
    {
      "speakerLabel": "spk_1",
      "start": 572.76,
      "end": 576.2,
      "text": " So it's a workflow that orchestrates different things."
    },
    {
      "speakerLabel": "spk_1",
      "start": 576.2,
      "end": 580.6,
      "text": " And eventually what it does, it creates a transcript for us."
    },
    {
      "speakerLabel": "spk_1",
      "start": 580.6,
      "end": 583.48,
      "text": " So the idea was, okay, we have already the step function."
    },
    {
      "speakerLabel": "spk_1",
      "start": 583.48,
      "end": 586.4399999999999,
      "text": " We have already a step that gives us something"
    },
    {
      "speakerLabel": "spk_1",
      "start": 586.4399999999999,
      "end": 587.52,
      "text": " that we can use as an input."
    },
    {
      "speakerLabel": "spk_1",
      "start": 587.52,
      "end": 590.28,
      "text": " So what we need to do next is basically extending"
    },
    {
      "speakerLabel": "spk_1",
      "start": 590.28,
      "end": 592.3199999999999,
      "text": " that step function, taking that input"
    },
    {
      "speakerLabel": "spk_1",
      "start": 592.3199999999999,
      "end": 594.4,
      "text": " and basically do more stuff with it."
    },
    {
      "speakerLabel": "spk_1",
      "start": 594.4399999999999,
      "end": 597.88,
      "text": " So once we have the transcript, what we can do"
    },
    {
      "speakerLabel": "spk_1",
      "start": 597.88,
      "end": 600.4399999999999,
      "text": " as the new steps that we introduce in this automation"
    },
    {
      "speakerLabel": "spk_1",
      "start": 600.4399999999999,
      "end": 602.1999999999999,
      "text": " is basically we can create a prompt"
    },
    {
      "speakerLabel": "spk_1",
      "start": 602.1999999999999,
      "end": 604.04,
      "text": " that will instruct the large language model"
    },
    {
      "speakerLabel": "spk_1",
      "start": 604.04,
      "end": 606.1999999999999,
      "text": " to generate few different things."
    },
    {
      "speakerLabel": "spk_1",
      "start": 606.1999999999999,
      "end": 609.56,
      "text": " One is the episode summary, then the YouTube chapters"
    },
    {
      "speakerLabel": "spk_1",
      "start": 609.56,
      "end": 611.68,
      "text": " with precise timing and topic"
    },
    {
      "speakerLabel": "spk_1",
      "start": 611.68,
      "end": 614.16,
      "text": " and a set of tags for the episode."
    },
    {
      "speakerLabel": "spk_1",
      "start": 614.16,
      "end": 615.64,
      "text": " I think here is worth mentioning also"
    },
    {
      "speakerLabel": "spk_1",
      "start": 615.64,
      "end": 616.9599999999999,
      "text": " that when we generate the transcript,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 616.9599999999999,
      "end": 620.8,
      "text": " it's not just the text, but we also keep time references"
    },
    {
      "speakerLabel": "spk_1",
      "start": 620.8,
      "end": 622.28,
      "text": " to all the different bits and pieces."
    },
    {
      "speakerLabel": "spk_1",
      "start": 622.4,
      "end": 625.36,
      "text": " And this is how we are basically capable"
    },
    {
      "speakerLabel": "spk_1",
      "start": 625.36,
      "end": 628.04,
      "text": " of doing chapters with precise timing,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 628.04,
      "end": 629.76,
      "text": " because we are giving the model"
    },
    {
      "speakerLabel": "spk_1",
      "start": 629.76,
      "end": 631.0799999999999,
      "text": " not just the text information,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 631.0799999999999,
      "end": 633.76,
      "text": " but also the timing of every text occurrence."
    },
    {
      "speakerLabel": "spk_1",
      "start": 633.76,
      "end": 638.0799999999999,
      "text": " So it can determine exactly which piece of text is said"
    },
    {
      "speakerLabel": "spk_1",
      "start": 638.0799999999999,
      "end": 639.88,
      "text": " at which specific point in time."
    },
    {
      "speakerLabel": "spk_1",
      "start": 641,
      "end": 644.8,
      "text": " So once we create this prompt that needs to kind of summarize"
    },
    {
      "speakerLabel": "spk_1",
      "start": 644.8,
      "end": 646.28,
      "text": " all of this instruction in a way"
    },
    {
      "speakerLabel": "spk_1",
      "start": 646.28,
      "end": 648.28,
      "text": " that the model can really understand"
    },
    {
      "speakerLabel": "spk_1",
      "start": 648.28,
      "end": 650.04,
      "text": " and give us the output we expect,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 650.04,
      "end": 651.3199999999999,
      "text": " we need to pass the prompt."
    },
    {
      "speakerLabel": "spk_1",
      "start": 651.36,
      "end": 654.48,
      "text": " So we need to actually make an API call to bedrock."
    },
    {
      "speakerLabel": "spk_1",
      "start": 654.48,
      "end": 657.32,
      "text": " And we also need to give the full episode transcript,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 657.32,
      "end": 659.2800000000001,
      "text": " of course, because that's part of the context"
    },
    {
      "speakerLabel": "spk_1",
      "start": 659.2800000000001,
      "end": 660.7600000000001,
      "text": " that we need to give it."
    },
    {
      "speakerLabel": "spk_1",
      "start": 660.7600000000001,
      "end": 664.2800000000001,
      "text": " And after a while, when this request is processed,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 664.2800000000001,
      "end": 667.2,
      "text": " we receive a response, we need to pass this response,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 667.2,
      "end": 670.5200000000001,
      "text": " and this becomes the next step in our integration."
    },
    {
      "speakerLabel": "spk_1",
      "start": 670.5200000000001,
      "end": 673.4000000000001,
      "text": " So what we finally want to do is basically"
    },
    {
      "speakerLabel": "spk_1",
      "start": 673.4000000000001,
      "end": 675.84,
      "text": " we want to create a pull request"
    },
    {
      "speakerLabel": "spk_1",
      "start": 675.84,
      "end": 679,
      "text": " to our website repository, which is something we manage"
    },
    {
      "speakerLabel": "spk_1",
      "start": 679,
      "end": 681.68,
      "text": " with a static set generator called Eleventy."
    },
    {
      "speakerLabel": "spk_1",
      "start": 681.68,
      "end": 683.48,
      "text": " And it's all managed open source"
    },
    {
      "speakerLabel": "spk_1",
      "start": 683.48,
      "end": 684.92,
      "text": " in a public repository on GitHub."
    },
    {
      "speakerLabel": "spk_1",
      "start": 684.92,
      "end": 686.84,
      "text": " So we will also have the link if you're curious"
    },
    {
      "speakerLabel": "spk_1",
      "start": 686.84,
      "end": 689.28,
      "text": " to see exactly how we build our own website."
    },
    {
      "speakerLabel": "spk_1",
      "start": 689.28,
      "end": 690.72,
      "text": " So we create this pull request,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 690.72,
      "end": 693.72,
      "text": " and this pull request contains all this information"
    },
    {
      "speakerLabel": "spk_1",
      "start": 693.72,
      "end": 697.72,
      "text": " nicely laid out in the PR description."
    },
    {
      "speakerLabel": "spk_1",
      "start": 697.72,
      "end": 699.76,
      "text": " So this is what we got from bedrock,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 699.76,
      "end": 701.64,
      "text": " but also contains the transcript"
    },
    {
      "speakerLabel": "spk_1",
      "start": 701.64,
      "end": 704.08,
      "text": " that we can incorporate in the website as well."
    },
    {
      "speakerLabel": "spk_1",
      "start": 704.08,
      "end": 705.52,
      "text": " And this is something we were doing before."
    },
    {
      "speakerLabel": "spk_1",
      "start": 705.52,
      "end": 708.64,
      "text": " So the new bit here is that the pull request description"
    },
    {
      "speakerLabel": "spk_1",
      "start": 709.16,
      "end": 711.8,
      "text": " will contain all this additional information,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 711.8,
      "end": 714,
      "text": " description, chapters, and tags"
    },
    {
      "speakerLabel": "spk_1",
      "start": 714,
      "end": 716.88,
      "text": " in a way that we can easily copy paste it into YouTube."
    },
    {
      "speakerLabel": "spk_1",
      "start": 716.88,
      "end": 719.3199999999999,
      "text": " And this way we're saving lots of time."
    },
    {
      "speakerLabel": "spk_1",
      "start": 719.3199999999999,
      "end": 722.56,
      "text": " Of course, we still take some manual time"
    },
    {
      "speakerLabel": "spk_1",
      "start": 722.56,
      "end": 725.4,
      "text": " to review everything and decide whether we like it or not"
    },
    {
      "speakerLabel": "spk_1",
      "start": 725.4,
      "end": 727.72,
      "text": " and add a little bit of personal touch,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 727.72,
      "end": 730.8,
      "text": " but I think that's saving us already a lot of time."
    },
    {
      "speakerLabel": "spk_1",
      "start": 731.76,
      "end": 733.8,
      "text": " I think one of the interesting bits here,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 733.8,
      "end": 736.3199999999999,
      "text": " which at least when we started to work on this"
    },
    {
      "speakerLabel": "spk_1",
      "start": 736.3199999999999,
      "end": 737.72,
      "text": " wasn't obvious at all to me,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 737.76,
      "end": 740.72,
      "text": " is the part where we defined basically"
    },
    {
      "speakerLabel": "spk_1",
      "start": 740.72,
      "end": 741.64,
      "text": " the prompt engineering."
    },
    {
      "speakerLabel": "spk_1",
      "start": 741.64,
      "end": 744.48,
      "text": " How do we tell the model, what do we want,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 744.48,
      "end": 746.52,
      "text": " and in which format it should give it to us?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 746.52,
      "end": 748.88,
      "text": " So do you want to talk a little bit more about that,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 748.88,
      "end": 750.2,
      "text": " or what?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 750.2,
      "end": 752.88,
      "text": " Yeah, the prompt syntax for every model is slightly different."
    },
    {
      "speakerLabel": "spk_0",
      "start": 752.88,
      "end": 754.9200000000001,
      "text": " For example, for the cloud one we're using,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 754.9200000000001,
      "end": 757.36,
      "text": " you need to specify like human colon,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 757.36,
      "end": 758.72,
      "text": " then your instruction,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 758.72,
      "end": 761.4,
      "text": " and then a new line with assistant colon,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 761.4,
      "end": 764.2,
      "text": " and then finish it with another two new lines."
    },
    {
      "speakerLabel": "spk_0",
      "start": 764.2,
      "end": 766.32,
      "text": " That's just the way that the model has been trained"
    },
    {
      "speakerLabel": "spk_0",
      "start": 766.32,
      "end": 767.6800000000001,
      "text": " and expects input."
    },
    {
      "speakerLabel": "spk_0",
      "start": 768.4799999999999,
      "end": 771.2399999999999,
      "text": " Beyond that, it's kind of like trying to come up"
    },
    {
      "speakerLabel": "spk_0",
      "start": 771.2399999999999,
      "end": 772.92,
      "text": " with the right phrases and instructions"
    },
    {
      "speakerLabel": "spk_0",
      "start": 772.92,
      "end": 774.56,
      "text": " and restrictions and examples"
    },
    {
      "speakerLabel": "spk_0",
      "start": 775.52,
      "end": 777.52,
      "text": " so that it has the best chance of giving you"
    },
    {
      "speakerLabel": "spk_0",
      "start": 777.52,
      "end": 780.18,
      "text": " the kind of inference results you're looking for."
    },
    {
      "speakerLabel": "spk_0",
      "start": 780.18,
      "end": 781.04,
      "text": " And the way you can do that,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 781.04,
      "end": 783.3199999999999,
      "text": " you can start off with a bedrock playground"
    },
    {
      "speakerLabel": "spk_0",
      "start": 783.3199999999999,
      "end": 784.7199999999999,
      "text": " in the AWS console,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 784.7199999999999,
      "end": 787.04,
      "text": " and you can type instructions there."
    },
    {
      "speakerLabel": "spk_0",
      "start": 787.04,
      "end": 791.16,
      "text": " The API or SDK is really simple for models."
    },
    {
      "speakerLabel": "spk_0",
      "start": 791.16,
      "end": 793.1999999999999,
      "text": " You're just doing an invoke model request."
    },
    {
      "speakerLabel": "spk_0",
      "start": 793.1999999999999,
      "end": 794.56,
      "text": " That's what we're doing."
    },
    {
      "speakerLabel": "spk_0",
      "start": 794.56,
      "end": 796.8399999999999,
      "text": " And there's only a couple of parameters you need to pass in."
    },
    {
      "speakerLabel": "spk_0",
      "start": 796.88,
      "end": 798.8000000000001,
      "text": " You can look at the documentation for the parameters"
    },
    {
      "speakerLabel": "spk_0",
      "start": 798.8000000000001,
      "end": 800.4,
      "text": " that you need to specify,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 800.4,
      "end": 803.1800000000001,
      "text": " and then it's just understanding how to format your prompt."
    },
    {
      "speakerLabel": "spk_0",
      "start": 803.1800000000001,
      "end": 807.9,
      "text": " So for us, it's just a string with this human start,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 807.9,
      "end": 809.64,
      "text": " and then we're asking it the instruction."
    },
    {
      "speakerLabel": "spk_0",
      "start": 809.64,
      "end": 813.32,
      "text": " So what we're saying is provide us with a episode summary,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 813.32,
      "end": 814.72,
      "text": " first person plural,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 814.72,
      "end": 817.6600000000001,
      "text": " and we're aiming for around 120 words."
    },
    {
      "speakerLabel": "spk_0",
      "start": 817.6600000000001,
      "end": 820.52,
      "text": " And then we say followed by 10 chapter summaries"
    },
    {
      "speakerLabel": "spk_0",
      "start": 821.88,
      "end": 824.36,
      "text": " for this following transcript JSON, right?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 824.36,
      "end": 826.84,
      "text": " So we're gonna include the JSON in the instruction."
    },
    {
      "speakerLabel": "spk_0",
      "start": 826.84,
      "end": 831.6,
      "text": " And then we're also asking for the chapter summaries"
    },
    {
      "speakerLabel": "spk_0",
      "start": 831.6,
      "end": 834.96,
      "text": " to be based off the timings in the transcript segments,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 834.96,
      "end": 837.72,
      "text": " and for those timestamps to be included"
    },
    {
      "speakerLabel": "spk_0",
      "start": 837.72,
      "end": 840.88,
      "text": " exactly as they were, the same format from the segments."
    },
    {
      "speakerLabel": "spk_0",
      "start": 840.88,
      "end": 844.28,
      "text": " And we're also asking then for the tags,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 844.28,
      "end": 847.5,
      "text": " like up to 20 relevant tags for the YouTube video."
    },
    {
      "speakerLabel": "spk_0",
      "start": 847.5,
      "end": 849.02,
      "text": " But we're also doing this kind of,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 849.02,
      "end": 850.9200000000001,
      "text": " it's kind of a single shot inference"
    },
    {
      "speakerLabel": "spk_0",
      "start": 850.9599999999999,
      "end": 855.0799999999999,
      "text": " where we're giving it an example as well"
    },
    {
      "speakerLabel": "spk_0",
      "start": 855.0799999999999,
      "end": 857.52,
      "text": " of the output we want to receive."
    },
    {
      "speakerLabel": "spk_0",
      "start": 857.52,
      "end": 860.92,
      "text": " So we're giving it a sample JSON"
    },
    {
      "speakerLabel": "spk_0",
      "start": 860.92,
      "end": 863.56,
      "text": " just to show the structure that we're looking for."
    },
    {
      "speakerLabel": "spk_0",
      "start": 863.56,
      "end": 866.68,
      "text": " And when we run that, then about 20 or 30 seconds later,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 866.68,
      "end": 869.3199999999999,
      "text": " we can get back our response."
    },
    {
      "speakerLabel": "spk_0",
      "start": 869.3199999999999,
      "end": 871.8199999999999,
      "text": " It starts off with a bit of text and then the JSON."
    },
    {
      "speakerLabel": "spk_0",
      "start": 871.8199999999999,
      "end": 875.4399999999999,
      "text": " So we just need to strip out the JSON and parse it."
    },
    {
      "speakerLabel": "spk_0",
      "start": 875.4399999999999,
      "end": 879.26,
      "text": " Now, you might wonder, this is a non-deterministic model."
    },
    {
      "speakerLabel": "spk_0",
      "start": 879.3,
      "end": 881,
      "text": " It can generate all sorts."
    },
    {
      "speakerLabel": "spk_0",
      "start": 881,
      "end": 883.38,
      "text": " Will it always generate valid JSON?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 883.38,
      "end": 885.86,
      "text": " That's something to be mindful of,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 885.86,
      "end": 888.86,
      "text": " but in our testing, it has always generated"
    },
    {
      "speakerLabel": "spk_0",
      "start": 888.86,
      "end": 891.26,
      "text": " exactly perfectly formatted JSON,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 891.26,
      "end": 892.7,
      "text": " and we haven't had any issue there"
    },
    {
      "speakerLabel": "spk_0",
      "start": 892.7,
      "end": 895.34,
      "text": " because we're using that example in the prompt."
    },
    {
      "speakerLabel": "spk_0",
      "start": 895.34,
      "end": 897.02,
      "text": " So then tying this all in briefly"
    },
    {
      "speakerLabel": "spk_0",
      "start": 897.02,
      "end": 898.1,
      "text": " into the total architecture,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 898.1,
      "end": 900.78,
      "text": " which you can see on the website, there's a diagram there."
    },
    {
      "speakerLabel": "spk_0",
      "start": 900.78,
      "end": 902.9399999999999,
      "text": " We're using step function to orchestrate."
    },
    {
      "speakerLabel": "spk_0",
      "start": 902.9399999999999,
      "end": 904.9399999999999,
      "text": " It's a very simple two-step step function."
    },
    {
      "speakerLabel": "spk_0",
      "start": 904.9399999999999,
      "end": 907.68,
      "text": " It's triggered by S3 events in EventBridge."
    },
    {
      "speakerLabel": "spk_0",
      "start": 907.68,
      "end": 909.68,
      "text": " It runs the summarization lambda function"
    },
    {
      "speakerLabel": "spk_0",
      "start": 909.68,
      "end": 912.3199999999999,
      "text": " that calls bedrock with the prompt,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 912.3199999999999,
      "end": 913.9599999999999,
      "text": " passing in the full transcript"
    },
    {
      "speakerLabel": "spk_0",
      "start": 913.9599999999999,
      "end": 917.18,
      "text": " and getting back the response, extracting the JSON."
    },
    {
      "speakerLabel": "spk_0",
      "start": 917.18,
      "end": 919.0999999999999,
      "text": " Then we pass that to the next step in the step function,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 919.0999999999999,
      "end": 921.02,
      "text": " which is our pull request lambda,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 921.02,
      "end": 923.4799999999999,
      "text": " which is the same one we had in the other project before."
    },
    {
      "speakerLabel": "spk_0",
      "start": 923.4799999999999,
      "end": 926.28,
      "text": " We just refactored this into the new repo,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 926.28,
      "end": 928.76,
      "text": " and that creates the pull request based on that JSON"
    },
    {
      "speakerLabel": "spk_0",
      "start": 928.76,
      "end": 931.1999999999999,
      "text": " and gives us that nice GitHub description."
    },
    {
      "speakerLabel": "spk_0",
      "start": 931.1999999999999,
      "end": 932.02,
      "text": " And that's it."
    },
    {
      "speakerLabel": "spk_0",
      "start": 932.02,
      "end": 933.4,
      "text": " So I think it's pretty simple all in all,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 933.4,
      "end": 934.4399999999999,
      "text": " but it's quite powerful."
    },
    {
      "speakerLabel": "spk_0",
      "start": 934.44,
      "end": 937.7800000000001,
      "text": " And the results, I think, so far look pretty impressive."
    },
    {
      "speakerLabel": "spk_0",
      "start": 937.7800000000001,
      "end": 942.7800000000001,
      "text": " And recently we did the interview with Jeremy Daley."
    },
    {
      "speakerLabel": "spk_0",
      "start": 943.12,
      "end": 945.74,
      "text": " We got really a great amount of time to talk to Jeremy,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 945.74,
      "end": 948.24,
      "text": " but the more time you have, the more effort you have to do"
    },
    {
      "speakerLabel": "spk_0",
      "start": 948.24,
      "end": 949.7600000000001,
      "text": " if you're trying to create chapters."
    },
    {
      "speakerLabel": "spk_0",
      "start": 949.7600000000001,
      "end": 951.6400000000001,
      "text": " So all of this automation really helps us"
    },
    {
      "speakerLabel": "spk_0",
      "start": 951.6400000000001,
      "end": 953.7600000000001,
      "text": " because this podcast is only really possible"
    },
    {
      "speakerLabel": "spk_0",
      "start": 953.7600000000001,
      "end": 956.72,
      "text": " because we've managed to find a format"
    },
    {
      "speakerLabel": "spk_0",
      "start": 956.72,
      "end": 958.96,
      "text": " that doesn't take too much of our time."
    },
    {
      "speakerLabel": "spk_0",
      "start": 958.96,
      "end": 961.5200000000001,
      "text": " We do some preparation, we record the episodes,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 961.5200000000001,
      "end": 964.36,
      "text": " and then we try to keep the post-production"
    },
    {
      "speakerLabel": "spk_0",
      "start": 965.24,
      "end": 966.5600000000001,
      "text": " process as lean as possible."
    },
    {
      "speakerLabel": "spk_1",
      "start": 966.5600000000001,
      "end": 968.16,
      "text": " Of course, all of this stuff is not free."
    },
    {
      "speakerLabel": "spk_1",
      "start": 968.16,
      "end": 970.76,
      "text": " We are using a service, we are using AWS."
    },
    {
      "speakerLabel": "spk_1",
      "start": 970.76,
      "end": 973.28,
      "text": " AWS is running servers and GPUs for us."
    },
    {
      "speakerLabel": "spk_1",
      "start": 973.28,
      "end": 975.24,
      "text": " So of course there is a cost to it."
    },
    {
      "speakerLabel": "spk_1",
      "start": 975.24,
      "end": 976.64,
      "text": " So what is the cost?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 976.64,
      "end": 979.34,
      "text": " And there are actually two different pricing models"
    },
    {
      "speakerLabel": "spk_1",
      "start": 979.34,
      "end": 980.48,
      "text": " that you can pick."
    },
    {
      "speakerLabel": "spk_1",
      "start": 980.48,
      "end": 983.02,
      "text": " One is called provisioned and one is called on-demand."
    },
    {
      "speakerLabel": "spk_1",
      "start": 983.02,
      "end": 985.12,
      "text": " Provision, you basically pay per hour."
    },
    {
      "speakerLabel": "spk_1",
      "start": 985.12,
      "end": 986.04,
      "text": " And it's interesting enough"
    },
    {
      "speakerLabel": "spk_1",
      "start": 986.04,
      "end": 988.04,
      "text": " that it's not supported for all models."
    },
    {
      "speakerLabel": "spk_1",
      "start": 988.04,
      "end": 989.9200000000001,
      "text": " So the idea is that you pay upfront,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 989.9200000000001,
      "end": 993.12,
      "text": " decide on which terms you want to commit,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 993.12,
      "end": 996.14,
      "text": " and then it looks a little bit like a compute saving plan"
    },
    {
      "speakerLabel": "spk_1",
      "start": 996.14,
      "end": 1000.48,
      "text": " where probably AWS is allocating something dedicated to you"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1000.48,
      "end": 1002.2,
      "text": " and then you are paying on the hour"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1002.2,
      "end": 1005,
      "text": " for that set of resources."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1005,
      "end": 1006.88,
      "text": " And we actually didn't use this one."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1006.88,
      "end": 1009.64,
      "text": " We used the on-demand just because it looks more flexible"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1009.64,
      "end": 1012.84,
      "text": " and it's, I think, better for us while we are experimenting"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1012.84,
      "end": 1014.44,
      "text": " and we don't really expect to use it"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1014.44,
      "end": 1016.2,
      "text": " in large volumes anyway."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1016.2,
      "end": 1019,
      "text": " And the on-demand is what you would expect"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1019,
      "end": 1020.7,
      "text": " as kind of a serverless offering"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1020.7,
      "end": 1022.86,
      "text": " where you pay per the amount,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1022.86,
      "end": 1024.98,
      "text": " the units that's being processed."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1024.98,
      "end": 1027.88,
      "text": " And it varies a lot depending on the model you pick."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1027.88,
      "end": 1032.06,
      "text": " For instance, we pay 0.3 of one cent to two cents"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1032.06,
      "end": 1033.48,
      "text": " per model for text."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1033.48,
      "end": 1037.98,
      "text": " And then the most expensive is the stable diffusion one,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1037.98,
      "end": 1040.06,
      "text": " probably because it's also the most expensive"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1040.06,
      "end": 1044.78,
      "text": " to run behind the scenes, and it's 7.2 cents per image."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1044.78,
      "end": 1048.9,
      "text": " So based on that, it might not be very obvious"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1048.9,
      "end": 1051.3400000000001,
      "text": " to understand, especially because we are not generating"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1051.3400000000001,
      "end": 1053.38,
      "text": " images, but we are generating text,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1053.38,
      "end": 1054.8600000000001,
      "text": " and text might vary a lot."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1054.8600000000001,
      "end": 1056.0600000000002,
      "text": " You might have very short text."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1056.0600000000002,
      "end": 1057.7800000000002,
      "text": " You might have very long text."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1057.7800000000002,
      "end": 1060.0800000000002,
      "text": " And also it's not just the text that is generated,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1060.0800000000002,
      "end": 1061.8400000000001,
      "text": " but even the input that you provide."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1061.8400000000001,
      "end": 1064.8000000000002,
      "text": " So if you have longer episodes, you are providing more text."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1064.8000000000002,
      "end": 1068.26,
      "text": " So it's very difficult to do a prediction and say,"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1068.26,
      "end": 1071.26,
      "text": " well, we're gonna be spending X per every episode."
    },
    {
      "speakerLabel": "spk_1",
      "start": 1071.26,
      "end": 1073.38,
      "text": " So how did we reason about cost?"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1073.38,
      "end": 1075.14,
      "text": " What did we do to try to make our costs"
    },
    {
      "speakerLabel": "spk_1",
      "start": 1075.14,
      "end": 1077.38,
      "text": " a little bit more predictable?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1077.5,
      "end": 1080.14,
      "text": " Because it's so difficult to understand this pricing model"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1080.14,
      "end": 1081.94,
      "text": " and it varies from model to model,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1081.94,
      "end": 1084.46,
      "text": " and then the dimension is a bit strange as well."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1084.46,
      "end": 1087.0200000000002,
      "text": " So this pricing example you gave,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1087.0200000000002,
      "end": 1091.14,
      "text": " you mentioned 0.03 of one cent at the lower end,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1091.14,
      "end": 1093.74,
      "text": " up to like one and a half, two cents."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1093.74,
      "end": 1096.7800000000002,
      "text": " That's for a thousand input tokens"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1096.7800000000002,
      "end": 1099.22,
      "text": " for these different language models."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1099.22,
      "end": 1100.18,
      "text": " So what's a token?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1100.18,
      "end": 1102.9,
      "text": " Well, it's generally roughly one word,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1102.9,
      "end": 1105.9,
      "text": " but the input, depending on if you're dynamically"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1105.9,
      "end": 1109.0600000000002,
      "text": " generating your input or if the output is extra long,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1109.0600000000002,
      "end": 1110.02,
      "text": " your price is gonna change."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1110.02,
      "end": 1112.9,
      "text": " So it's important to get more of a real-time handle on costs."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1112.9,
      "end": 1116.5800000000002,
      "text": " So what we did to solve that was we created a real-time view"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1116.5800000000002,
      "end": 1119.8400000000001,
      "text": " of our pricing using a CloudWatch dashboard"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1119.8400000000001,
      "end": 1122.18,
      "text": " that is generated from a CDK application."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1122.18,
      "end": 1124.1000000000001,
      "text": " So this CDK application is in the same repo."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1124.1000000000001,
      "end": 1126.26,
      "text": " You can take a look at it and you can use it as an example"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1126.26,
      "end": 1129.5,
      "text": " to create your own Bedrock pricing dashboard too."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1129.5,
      "end": 1133.5600000000002,
      "text": " And what we do is we hard code the pricing in there"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1133.5600000000002,
      "end": 1135.74,
      "text": " for a cloud model, because unfortunately,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1136.42,
      "end": 1139.7,
      "text": " right now it's not available via the Amazon pricing API."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1139.7,
      "end": 1141.08,
      "text": " So we just had to hard code it,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1141.08,
      "end": 1144.6200000000001,
      "text": " but then we can just generate widgets for a dashboard"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1144.6200000000001,
      "end": 1148.4,
      "text": " that allow us to see a blink of an eye in real time,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1148.4,
      "end": 1151.82,
      "text": " like based on a minute of granularity update,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1151.82,
      "end": 1153.02,
      "text": " what's the price for input?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1153.02,
      "end": 1154.22,
      "text": " What's the price for output?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1154.22,
      "end": 1157.3,
      "text": " What's the total cost over the last week,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1157.3,
      "end": 1160.28,
      "text": " over the last hour, over the last day, whatever."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1160.28,
      "end": 1163.92,
      "text": " And then we can see based on the number of invocations,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1163.92,
      "end": 1167.3000000000002,
      "text": " what does it cost for the average episode to be summarized?"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1167.3000000000002,
      "end": 1169.4,
      "text": " And we have that dashboard, but we also have alarms."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1169.4,
      "end": 1173.46,
      "text": " So we can say, if this goes above $1 per hour"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1173.46,
      "end": 1176.76,
      "text": " for three consecutive hours, then send us notification."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1176.76,
      "end": 1179.16,
      "text": " So we don't have to wait for our budgets to fire"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1179.16,
      "end": 1182.2,
      "text": " or for the end of day billing reports."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1182.2,
      "end": 1183.76,
      "text": " We got much more real time alerts."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1183.76,
      "end": 1185.3600000000001,
      "text": " And so it's an interesting model that you could apply,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1185.3600000000001,
      "end": 1188.3200000000002,
      "text": " but I think it's particularly useful for this kind of stuff."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1188.3200000000002,
      "end": 1190.26,
      "text": " By the way, in case you're wondering,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1190.26,
      "end": 1193.1000000000001,
      "text": " it costs around 13, 14 cents per episode"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1193.1399999999999,
      "end": 1195.06,
      "text": " for us to do all this summarization."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1195.06,
      "end": 1197.06,
      "text": " I think the cost is pretty good."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1197.06,
      "end": 1201.1399999999999,
      "text": " We've run tens, almost a hundred so far"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1201.1399999999999,
      "end": 1205.02,
      "text": " and haven't spent more than $5, I think,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1205.02,
      "end": 1208.1399999999999,
      "text": " or something like that, just with all our testing"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1208.1399999999999,
      "end": 1211.4599999999998,
      "text": " and running the latest few episodes through this engine."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1212.4599999999998,
      "end": 1214.26,
      "text": " If anyone wants to get this up and running"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1214.26,
      "end": 1217.34,
      "text": " for their Gen AI with Bedrock, just check out the repo"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1217.34,
      "end": 1220.56,
      "text": " and you feel free to use that code as an example."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1220.56,
      "end": 1222.6599999999999,
      "text": " And I think that's it for this episode."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1223.0600000000002,
      "end": 1224.3400000000001,
      "text": " Please check out this episode or product."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1224.3400000000001,
      "end": 1225.18,
      "text": " Let us know what you think."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1225.18,
      "end": 1227.26,
      "text": " We'd love to have others contribute to it,"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1227.26,
      "end": 1230.42,
      "text": " add new features and give us some ideas as well."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1230.42,
      "end": 1232.5,
      "text": " So thanks very much for joining us."
    },
    {
      "speakerLabel": "spk_0",
      "start": 1232.5,
      "end": 1233.42,
      "text": " I hope you're really enjoying"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1233.42,
      "end": 1236.5,
      "text": " those robot generated YouTube descriptions"
    },
    {
      "speakerLabel": "spk_0",
      "start": 1236.5,
      "end": 1238.5,
      "text": " and we'll see you in the next episode."
    }
  ]
}