WEBVTT

1
00:00:00.000 --> 00:00:03.600
Integration testing event driven systems is a classic hard problem.

2
00:00:03.600 --> 00:00:08.080
With modern distributed applications, you have events filing off all over the place.

3
00:00:08.080 --> 00:00:12.080
How do you write integration tests that check if events have been sent and received correctly?

4
00:00:12.080 --> 00:00:16.480
As part of pre-Invent, AWS have just released a solution for exactly that.

5
00:00:16.480 --> 00:00:18.640
The AWS IATK.

6
00:00:18.640 --> 00:00:22.240
We've been taking it for a test drive and are going to share everything we found out.

7
00:00:22.240 --> 00:00:24.640
We'll also talk about some of the alternatives.

8
00:00:24.640 --> 00:00:28.880
By the end of this episode, you should have a good idea of how you can use IATK

9
00:00:28.880 --> 00:00:32.240
and we'll share a project where we have been able to use it to test

10
00:00:32.240 --> 00:00:34.560
a cross account application with EventBridge.

11
00:00:34.560 --> 00:00:37.440
My name is Eoin. I'm here with Luciano and this is AWS Bites.

12
00:00:44.800 --> 00:00:49.680
AWS Bites is brought to you by 4thErem, the ultimate AWS partner for modern applications on

13
00:00:49.680 --> 00:00:55.200
AWS. We can help you to be successful with AWS. So check us out at 4thErem.com.

14
00:00:55.200 --> 00:00:59.760
Before we get into IATK and the alternatives, let's take a step back to Luciano.

15
00:00:59.760 --> 00:01:03.440
What is integration testing? How does it compare to other forms of testing?

16
00:01:03.440 --> 00:01:06.960
And why is it so difficult for event-driven applications?

17
00:01:07.920 --> 00:01:14.400
Testing involves taking your code and testing it together with your application and including

18
00:01:14.400 --> 00:01:21.360
external systems. So if your code is communicating with things like a database, for instance,

19
00:01:21.360 --> 00:01:25.040
as part of your integration test, you need to include that database.

20
00:01:25.040 --> 00:01:29.520
And for instance, in a more complicated use case, maybe you connect to another base first,

21
00:01:29.520 --> 00:01:33.360
then you create an email and then you send that email through an email provider.

22
00:01:33.360 --> 00:01:38.320
So you can include all these external pieces as part of your integration test.

23
00:01:38.960 --> 00:01:44.720
And it's a little bit broader than what you might have been used to if you only have done unit tests,

24
00:01:45.280 --> 00:01:51.040
which typically are focusing only on small units of code in isolation.

25
00:01:51.120 --> 00:01:56.240
The idea is to be very efficient, very specific, make sure that that one feature works really,

26
00:01:56.240 --> 00:02:00.560
really well, but they don't cover how do you integrate that feature with the rest of the

27
00:02:00.560 --> 00:02:06.240
application. So this is where integration tests come into place to make sure that you are actually

28
00:02:06.240 --> 00:02:11.280
writing units that are correct, but then those units are actually still correct when they are

29
00:02:11.280 --> 00:02:18.560
put together and combined into your own software solution. So with AWS, it's tricky because often

30
00:02:18.560 --> 00:02:24.320
when you build a solution for AWS, you start to use all these very specific AWS services

31
00:02:24.320 --> 00:02:31.360
with their own specific APIs, for instance, EC2, RDS, ElastiCache or DynamoDB, EventBridge.

32
00:02:31.360 --> 00:02:37.120
And of course, if you're writing unit tests, you can mock some of that and simulate their

33
00:02:37.120 --> 00:02:41.200
behavior to make sure that part of your own business logic works well. But then at some

34
00:02:41.200 --> 00:02:45.920
point you need to make sure that also your own mocks are correct and your implementation

35
00:02:45.920 --> 00:02:51.360
actually works with the real backend, with the real AWS services. So that's when writing

36
00:02:51.360 --> 00:02:55.520
integration tests can help to increase the confidence that your application is actually

37
00:02:55.520 --> 00:03:00.720
going to perform well and be correct when you deploy to production. And it's very often that

38
00:03:00.720 --> 00:03:05.760
you will find bugs not in your code itself, but just the way that you are integrating things

39
00:03:05.760 --> 00:03:10.960
together. Maybe a configuration option is wrong, or maybe you assume that certain API will work in

40
00:03:10.960 --> 00:03:15.680
a certain way and then in reality works slightly different. So in your unit test, you didn't

41
00:03:15.680 --> 00:03:20.960
capture that behavior because you mocked that API and made assumptions. But then when you run

42
00:03:20.960 --> 00:03:25.440
it against the real service, then you realize that there was a mistake there or an edge case that you

43
00:03:25.440 --> 00:03:31.920
didn't include in your own logic. We usually like to mention as an example building e-commerce

44
00:03:31.920 --> 00:03:37.440
solution, because I think this is an example that everyone can relate to. And in that particular

45
00:03:37.440 --> 00:03:42.720
case, we can imagine that there is, I don't know, an order service and a delivery service.

46
00:03:42.720 --> 00:03:47.600
You might be writing them independently as two totally separate services. They might have their

47
00:03:47.600 --> 00:03:52.080
own tests, but then at some point they will have to be integrated together. So for instance,

48
00:03:52.080 --> 00:03:57.920
we might have the case where when you place an order, that order is pushed to something like

49
00:03:57.920 --> 00:04:03.120
EventBridge. And through EventBridge, there is a notification that gets picked up by the delivery

50
00:04:03.120 --> 00:04:09.680
service and the delivery service knows that an order was created and it starts to process it and

51
00:04:09.760 --> 00:04:15.600
do all the fulfillment procedure that you put in place for your own e-commerce. So that EventBridge

52
00:04:15.600 --> 00:04:22.000
is the tricky bit because how do you actually test it and how do you make sure that on one side you

53
00:04:22.000 --> 00:04:26.560
are producing the right type of event, on the other side you are picking it up and processing

54
00:04:26.560 --> 00:04:32.160
it correctly. So that's the question that we want to explore today.

55
00:04:32.160 --> 00:04:37.200
There's different ways, different approaches that people use for testing events, these kinds of applications. One is you

56
00:04:37.280 --> 00:04:42.080
just build in logging to the event system so all events are logged. And then in your integration

57
00:04:42.080 --> 00:04:48.720
test, you can actually scan the logs and filter out for the ones that you're interested in testing

58
00:04:48.720 --> 00:04:54.400
and validating. That's a fairly simple approach, but logs aren't always reliable in terms of the

59
00:04:54.400 --> 00:04:58.880
time to deliver them and the guarantees around delivering them and having to parse them. It can

60
00:04:58.880 --> 00:05:03.600
be a little bit slow and inefficient. Another approach you can take is just focus on more

61
00:05:03.600 --> 00:05:08.960
end-to-end testing. So testing the final outcome like a record appearing in the database or an

62
00:05:08.960 --> 00:05:12.960
email being delivered and then you don't have to think about testing the events at all. It might

63
00:05:12.960 --> 00:05:18.080
work for some cases, but not all cases will have a readable outcome like this and you might want to

64
00:05:18.080 --> 00:05:22.800
focus on just a smaller unit that you're integrating. And then the third approach

65
00:05:22.800 --> 00:05:28.240
is temporarily recreating an additional consumer for the event just for the purposes of your test.

66
00:05:28.240 --> 00:05:35.360
So if you are testing SNS or EventBridge, this could involve adding a temporary SQS queue

67
00:05:35.360 --> 00:05:40.320
as a subscriber or target and polling that SQS queue for a limited period to check

68
00:05:40.320 --> 00:05:45.360
for delivery of the expected message. I think this last approach with the temporary queue

69
00:05:45.360 --> 00:05:49.360
is probably the most reliable, but it requires a bit of setup. You also have to think about

70
00:05:49.360 --> 00:05:53.600
the additional latency to create these test resources and also think about deleting the

71
00:05:53.600 --> 00:05:58.800
queue when the test is finished, including in cases where the test exits before any tear-down

72
00:05:58.800 --> 00:06:03.360
phase has a chance to happen. Now when we're talking about the different approaches, we're

73
00:06:03.360 --> 00:06:08.800
talking about integration testing and end-to-end testing, so it might be worth clarifying the

74
00:06:08.800 --> 00:06:13.680
distinction between those two. Integration testing, as you said Luciano, is basically ensuring that

75
00:06:13.680 --> 00:06:18.720
application components work well individually and together, including with external systems.

76
00:06:19.280 --> 00:06:24.400
End-to-end testing is broader. It's still integration testing because you're using real

77
00:06:24.400 --> 00:06:30.000
services, but it's really everything altogether. So it evaluates the product as a whole from the

78
00:06:30.000 --> 00:06:35.200
user's perspective, user flows, and that can include starting with your front end or an API

79
00:06:35.200 --> 00:06:41.440
or whatever the external user interface is. So given those three approaches we talk about,

80
00:06:41.440 --> 00:06:47.200
what are the tools out there to help you with this?

81
00:06:47.200 --> 00:06:53.760
One of the tools that we have been using, and I think it's very relevant here, is called SLS Test Tools, which comes from this company

82
00:06:53.760 --> 00:07:01.280
called Alayos. It's basically a tool that extends Jest, so the famous Node.js test runner,

83
00:07:01.280 --> 00:07:06.640
and it provides a bunch of additional matchers, I guess I'm going to call them. I'm not sure it's

84
00:07:06.640 --> 00:07:12.880
the right terminology, but it extends basically the capabilities of Jest, the built-in checks

85
00:07:12.880 --> 00:07:18.160
that you can do to include checks that are very specific to AWS services, for instance DynamoDB,

86
00:07:18.160 --> 00:07:26.160
S3, Step Functions, SQS, EventBridge. So the idea is that you will create a test where you

87
00:07:26.160 --> 00:07:32.320
provision some infrastructure and then as part of your test running you can use the specific

88
00:07:32.320 --> 00:07:37.680
matchers or assertions to basically check that the infrastructure was created correctly and that

89
00:07:38.400 --> 00:07:43.440
certain behaviors actually are apparent in the infrastructure after you executed the specific

90
00:07:43.440 --> 00:07:48.800
tests. There is a very good article by Sarah Hamilton that we're going to put in the show

91
00:07:48.800 --> 00:07:55.040
notes which describes a little bit of a tutorial on how to use it and why it can be very convenient,

92
00:07:55.040 --> 00:08:01.920
but I think the hype these days is into this new tool announced by AWS that we mentioned in the

93
00:08:01.920 --> 00:08:08.240
introduction and I think we want to show a little bit more of that and maybe compare it with SLS

94
00:08:08.240 --> 00:08:14.480
test tools. So how does AWS integrated application test kit compares with SLS test tools?

95
00:08:19.600 --> 00:08:24.160
I think that Sarah Hamilton article is actually a very good article on the general approach here, everything we're describing, and I wouldn't be surprised if it actually inspired some of the

96
00:08:24.160 --> 00:08:29.920
design of this integration application test kit from AWS. So it just has been launched and it's

97
00:08:29.920 --> 00:08:34.560
still under public preview, so we're going to talk about the pros and cons, but we should be

98
00:08:34.560 --> 00:08:40.000
fair and say that this is just released. AWS releases things early so we can expect some

99
00:08:40.000 --> 00:08:46.000
glitches. This one is currently available for Python-based tests, although it's implemented

100
00:08:46.000 --> 00:08:53.120
mostly in Go, Golang for the core and it simply uses an RPC wrapper for Python. AWS says that

101
00:08:53.120 --> 00:08:58.560
they will add other languages in time, so I think that's a good thing to see. It has a few

102
00:08:58.560 --> 00:09:03.680
capabilities. We can kind of break them down into three parts. One is creating test events from the

103
00:09:03.680 --> 00:09:08.160
EventBridge schema registry that you can use in your integration tests. The second one is probably

104
00:09:08.160 --> 00:09:12.960
more aligned to what we've been talking about in terms of challenges and that's the validating that

105
00:09:12.960 --> 00:09:17.920
events have been received via EventBridge and have the correct structure. And the third one,

106
00:09:17.920 --> 00:09:23.360
which is kind of the most innovative piece almost, is checking the correct flow of events with X-ray.

107
00:09:23.360 --> 00:09:28.320
So we'll go through how the process for all of these things work. Maybe Luciano, you can talk

108
00:09:28.320 --> 00:09:35.760
about IATK and how it works from the perspective of EventBridge event testing.

109
00:09:35.760 --> 00:09:43.840
So what we tested is basically a very simple example and in this example what happens with this IATK tool is that

110
00:09:43.840 --> 00:09:50.080
it creates a temporary SQS queue and a temporary rule on the bus which uses the same patterns as

111
00:09:50.080 --> 00:09:56.800
the rule you want to test and that will allow you to basically put into SQS copies of the events

112
00:09:56.800 --> 00:10:01.360
that are happening so you can expect them and make sure that they look correct from an application

113
00:10:01.360 --> 00:10:06.560
perspective. It doesn't allow you to specify any pattern. You have to specify a rule and a target

114
00:10:06.560 --> 00:10:11.360
when you create a test listener and this seems a little bit strange. Now I don't know why it needs

115
00:10:11.360 --> 00:10:17.360
the target but we could be missing something that maybe is a little bit obvious to AWS and that we

116
00:10:17.360 --> 00:10:24.880
are not seeing here. Now the idea is that again you are trying to capture that event into SQS and

117
00:10:24.880 --> 00:10:29.920
then analyze it after you have been executing the code that you want to test. So it provides

118
00:10:29.920 --> 00:10:36.240
a number of helper functions for you to effectively clean up everything after you

119
00:10:36.240 --> 00:10:42.480
executed the test but also to inspect the state of the system after the test was executed. And

120
00:10:42.480 --> 00:10:49.680
you can also do things like clean up first just in case that a previous execution maybe left things

121
00:10:49.680 --> 00:10:53.600
in a little bit of a dirty state. So this is something that's actually recommended by the

122
00:10:53.600 --> 00:11:00.000
documentation and then you run your test, you do all of your own assertions and then in the

123
00:11:00.000 --> 00:11:06.000
third down phase you clean up again. Now before we go through all the features of this tool and how

124
00:11:06.000 --> 00:11:13.440
to use it, it's interesting to note that everything is available on GitHub including examples

125
00:11:13.440 --> 00:11:19.760
and what we did is basically we created an integration test for a repository that we call

126
00:11:19.760 --> 00:11:24.320
Cross Account Event Bridge which is something we built previously and it basically allows you to

127
00:11:25.200 --> 00:11:31.280
execute event bridge across accounts and share messages across accounts. And this is something

128
00:11:31.280 --> 00:11:37.520
we mentioned in a previous episode, episode 39, and you can find the link in the show notes if

129
00:11:37.520 --> 00:11:42.400
you want to know a little bit more about that specific use case and why we built it. Now this

130
00:11:42.400 --> 00:11:49.600
repository uses TypeScript for the CDK but because right now this tool only allows you to use Python,

131
00:11:50.480 --> 00:11:56.800
we wrote the integration tests in Python and we will also have a link to the specific test section in this

132
00:11:56.800 --> 00:12:02.640
repository if you want to find a quick way to go and just see how we brought the tests. So let's talk

133
00:12:02.640 --> 00:12:08.400
maybe a little bit about the process of creating this kind of test. Eoin, do you want to cover that?

134
00:12:15.440 --> 00:12:22.320
Yep, so what we did was we were using PyTest so you create your Python test then you use the AWS IATK Python module and instantiate it. Now immediately we kind of ran into an issue where

135
00:12:22.320 --> 00:12:26.880
it didn't pick up the credentials locally. The documentation says that it should pick up your

136
00:12:26.880 --> 00:12:32.000
AWS environment variables but I was just getting expired key all the time and I think it was

137
00:12:32.000 --> 00:12:36.640
picking them up from somewhere else like from a credentials file or config file. I don't use

138
00:12:36.640 --> 00:12:42.240
credentials for files so I don't know why but that didn't seem to work as documented so we had to

139
00:12:42.240 --> 00:12:48.400
actually specify a profile argument in the constructor in order to get this to work. Once

140
00:12:48.400 --> 00:12:53.920
we've done that then you just you need to know the event bus, the rule and the target. So IATK

141
00:12:53.920 --> 00:13:00.720
also provides some utility functions for reading cloud formation resource physical IDs or reading

142
00:13:00.720 --> 00:13:06.720
cloud formation outputs so that you can get those values for your stack. You mentioned also the

143
00:13:06.800 --> 00:13:12.960
cleanup process for ephemeral resources so you can use the IATK remove listeners helper to do that

144
00:13:12.960 --> 00:13:19.120
and you will it will use a tag filter to identify the resources that it can clean up safely. So you

145
00:13:19.120 --> 00:13:23.680
call that at the start of your test and then you also call it during your tear down. That's

146
00:13:23.680 --> 00:13:30.880
basically how you do it so that it clean up at the end of the tests normally but it'll also run at the

147
00:13:30.880 --> 00:13:36.560
start of tests in case there's anything dangling from previously aborted runs. So then you create

148
00:13:36.560 --> 00:13:42.320
an IATK listener so you give it the bus name, the rule name, the target ID and some tags and this

149
00:13:42.320 --> 00:13:47.040
will allow you to start checking for events. So when you create this listener under the hood it's

150
00:13:47.040 --> 00:13:52.720
creating an SQS queue and it's creating an event bridge rule to route events to that queue and it

151
00:13:52.720 --> 00:13:56.960
basically copies the pattern from the rule you provided. Again the fact that they ask you to

152
00:13:56.960 --> 00:14:02.320
provide the target ID as well doesn't make any sense to me because once you have a rule and a

153
00:14:02.320 --> 00:14:07.840
bus and you have a pattern that's all you need I think to do the test. So I didn't look into the

154
00:14:07.840 --> 00:14:13.760
code to find out what was that what that was all about. I'm not very good at reading Golang so I

155
00:14:13.760 --> 00:14:19.120
wasn't going to go in there and try to figure out what was going on but yeah maybe somebody can

156
00:14:19.120 --> 00:14:23.360
explain. I'm sure they have a valid reason for it. And then you have two options for actually

157
00:14:23.360 --> 00:14:28.160
retrieving the events and doing the validation. One is wait until event matched. This basically

158
00:14:28.160 --> 00:14:33.440
just waits for one event to come in on the bus and you provide an assertion function to check if the

159
00:14:33.440 --> 00:14:38.320
message is the one you expect. The other one is poll events. So this is a different model where

160
00:14:38.320 --> 00:14:42.240
you basically say you poll for events for 20 seconds and it'll give you all the events that

161
00:14:42.240 --> 00:14:46.240
arrive in that period and then you can go through them and filter them and check if they are valid

162
00:14:46.240 --> 00:14:50.960
yourself. In your tests teardown function then just remember to clean up the resources created by

163
00:14:51.680 --> 00:14:58.560
IATK. And you can see this example and we have in our cross-account event bridge e-commerce example

164
00:14:58.560 --> 00:15:04.720
we have the event bridge testing approach but we also tried out the trace validation with x-ray

165
00:15:04.720 --> 00:15:09.040
which seemed pretty exciting. We got some mixed results but we were able to get it to work.

166
00:15:09.040 --> 00:15:15.920
Luciano do you want to describe that process?

167
00:15:15.920 --> 00:15:22.480
Yes I think it's a good advice in general to have x-ray enabled when you're doing event driven systems because that gives you peace of mind that you can

168
00:15:22.480 --> 00:15:28.160
trace exactly how requests flow through the system and which different components gets

169
00:15:28.880 --> 00:15:33.760
used based on your own requests. And of course this is something you can even leverage here

170
00:15:33.760 --> 00:15:38.960
for testing and this is the one of the more innovative things that I think this tool brings

171
00:15:38.960 --> 00:15:44.480
to the table. So the idea is that you set up everything, you execute your test, meanwhile

172
00:15:44.480 --> 00:15:50.080
the system is also collecting traces because you have enabled x-ray. And one of the things that

173
00:15:50.080 --> 00:15:56.160
you can do in your own assertions is that you can actually fetch the traces as a structured object

174
00:15:56.160 --> 00:16:02.800
and then do assertions on the traces themselves. So basically that can help you to make sure that

175
00:16:03.440 --> 00:16:07.760
the systems that you expect to be involved in that particular flow are actually being involved.

176
00:16:07.760 --> 00:16:12.960
If there is some kind of ordering that might be important for you it's also something you can use

177
00:16:12.960 --> 00:16:18.560
to do assertion and make sure systems are actually propagating messages in the correct order.

178
00:16:18.560 --> 00:16:25.680
So basically what the library allows you to do is gives you an helper function that's called

179
00:16:26.640 --> 00:16:32.560
getTraceTree and with this function you can specify a tracing header as a parameter and then

180
00:16:32.560 --> 00:16:38.240
it gives you back this object which represents the tree of traces so it's a nested structure

181
00:16:38.240 --> 00:16:42.560
where you can follow the different branches to make sure that things are happening correctly.

182
00:16:42.560 --> 00:16:47.360
Now depending of course on the complexity of your code and how many systems are involved

183
00:16:48.000 --> 00:16:53.760
you might have to write lots of code to do these assertions correctly like it's not like a plain

184
00:16:53.760 --> 00:16:58.560
array where it's easy to assert certain things you might need to traverse the tree so it might be a

185
00:16:58.560 --> 00:17:03.600
little bit tricky to test exactly what you want to test but you have the entire view of all the

186
00:17:03.600 --> 00:17:10.240
systems involved there assuming that you enable and configure x-ray correctly. Now just to give

187
00:17:10.240 --> 00:17:16.720
you examples of the kind of matching that you might be doing on the trace tree for instance

188
00:17:16.720 --> 00:17:24.240
you might check if there are errors in any segment maybe a specific system was part of this

189
00:17:24.240 --> 00:17:28.880
transaction and that system produced an error maybe it's not something you might realize

190
00:17:28.880 --> 00:17:33.920
immediately by just looking at the final result of your execution but just looking at the tree

191
00:17:33.920 --> 00:17:39.200
you might realize that some of the components was failing in some unexpected way so I think it's

192
00:17:39.200 --> 00:17:43.920
good practice to try to traverse the tree and look for this kind of things and if you didn't

193
00:17:43.920 --> 00:17:49.360
expect any error in the case you see an error maybe make the test fail and report that particular

194
00:17:49.360 --> 00:17:54.480
error. You can also check performance metrics so make sure for instance if you have requirements

195
00:17:54.480 --> 00:18:00.640
in terms of SLAs regarding response times you might produce a warning or even fail the test

196
00:18:00.640 --> 00:18:06.640
if you see that certain numbers go beyond the thresholds that you expect as acceptable and you

197
00:18:06.640 --> 00:18:13.200
can also check if specific components were actually part of the trace maybe there are

198
00:18:13.200 --> 00:18:19.360
systems that don't really expose a behavior that you can assert at the end of your test but you

199
00:18:19.360 --> 00:18:24.080
just want to make sure that they received for instance some information and somehow they were

200
00:18:24.080 --> 00:18:30.480
part of this transaction so you can just assert that they were part of the trace tree at some

201
00:18:30.480 --> 00:18:35.760
point in the tree and finally you can also do the inverse for instance you might know that there are

202
00:18:35.760 --> 00:18:41.360
only three systems for example involved so you might assert that those three systems are there

203
00:18:41.360 --> 00:18:45.200
but if by any chance you see a fourth system that's probably a symptom that you are doing

204
00:18:45.200 --> 00:18:49.280
something a little bit unexpected so maybe something else that you might want to write

205
00:18:49.280 --> 00:18:54.000
an assertion about and make sure that only the things that you expect to happen are actually

206
00:18:54.000 --> 00:18:58.960
happening and nothing else is happening in the flow. So what are the things that we were happy

207
00:18:58.960 --> 00:19:03.200
with and the things that we were disappointed with?

208
00:19:03.200 --> 00:19:07.520
I think we were curious to see this in action but when we did the testing there were a couple of issues with the x-ray approach.

209
00:19:07.520 --> 00:19:14.080
The get trace tree function you mentioned gave us an error which basically said error building trace

210
00:19:14.080 --> 00:19:19.840
tree and it said that it found a trace with a segment that had no parent which was a very

211
00:19:19.840 --> 00:19:24.640
strange one like how can how can you get a segment from x-ray with no parent so we looked into the

212
00:19:24.640 --> 00:19:29.760
raw data like in the x-ray console in cloud watch and we saw the raw data we saw the segment and we

213
00:19:29.760 --> 00:19:35.440
saw that it had a parent so we figured maybe it was like an eventual consistency kind of a problem

214
00:19:35.440 --> 00:19:40.160
that but at the time when the test was reading it maybe all of the data hadn't been fully settled

215
00:19:40.880 --> 00:19:47.760
so what we did was we filed a bug in the IADK repo and we did a workaround so there was that

216
00:19:47.760 --> 00:19:54.320
other function you mentioned that allows you to wait until a trace comes with a valid condition.

217
00:19:55.280 --> 00:20:01.120
We still had to add in a sleep in order for this to work so when we switched over to that function

218
00:20:01.120 --> 00:20:05.280
even though the documentation says you should never have to sleep in order to get it to work

219
00:20:05.280 --> 00:20:10.720
we had to get it to sleep and that would work. Now there are examples in the code of using

220
00:20:10.720 --> 00:20:15.440
sleeps with the get trace tree approach but not with the approach we eventually used so

221
00:20:16.080 --> 00:20:21.600
it seems like the documentation and the behavior aren't 100 aligned on this but luckily we were

222
00:20:21.600 --> 00:20:26.960
able to do it and we were able to get the traces in this example application we have we've got

223
00:20:26.960 --> 00:20:32.160
three kind of services we've got this kind of global bus and then we've got an order service

224
00:20:32.160 --> 00:20:37.360
and a delivery service so the flow the trace is kind of interesting it's like an event bridge to

225
00:20:37.360 --> 00:20:42.080
lambda to event bridge event bridge to lambda to event bridge three times and we were able to

226
00:20:42.080 --> 00:20:47.040
assert that that's true and we were also able to put in some performance checks like an SLA that

227
00:20:47.040 --> 00:20:52.560
all of this should take no longer than 10 seconds for example which is pretty good for exposing any

228
00:20:52.560 --> 00:20:57.280
unexpected performance degradations just in your continuous build process so I think that was quite

229
00:20:57.280 --> 00:21:02.240
a nice one. So that's we've talked about the event bridge testing approach the x-ray testing approach

230
00:21:02.240 --> 00:21:07.760
there was one other feature in IATK do you want to say something about mock events?

231
00:21:07.760 --> 00:21:12.080
Yes mock event is something else we we tried and it's an interesting feature that you have available

232
00:21:12.720 --> 00:21:19.120
and the idea is that if you're using event bridge in event bridge you can have a schema registry so

233
00:21:19.120 --> 00:21:24.880
what this library allows you to do is basically to generate a mock event starting from your own

234
00:21:24.880 --> 00:21:31.280
schema registry and then use it effectively as a source for your own tests and for instance you

235
00:21:31.280 --> 00:21:38.400
you can say I want to generate a mock event that invokes a lambda or a step function and then

236
00:21:38.400 --> 00:21:44.240
that's basically the starting point of your own test and this can be convenient for instance when

237
00:21:44.240 --> 00:21:50.000
you have maybe a very complex flow and you want to break down the testing into individual parts

238
00:21:50.000 --> 00:21:54.960
maybe you want to test one integration at the time it can make it a little bit easier to actually have

239
00:21:54.960 --> 00:22:00.720
a clear starting point where you can craft exactly the event that gives you a good test case without

240
00:22:00.720 --> 00:22:05.680
having maybe to go through a bunch of additional steps that you might have in the entire flow

241
00:22:05.680 --> 00:22:12.400
so it's basically a way to make your test case start from an event in event bridge

242
00:22:14.160 --> 00:22:18.960
I don't think this was very applicable for our own testing so we kind of had more of a look at

243
00:22:18.960 --> 00:22:23.440
the documentation and so that looks like an interesting feature when you have kind of a

244
00:22:23.440 --> 00:22:28.960
multi-step approach maybe going through different rounds of generating events on event bridge

245
00:22:28.960 --> 00:22:33.360
picking up the event from there and doing something else but yeah in our case this wasn't

246
00:22:33.360 --> 00:22:38.320
really applicable but nonetheless it's an interesting feature that you might find useful

247
00:22:38.320 --> 00:22:44.880
and it's great to have the convenience to be able to create an event not let's say from scratch but

248
00:22:44.880 --> 00:22:49.120
starting with what you have already in your schema registry which should give you a little bit of

249
00:22:49.120 --> 00:22:54.880
confidence that the event is matching what you will actually have in a production scenario

250
00:22:54.880 --> 00:23:02.480
so what are all our overall thoughts like what did we like and what we didn't like about this new tool

251
00:23:07.120 --> 00:23:13.040
on the good side I think this is a nice addition just fills a gap in tooling for integration testing there weren't a lot of options out there we had sls test tools people are rolling their

252
00:23:13.040 --> 00:23:17.920
own this is a good one it supports other languages which is a good thing I think as well once you're

253
00:23:17.920 --> 00:23:23.440
familiar with it it makes testing these pretty complex cases quite simple the fact that they

254
00:23:23.440 --> 00:23:27.280
allow you to clean up down resources easily it's very nice because that's one of the problems you'll

255
00:23:27.280 --> 00:23:33.760
face if you do this yourself and I think an advantage of that RPC approach is that we will

256
00:23:33.760 --> 00:23:37.840
have support for additional languages in the future which is promising because it'll see

257
00:23:37.840 --> 00:23:43.120
broader adoption and hopefully then more features without them having to rewrite different versions

258
00:23:43.120 --> 00:23:48.320
for different languages what about the bad do you want to be the messenger for all the bad news

259
00:23:55.520 --> 00:24:00.560
Luciano I can't bear it I can be the bearer of bad news so let's recap what we didn't like and just disclaimer this is probably due to the fact that this is a very new product it's still very early

260
00:24:00.560 --> 00:24:06.320
stage so everything we are saying here maybe it's not going to be applicable anymore in a few months

261
00:24:06.320 --> 00:24:12.160
as the product evolves and gets polished gets new feature gets bug fixes and so on so we already

262
00:24:12.160 --> 00:24:17.120
mentioned that traces didn't work the first time maybe our fault maybe we did something wrong but

263
00:24:17.120 --> 00:24:21.200
it wasn't really obvious how to do this just by looking at the documentation and copying their

264
00:24:21.200 --> 00:24:25.920
own example so definitely something to be improved either fixing bugs improving the

265
00:24:25.920 --> 00:24:31.600
documentation providing more examples and making this functionality easier to use correctly the

266
00:24:31.600 --> 00:24:38.000
other problem is that there is right now no SQS or SNS or Kinesis or Kafka support yet so really

267
00:24:38.000 --> 00:24:43.760
this is applicable today if you're using EventBridge but we know that EventBridge is not the only option

268
00:24:43.760 --> 00:24:48.960
here so depending on your architecture it might be disappointing to be able to test

269
00:24:48.960 --> 00:24:54.560
EventBridge but not to be able to test the other types of integrations documentation is there

270
00:24:54.560 --> 00:25:00.560
there is actually a website with a bunch of pages and examples but it looks like it was put together

271
00:25:00.560 --> 00:25:07.120
very quickly so it feels like there is a a lot more work to be done there for instance there is

272
00:25:07.120 --> 00:25:12.720
a section called tutorial and in that tutorial you only learn how to install the tool and then there

273
00:25:12.720 --> 00:25:17.920
is a link to some examples so I had the feeling that they want to create a more kind of fully

274
00:25:17.920 --> 00:25:22.880
fledged tutorial that walk you through all the different steps and gives you a bunch of different

275
00:25:22.880 --> 00:25:28.160
examples where every example is actually discussed what is the rationale behind the specific

276
00:25:28.160 --> 00:25:33.280
implementation for that example but right now you have to kind of fill the gaps on your own and just

277
00:25:33.280 --> 00:25:38.000
learn how to install it look at the code and the examples and figure out everything else in between

278
00:25:38.000 --> 00:25:43.360
now this is also a project that is open source so maybe if people are willing to contribute they can

279
00:25:43.360 --> 00:25:49.200
speed up the process of building this body of documentation and making the experience better

280
00:25:49.200 --> 00:25:54.480
for everyone else so that wouldn't be the first time for AWS to receive open source contribution

281
00:25:54.480 --> 00:26:00.800
and make specific tooling a little bit better so probably something where actually we have a chance

282
00:26:00.800 --> 00:26:06.480
to contribute and makes the project a little bit better the last one is on the RPC approach that we

283
00:26:06.480 --> 00:26:11.840
mentioned we like on one side because it makes this project more likely to be fully supported

284
00:26:11.840 --> 00:26:17.600
across languages in a consistent way even though today is all available for python the problem that

285
00:26:17.600 --> 00:26:23.760
we expect to see there is that with this kind of abstractions often when you have an error that

286
00:26:23.760 --> 00:26:29.200
error can be very obscure because it's just showing you for instance an issue at the python

287
00:26:29.200 --> 00:26:35.360
wrapper level but that error that you might see might be very generic and then the actual error is

288
00:26:35.360 --> 00:26:41.600
hidden in the go implementation which is abstracted away by the RPC wrapper this is something that we

289
00:26:41.600 --> 00:26:48.240
have seen for many many times i guess when when we use cdk and we see the kind of js

290
00:26:48.240 --> 00:26:53.840
ai errors appearing and it's always very hard to troubleshoot here because the design seems very

291
00:26:53.840 --> 00:26:58.960
similar we expect to have the same problem and this is maybe something that can be fixed by

292
00:26:58.960 --> 00:27:04.320
putting lots of attention in making sure that the rpc layer also propagates good errors and these

293
00:27:04.320 --> 00:27:09.280
errors are actually displayed well by all the different wrappers but nonetheless is an effort

294
00:27:09.280 --> 00:27:14.640
that ws needs to put into building the library and building the reporting tools when an exception

295
00:27:14.640 --> 00:27:19.680
happens so we expect this to be a bit of a friction point for people using the tool now again

296
00:27:19.680 --> 00:27:25.120
it's worth remarking that this project is in public preview so we don't need to be too harsh on

297
00:27:25.120 --> 00:27:30.000
judgment here i think the starting point is absolutely positive and it's great to have this

298
00:27:30.000 --> 00:27:34.320
tool so i think that the future is going to be brighter and this is going to be a valuable tool

299
00:27:40.480 --> 00:27:45.760
for people to use and write their own integration tests with in general iatk looks very promising i think and we hope to see plenty of improvements before it becomes generally available aws as we

300
00:27:45.760 --> 00:27:51.280
mentioned tends to release products early so we won't dwell further on the shortcomings if the

301
00:27:51.280 --> 00:27:57.040
concerns are addressed this should really be a valuable part of our toolkit but let us know what

302
00:27:57.040 --> 00:28:03.520
you think if you've tried it out what alternative approaches might we have missed and if there's

303
00:28:03.520 --> 00:28:09.600
some other features that you think should be added into iatk let us know and let the maintainers know

304
00:28:09.600 --> 00:28:14.320
as well. Until then, we'll see you in the next episode.
