WEBVTT

1
00:00:00.000 --> 00:00:02.960
S3 must be the most loved of all AWS services.

2
00:00:02.960 --> 00:00:06.560
It's a storage service that allows you to store files with a simple API

3
00:00:06.560 --> 00:00:10.000
and takes care of scalability, durability, security,

4
00:00:10.000 --> 00:00:13.320
and a whole bunch of other things with very little effort on the developer side.

5
00:00:13.320 --> 00:00:16.040
S3 is becoming the ubiquitous cloud storage platform

6
00:00:16.040 --> 00:00:18.400
and powers a large variety of use cases.

7
00:00:18.400 --> 00:00:20.760
And for some of these use cases, performance really matters.

8
00:00:20.760 --> 00:00:23.400
So if you're building a product that relies heavily on S3,

9
00:00:23.400 --> 00:00:26.920
there are a few interesting optimizations that you might want to leverage.

10
00:00:26.920 --> 00:00:29.680
In today's episode, we're going to talk about some of the lessons

11
00:00:29.680 --> 00:00:32.000
we've learned and some of the tips and tricks

12
00:00:32.000 --> 00:00:35.320
that we've discovered along the way working with S3 at scale.

13
00:00:35.320 --> 00:00:37.200
My name is Eoin, I'm joined by Luciano

14
00:00:37.200 --> 00:00:40.320
and this is another episode of the AWS Bites podcast.

15
00:00:48.440 --> 00:00:50.720
AWS Bites is brought to you by fourTheorem,

16
00:00:50.720 --> 00:00:54.000
an AWS consulting partner with tons of experience with S3.

17
00:00:54.000 --> 00:00:57.440
If you need someone to work with you to optimize your S3-based workloads,

18
00:00:57.440 --> 00:01:02.080
check out fourtheorem.com or contact us directly using the links in the show notes.

19
00:01:02.080 --> 00:01:05.560
We already spoke about S3 best practices back in episode 33.

20
00:01:05.560 --> 00:01:09.000
Now that was more of a generic episode on a variety of best practices

21
00:01:09.000 --> 00:01:11.960
that are relevant to using S3, but we did give a quick intro

22
00:01:11.960 --> 00:01:15.000
on what S3 is, the related terminology.

23
00:01:15.000 --> 00:01:18.040
So if you haven't checked it out, it might be a good one to go back to.

24
00:01:18.040 --> 00:01:21.480
Today though, we're going to assume you already have a little bit of basic knowledge

25
00:01:21.480 --> 00:01:25.400
about the service and how it works, and we're going to focus mostly on performance.

26
00:01:25.400 --> 00:01:29.320
But let's give a brief intro. Luciano, where would you like to start?

27
00:01:34.480 --> 00:01:39.600
I think it's a good idea to still review how S3 works under the hood, because I think understanding, at least at the high level, what's the machinery behind it,

28
00:01:39.600 --> 00:01:43.440
it's important to really understand why certain performance or activities actually work.

29
00:01:43.440 --> 00:01:46.240
So if we want to just start with some stats,

30
00:01:46.240 --> 00:01:50.400
this is something that we can just observe to understand the scale of the service.

31
00:01:50.400 --> 00:01:54.760
And this is coming from a presentation that's maybe a little bit obsolete at this point,

32
00:01:54.760 --> 00:01:58.120
because it's a presentation from reInvent that was delivered in 2021,

33
00:01:58.120 --> 00:01:59.960
called Deep Dive on Amazon S3.

34
00:01:59.960 --> 00:02:02.520
It's a really good one, so we'll leave the link in the show notes.

35
00:02:02.520 --> 00:02:06.440
But the data that they share there is that S3 stores exabytes of data.

36
00:02:06.440 --> 00:02:10.760
This is 1 billion gigabytes, I had to look that up, across millions of drives.

37
00:02:10.760 --> 00:02:16.960
So you can imagine that AWS somehow has to manage this huge amount of physical drives

38
00:02:16.960 --> 00:02:20.080
where all your data is going to be stored in a way or another.

39
00:02:20.080 --> 00:02:23.760
So this is the level of complexity that AWS is taking care of for you,

40
00:02:23.760 --> 00:02:27.280
so you don't have to worry about the kind of management of physical devices.

41
00:02:27.280 --> 00:02:32.720
Now, there are a list that's, what they say, trillions of objects stored in various S3 markets.

42
00:02:32.720 --> 00:02:38.800
So all these drives are effectively a distributed system that shares all these trillions of objects.

43
00:02:38.800 --> 00:02:42.320
And the service can handle millions of requests per second.

44
00:02:42.320 --> 00:02:47.280
So I hope that all these numbers give you an idea of the volume and the scale of the service.

45
00:02:47.280 --> 00:02:52.960
There is another one, they even say that they can reach a peak of 60 terabytes per second of data processed.

46
00:02:52.960 --> 00:02:55.680
So again, how is that magic happening?

47
00:02:55.680 --> 00:02:58.400
We don't necessarily know all the implementation details.

48
00:02:58.400 --> 00:03:04.880
But the interesting thing to know is that AWS does all of this at scale and still guarantees data durability.

49
00:03:04.880 --> 00:03:10.080
And the way they do that is by storing your data in multiple copies in different places.

50
00:03:10.080 --> 00:03:12.880
So we are obviously talking about the distributed system here,

51
00:03:12.880 --> 00:03:18.080
because it wouldn't be possible to reach this level of scalability with just one big machine, of course.

52
00:03:18.080 --> 00:03:22.240
Now, if we remember the networking basics, you know that there are regions,

53
00:03:22.240 --> 00:03:24.640
and inside regions there are availability zones.

54
00:03:24.640 --> 00:03:30.800
And you can imagine an availability zone as a separate data center with independent connectivity, power, and so on.

55
00:03:30.800 --> 00:03:35.680
So in most cases, and I say in most cases because there are certain configurations that you can tweak,

56
00:03:35.680 --> 00:03:39.840
but by default S3 stores your data across multiple availability zones.

57
00:03:39.840 --> 00:03:43.360
That basically means that as soon as you send an object to S3,

58
00:03:43.360 --> 00:03:48.160
AWS is automatically copying that object across independent availability zones.

59
00:03:48.160 --> 00:03:50.000
And then you get an acknowledge.

60
00:03:50.000 --> 00:03:55.120
That means that at that point your file is saved securely across different locations.

61
00:03:55.120 --> 00:04:00.480
Now, in all that process, at some point the data is being stored in a physical disk.

62
00:04:00.480 --> 00:04:03.360
And you can also imagine that it's stored in many of them,

63
00:04:03.360 --> 00:04:06.560
because of course if the data is living in independent locations,

64
00:04:06.560 --> 00:04:09.920
there are independent disks that are keeping different copies of your data.

65
00:04:09.920 --> 00:04:14.240
So you can imagine that managing all these disks is tricky,

66
00:04:14.240 --> 00:04:19.200
and AWS needs to really have a solid process to check for physical device failure.

67
00:04:19.200 --> 00:04:22.480
And they actually can predict when the devices fail,

68
00:04:22.480 --> 00:04:25.040
and they can actually replace them before they actually break.

69
00:04:25.040 --> 00:04:29.920
And they can do all of that without basically losing access to your data.

70
00:04:29.920 --> 00:04:35.120
So they can still do all this swapping of disks and making sure that your data is always available and durable,

71
00:04:35.120 --> 00:04:37.680
without you having any interruption of service.

72
00:04:37.680 --> 00:04:41.360
There is another cool feature that you can enable, which is called cross-region replication.

73
00:04:41.440 --> 00:04:46.800
So by default a bucket lives in one region, and the data is shared across multiple availability zones.

74
00:04:46.800 --> 00:04:51.840
But if you want extra guarantees, or maybe you want lower latency because you might have

75
00:04:51.840 --> 00:04:54.960
the necessity to access to that data from different locations around the world,

76
00:04:54.960 --> 00:04:57.760
what you can do is you can enable this cross-region replication.

77
00:04:57.760 --> 00:05:00.720
And what happens is basically for every object you create in a bucket,

78
00:05:00.720 --> 00:05:03.600
you can replicate that object in other regions as well.

79
00:05:03.600 --> 00:05:05.280
A bucket exists in other regions.

80
00:05:05.280 --> 00:05:09.600
And you can even make the data available to any location through something called

81
00:05:09.600 --> 00:05:14.560
AWS Global Accelerator. And we'll mention some around that a little bit later in this episode.

82
00:05:14.560 --> 00:05:20.320
So hopefully that gives you an understanding of the scale and the things that AWS takes care of

83
00:05:20.320 --> 00:05:25.040
for us when we use this service. So probably this is a good point now to jump to the first

84
00:05:25.040 --> 00:05:25.840
performance tip.

85
00:06:09.600 --> 00:06:15.280
... 10,000 parts and you don't even need to upload them in order. So every part is, I think,

86
00:06:15.280 --> 00:06:19.040
between the limits. It has to be between five megabytes and five gigabytes per part.

87
00:06:19.040 --> 00:06:21.920
So if you've got a three megabyte file, you wouldn't use a multi-part upload for it.

88
00:06:21.920 --> 00:06:26.880
It has to be at least five megs. And AWS generally recommend you use something like eight or 16

89
00:06:26.880 --> 00:06:31.840
megabytes for your part size. When you upload a single part, S3 will return to an entity tag,

90
00:06:31.840 --> 00:06:36.720
also known as an ETag for the part. And you record that with the part number.

91
00:06:36.720 --> 00:06:41.280
And when you do the third step in the process, which is complete multi-part upload,

92
00:06:41.280 --> 00:06:46.160
then you essentially provide a manifest of all of the part numbers and ETags with that request.

93
00:06:46.160 --> 00:06:50.480
You can even send AWS a checksum of the original file to make sure everything was transferred

94
00:06:50.480 --> 00:06:55.440
correctly. And it's not a checksum of the entire object, but rather each individual part.

95
00:06:56.080 --> 00:07:00.160
There's a link in the show notes to a user guide that will help you to understand that process.

96
00:07:00.160 --> 00:07:04.800
You generally don't have to do this yourself since most of the SDKs include some higher level

97
00:07:04.880 --> 00:07:10.880
abstraction in the API, or in the SDK for uploads and downloads, actually. But the upload part will

98
00:07:10.880 --> 00:07:15.920
generally automatically use multi-part uploads when it makes sense. And we'll provide links to

99
00:07:15.920 --> 00:07:22.960
code samples, the SDKs, including one example is the Node.js helper library, which is the lib

100
00:07:22.960 --> 00:07:28.800
storage in the AWS SDK version three. You can also do some cool esoteric things with this as well.

101
00:07:28.800 --> 00:07:33.680
I remember having a case before when we needed to essentially merge a lot of CSV files. And those

102
00:07:33.680 --> 00:07:38.480
CSV files didn't have headers in them. So we were able to do that just using S3 features. Because

103
00:07:38.480 --> 00:07:41.920
when you specify a part for a multi-part upload, it doesn't have to be something that's on your

104
00:07:41.920 --> 00:07:46.240
client machine, it can also be an existing object on S3. So you can use it just to concatenate a

105
00:07:46.240 --> 00:07:51.440
bunch of files on S3 without any of that data, leaving S3 and being transferred to your machine.

106
00:07:51.440 --> 00:07:56.720
Now, let's get on to multi-part downloads, or as it's better known, byte range fetches. So when

107
00:07:56.720 --> 00:08:02.720
you're doing a get object command, you can specify the start and end range for bytes. And if you want

108
00:08:02.720 --> 00:08:08.240
to download the entire file, it's generally not built into the SDKs. But there are examples of

109
00:08:08.240 --> 00:08:13.040
doing of implementing this yourself, we'll provide a link to that in the show notes.

110
00:08:13.040 --> 00:08:18.240
There is a very interesting podcast episode and a library associated with it from our friends at

111
00:08:18.240 --> 00:08:23.680
Cloudonaut. And they had a very specific need for one of their products to download large,

112
00:08:23.680 --> 00:08:29.280
large objects from S3 in Node.js and implemented a highly optimized library for it. So you can check

113
00:08:29.280 --> 00:08:33.200
that link out in the show notes as well. So that's tip one. Basically, use concurrency,

114
00:08:33.200 --> 00:08:38.560
do multi-part uploads and byte range fetches for downloads. What else should we suggest, Luciano?

115
00:08:38.560 --> 00:08:45.520
Another common thing is to try to spread the load across different key namespaces. And I

116
00:08:45.520 --> 00:08:50.080
think to really understand this one, we need to explain a little bit how some of the details of

117
00:08:50.080 --> 00:08:56.000
how S3 stores the object and what are some of the limits. Because if you look at the documentation,

118
00:08:56.000 --> 00:09:02.320
what the documentation says is that you can do 3500 put, copy, post, or delete operations,

119
00:09:02.320 --> 00:09:08.640
and 5500 get and head operations per prefix. And this is where things get a little bit confusing,

120
00:09:08.640 --> 00:09:14.240
because what does it mean per prefix? And if you look at other parts of the documentation,

121
00:09:14.240 --> 00:09:19.280
there is an official definition that says a prefix is a string of characters at the beginning of the

122
00:09:19.280 --> 00:09:23.920
object key name. A prefix can be of any length, subject to the maximum length of the object key

123
00:09:23.920 --> 00:09:29.280
name, which is 1204 bytes. You can think of prefixes as a way to organize your data in a

124
00:09:29.280 --> 00:09:34.240
similar way to directories. However, prefixes are not directories. So you can kind of make the

125
00:09:34.240 --> 00:09:41.600
parallel that a prefix is like saying, I don't know, "/home," "/luciano," "/documents," and then

126
00:09:41.600 --> 00:09:46.240
the name of your object. But behind the scenes, AWS is not really maintaining a file system. It's

127
00:09:46.240 --> 00:09:50.560
just a way for you to organize your data. What is interesting, though, is that somehow

128
00:09:50.560 --> 00:09:56.160
AWS is using this information to distribute the data across multiple partitions. And this is

129
00:09:56.160 --> 00:10:00.960
probably where the limit conversation comes from. You can do a certain amount of operations per

130
00:10:00.960 --> 00:10:05.200
prefix, but that probably really means per partition. And this is something that is not

131
00:10:05.200 --> 00:10:11.520
always entirely clear. What is the logic that AWS uses there to define how prefix maps to actual

132
00:10:11.520 --> 00:10:17.680
physical partitions? So it's something that AWS tries to determine automatically, depending on

133
00:10:17.680 --> 00:10:23.200
your usage patterns. But what we have seen in the wild is that if you really do lots of requests,

134
00:10:23.200 --> 00:10:28.480
even if you have different prefixes, you can still get throttled and see 503 errors.

135
00:10:28.480 --> 00:10:34.800
So it is really important if you're running at such scale to monitor the number of 503s,

136
00:10:34.800 --> 00:10:39.120
because if you're using the SDK, there are retries. So eventually you might be able to

137
00:10:39.120 --> 00:10:43.200
get your operation successfully performed. But that operation might take a long time,

138
00:10:43.200 --> 00:10:46.560
because there is a loop of retries that is happening behind the scenes. So you need to

139
00:10:46.560 --> 00:10:50.080
be aware if you're trying to get the best performance when retries are happening.

140
00:10:50.080 --> 00:10:54.640
Another interesting thing that we bumped into working with one of our customers

141
00:10:54.640 --> 00:11:00.480
is that we were still getting lots of 503s and at some point we decided to talk with support.

142
00:11:00.480 --> 00:11:06.720
And it was a long conversation. We got lots of help from AWS, but it seems to be possible to get

143
00:11:06.720 --> 00:11:11.440
AWS to tweak whatever is the internal mechanism for your specific use case. So if you're really

144
00:11:11.440 --> 00:11:14.880
hitting all these limits and you don't know what else can you do, I think the best course

145
00:11:14.880 --> 00:11:19.920
to action right now is to just open a ticket, try to talk with AWS, explain your use case.

146
00:11:19.920 --> 00:11:25.520
And I think they might be able to discuss with you very custom options that are the best solution for

147
00:11:25.520 --> 00:11:30.160
your particular use case. I think this is still very rare in the industry. We only had one use

148
00:11:30.160 --> 00:11:35.120
case, at least that I can remember on in my career. But again, if you happen to do thousands and

149
00:11:35.120 --> 00:11:39.600
thousands of requests to AWS per second, it's not unlikely that you're going to bump in this

150
00:11:39.600 --> 00:11:44.160
particular limit action. So just be aware that there are solutions, even though the solution is

151
00:11:44.160 --> 00:11:48.080
not necessarily well documented, but you can talk with AWS and they will help you to figure out the

152
00:11:48.080 --> 00:11:53.840
solution. Overall, the idea is to try to think about namespaces that make sense and then distribute

153
00:11:53.840 --> 00:11:58.880
your access, your operations to different namespaces if you want to leverage as much

154
00:11:59.520 --> 00:12:02.080
requests per second as possible. What's the next one you have, Eoin?

155
00:12:05.854 --> 00:12:07.523
The next one is going down to the network

156
00:12:07.523 --> 00:12:10.526
level. So it's a fairly common design

157
00:12:10.526 --> 00:12:12.027
pattern in networking

158
00:12:12.161 --> 00:12:14.763
and files storage to horizontally scale

159
00:12:14.763 --> 00:12:16.365
performance using multiple

160
00:12:16.365 --> 00:12:17.566
connections. So if you're making

161
00:12:17.666 --> 00:12:19.702
requests from one network device to

162
00:12:19.702 --> 00:12:21.103
another, you might bump into some

163
00:12:21.103 --> 00:12:22.271
bandwidth limits of that

164
00:12:22.271 --> 00:12:24.573
device and devices in between. So

165
00:12:24.573 --> 00:12:25.407
distributing the requests

166
00:12:25.407 --> 00:12:27.276
across multiple devices, multiple

167
00:12:27.376 --> 00:12:29.144
end-to-end connections can definitely

168
00:12:29.144 --> 00:12:30.512
help you to achieve higher

169
00:12:30.512 --> 00:12:32.848
throughput. So if an example of

170
00:12:32.848 --> 00:12:34.783
that is born out, again, going back to

171
00:12:34.783 --> 00:12:37.586
the Cloudonaut example, they realized that

172
00:12:37.586 --> 00:12:39.121
connecting to S3 from

173
00:12:39.121 --> 00:12:41.056
an EC2 instance, there's a limit of five

174
00:12:41.056 --> 00:12:43.025
gigabits per single VPC flow.

175
00:12:43.292 --> 00:12:44.393
And a VPC flow is defined as

176
00:12:44.493 --> 00:12:46.462
combination of source IP, source port,

177
00:12:46.795 --> 00:12:47.763
and then a destination IP

178
00:12:47.763 --> 00:12:49.198
and destination port. And if

179
00:12:49.198 --> 00:12:51.333
you're just doing a fairly simple HTTP

180
00:12:51.333 --> 00:12:54.036
request to an S3 endpoint, you're going

181
00:12:54.036 --> 00:12:55.237
to get a DNS lookup.

182
00:12:55.604 --> 00:12:57.773
It's going to give you back an IP or a

183
00:12:57.773 --> 00:12:58.874
set of IP addresses. Your

184
00:12:58.874 --> 00:12:59.708
client is going to pick one

185
00:12:59.908 --> 00:13:02.010
and make the connection to that IP

186
00:13:02.010 --> 00:13:02.978
address. But if you're a

187
00:13:02.978 --> 00:13:04.413
little bit smarter about it,

188
00:13:04.413 --> 00:13:07.049
you can take all of the IP addresses for

189
00:13:07.049 --> 00:13:09.251
S3 back and use that to

190
00:13:09.251 --> 00:13:10.352
get multiple connections

191
00:13:10.819 --> 00:13:12.955
from your source to the destination. And

192
00:13:12.955 --> 00:13:13.789
that's exactly what that

193
00:13:13.789 --> 00:13:15.190
clever library from Cloudonaut

194
00:13:15.357 --> 00:13:18.961
did. It's something this load balancing

195
00:13:18.961 --> 00:13:20.395
on the client is

196
00:13:20.395 --> 00:13:22.831
something that the AWS CRT,

197
00:13:22.831 --> 00:13:24.867
the Common Runtime does as well. So the

198
00:13:24.867 --> 00:13:26.935
AWS CRT library, which is

199
00:13:26.935 --> 00:13:29.304
used in the Java SDK and Boto3

200
00:13:29.304 --> 00:13:31.907
as well, has the capability to do that

201
00:13:31.907 --> 00:13:34.676
and do all this download performance

202
00:13:34.676 --> 00:13:35.978
optimization too. So

203
00:13:36.011 --> 00:13:37.679
it's worth checking out. And then as

204
00:13:37.679 --> 00:13:39.915
well, on the topic of network

205
00:13:39.915 --> 00:13:40.949
connections, different

206
00:13:40.949 --> 00:13:42.651
environments vary, different EC2

207
00:13:42.651 --> 00:13:44.520
instances have different bandwidth

208
00:13:44.520 --> 00:13:45.854
characteristics on the network

209
00:13:45.854 --> 00:13:47.456
devices. And then you have enhanced

210
00:13:47.456 --> 00:13:48.991
networking and elastic fabric

211
00:13:48.991 --> 00:13:50.692
adapter to really squeeze more

212
00:13:50.692 --> 00:13:52.261
performance out of it. Also bear in mind

213
00:13:52.261 --> 00:13:53.262
that when you're running

214
00:13:53.262 --> 00:13:54.763
an AWS Lambda, your network

215
00:13:54.763 --> 00:13:56.698
connection size depends on your memory

216
00:13:56.698 --> 00:13:59.101
configuration because it's linearly

217
00:13:59.101 --> 00:14:00.836
proportional. So if you're

218
00:14:00.836 --> 00:14:02.805
finding that bandwidth is a constraint,

219
00:14:02.805 --> 00:14:03.705
you might think about,

220
00:14:03.705 --> 00:14:05.274
"Okay, well, can I do multiple

221
00:14:05.474 --> 00:14:07.476
downloads and multiple functions or do I

222
00:14:07.476 --> 00:14:08.210
just need to up the

223
00:14:08.210 --> 00:14:10.112
memory so that I get maximum IO

224
00:14:10.112 --> 00:14:12.014
throughput on that as well?" So that's

225
00:14:12.014 --> 00:14:13.515
the lower level performance

226
00:14:13.515 --> 00:14:15.651
tips. What else do we have, Luciano?

227
00:14:15.651 --> 00:14:18.320
Another interesting one is the

228
00:14:18.320 --> 00:14:20.189
usage of the edge. Let's

229
00:14:20.189 --> 00:14:21.657
call it like that. The idea is

230
00:14:21.657 --> 00:14:23.392
that you can enable something like Amazon

231
00:14:23.392 --> 00:14:25.093
S3 transfer acceleration.

232
00:14:25.427 --> 00:14:26.862
This is more when you have

233
00:14:26.862 --> 00:14:28.730
use cases where you might, for instance,

234
00:14:28.964 --> 00:14:30.065
be building a web

235
00:14:30.065 --> 00:14:31.600
application and you might have users

236
00:14:31.934 --> 00:14:33.769
that are connecting from all around the

237
00:14:33.769 --> 00:14:35.170
globe. And of course, if you

238
00:14:35.170 --> 00:14:37.906
store your data in a bucket

239
00:14:37.906 --> 00:14:40.375
that exists only one region, you might

240
00:14:40.375 --> 00:14:42.177
have good latency for all

241
00:14:42.177 --> 00:14:43.345
the users that are close to the

242
00:14:43.345 --> 00:14:45.247
region and very poor latency for all the

243
00:14:45.247 --> 00:14:46.048
other users that may be

244
00:14:46.048 --> 00:14:47.416
very far away from the region.

245
00:14:47.683 --> 00:14:48.884
So one way that you can solve this

246
00:14:48.884 --> 00:14:50.085
particular problem and give

247
00:14:50.085 --> 00:14:52.454
more or less similar performance

248
00:14:52.454 --> 00:14:54.189
to all the users, regardless of where

249
00:14:54.189 --> 00:14:55.557
they are around the globe, is

250
00:14:55.557 --> 00:14:56.758
to enable this feature called

251
00:14:56.925 --> 00:14:58.827
transfer acceleration. And there are some

252
00:14:58.827 --> 00:15:00.195
data that AWS shares in

253
00:15:00.195 --> 00:15:01.163
their marketing page where

254
00:15:01.230 --> 00:15:03.298
they say that this can improve as much as

255
00:15:03.298 --> 00:15:06.134
between 50 and 500% performance for

256
00:15:06.134 --> 00:15:07.169
long-distance transfer

257
00:15:07.169 --> 00:15:09.404
of large objects. So that means, imagine

258
00:15:09.404 --> 00:15:12.307
that you have a bucket somewhere in

259
00:15:12.307 --> 00:15:13.475
Europe and a user from

260
00:15:13.609 --> 00:15:15.410
Australia is connected to that bucket.

261
00:15:15.644 --> 00:15:16.511
You can imagine that there

262
00:15:16.511 --> 00:15:17.512
is by default significant

263
00:15:17.679 --> 00:15:19.314
latency, but enabling this kind of

264
00:15:19.314 --> 00:15:20.849
feature will reduce that latency

265
00:15:20.849 --> 00:15:22.384
significantly. And this is

266
00:15:22.384 --> 00:15:23.719
a feature that you need to enable

267
00:15:23.719 --> 00:15:25.220
because, of course, there is a

268
00:15:25.220 --> 00:15:26.555
significant complexity to

269
00:15:27.189 --> 00:15:29.324
make all of this happen for you. Data is

270
00:15:29.324 --> 00:15:30.325
replicated effectively

271
00:15:30.325 --> 00:15:31.393
around the globe for you.

272
00:15:31.793 --> 00:15:33.629
So it's something that you enable it and

273
00:15:33.629 --> 00:15:35.163
you need to be aware that you pay a

274
00:15:35.163 --> 00:15:36.198
premium price for it.

275
00:15:36.198 --> 00:15:37.966
So it's not a free feature. So of course,

276
00:15:37.966 --> 00:15:38.901
it makes sense to use it

277
00:15:38.901 --> 00:15:40.168
only when you really have that

278
00:15:40.168 --> 00:15:42.170
particular type of use case, not just

279
00:15:42.170 --> 00:15:43.472
enable it because it might

280
00:15:43.472 --> 00:15:44.840
seem like a convenient thing to

281
00:15:44.840 --> 00:15:47.276
do. And if you know CloudFront, this

282
00:15:47.276 --> 00:15:49.177
feature is effectively leveraging

283
00:15:49.177 --> 00:15:50.712
CloudFront under the hood

284
00:15:50.812 --> 00:15:52.948
and is just distributing the data across

285
00:15:52.948 --> 00:15:55.050
different edge locations and then using

286
00:15:55.751 --> 00:15:58.287
the AWS Packable Networks to make sure

287
00:15:58.287 --> 00:15:59.688
that the connection between

288
00:15:59.688 --> 00:16:01.723
your actual region and the edge

289
00:16:01.723 --> 00:16:04.159
location is as fast as it could be. This

290
00:16:04.159 --> 00:16:04.927
is a feature that you need

291
00:16:04.927 --> 00:16:06.328
to enable at the bucket level.

292
00:16:06.662 --> 00:16:09.498
So you just go to the bucket setting and

293
00:16:09.498 --> 00:16:10.532
you can enable it there

294
00:16:10.532 --> 00:16:12.901
either from the UI or with the CLI.

295
00:16:13.569 --> 00:16:15.971
And effectively, then when you want to

296
00:16:15.971 --> 00:16:18.674
download a file from S3

297
00:16:18.674 --> 00:16:19.741
using this particular feature,

298
00:16:19.875 --> 00:16:21.843
you have to specify a special endpoint

299
00:16:21.843 --> 00:16:22.678
that is called

300
00:16:22.678 --> 00:16:26.982
https://s3-accelerate.amazonaws.com

301
00:16:26.982 --> 00:16:28.684
So that basically, rather than going

302
00:16:28.684 --> 00:16:30.485
directly through the bucket endpoint,

303
00:16:30.819 --> 00:16:32.087
is going to go through this special

304
00:16:32.087 --> 00:16:34.189
endpoint that uses the Edge Network.

305
00:16:34.489 --> 00:16:36.291
Now we can give you a lot more details,

306
00:16:36.291 --> 00:16:37.626
but it's probably going to be more useful

307
00:16:37.759 --> 00:16:39.494
for you to redirect to the documentation

308
00:16:39.494 --> 00:16:40.796
page. We have a link in the

309
00:16:40.796 --> 00:16:41.830
show notes if we're curious

310
00:16:41.830 --> 00:16:43.498
to really find out how do you really

311
00:16:43.498 --> 00:16:45.167
enable this and kind of how

312
00:16:45.167 --> 00:16:46.468
to with all the steps that you

313
00:16:46.501 --> 00:16:47.936
need to follow if you really want to

314
00:16:47.936 --> 00:16:49.471
implement this particular feature.

315
00:16:49.805 --> 00:16:52.307
And the other option is if you are just

316
00:16:52.307 --> 00:16:53.375
building a website, for

317
00:16:53.375 --> 00:16:54.810
instance, and you want to make sure

318
00:16:54.810 --> 00:16:56.712
that all the static assets of that

319
00:16:56.712 --> 00:16:58.480
website are available in the edge

320
00:16:58.480 --> 00:17:00.148
locations, you can use

321
00:17:00.148 --> 00:17:03.652
CloudFront directly. So you just enable a

322
00:17:03.652 --> 00:17:04.586
CloudFront distribution.

323
00:17:04.886 --> 00:17:06.388
CloudFront is effectively a CDN.

324
00:17:06.755 --> 00:17:08.824
So that will make your object available

325
00:17:08.824 --> 00:17:10.892
in different locations

326
00:17:10.892 --> 00:17:11.893
around the world. AWS

327
00:17:11.927 --> 00:17:13.929
claims that they have about 400 edge

328
00:17:13.929 --> 00:17:15.197
locations. So this is

329
00:17:15.197 --> 00:17:16.131
probably going to have a good

330
00:17:16.164 --> 00:17:18.333
coverage for all around the globe. And

331
00:17:18.333 --> 00:17:19.534
yeah, if you're doing all

332
00:17:19.534 --> 00:17:20.402
of that, there is another

333
00:17:20.402 --> 00:17:22.371
extra advantage because at that point you

334
00:17:22.371 --> 00:17:23.205
are serving an entire

335
00:17:23.205 --> 00:17:24.973
website from an S3 bucket.

336
00:17:25.240 --> 00:17:28.310
But if you just enable the S3 website

337
00:17:28.310 --> 00:17:29.945
feature, that by default is

338
00:17:29.945 --> 00:17:31.913
only HTTP, which is not really

339
00:17:31.913 --> 00:17:33.749
ideal these days. You probably want to

340
00:17:33.749 --> 00:17:36.018
have HTTPS. When you use CloudFront, you

341
00:17:36.018 --> 00:17:37.252
also get support for

342
00:17:37.252 --> 00:17:39.554
HTTPS. So that's one more reason to use

343
00:17:39.554 --> 00:17:40.889
CloudFront when you are

344
00:17:40.889 --> 00:17:42.391
serving just static assets for a

345
00:17:42.391 --> 00:17:44.760
website. That I think concludes this tip.

346
00:17:45.093 --> 00:17:46.028
So what do we have next?

347
00:17:46.328 --> 00:17:48.230
The next one and final one is a bit neat

348
00:17:48.230 --> 00:17:49.898
maybe, but if your

349
00:17:49.898 --> 00:17:52.267
application relates to tabular data,

350
00:17:52.267 --> 00:17:54.803
like analytics or data science, you can

351
00:17:54.803 --> 00:17:55.871
leverage some of the

352
00:17:55.871 --> 00:17:57.305
great tools that optimize data

353
00:17:57.305 --> 00:17:59.508
retrieval from S3 for you to avoid

354
00:17:59.508 --> 00:18:01.510
reading data that you don't need. And

355
00:18:01.510 --> 00:18:02.577
this goes back to our

356
00:18:02.577 --> 00:18:04.746
byte range fetch really, but it's also

357
00:18:04.746 --> 00:18:06.515
saying some of the tools are already

358
00:18:06.515 --> 00:18:07.349
doing this for you on

359
00:18:07.349 --> 00:18:08.684
the hood and you don't even really need

360
00:18:08.684 --> 00:18:10.318
to think about how it works. And the

361
00:18:10.318 --> 00:18:11.186
simplest one of all is

362
00:18:11.219 --> 00:18:13.789
S3 Select. This is an S3 API. It's

363
00:18:13.789 --> 00:18:15.257
available in all the SDKs

364
00:18:15.257 --> 00:18:16.992
and in the console. And it's

365
00:18:17.225 --> 00:18:18.593
pretty straightforward. It allows you to

366
00:18:18.593 --> 00:18:19.928
retrieve specific rows and

367
00:18:19.928 --> 00:18:21.830
columns of data from S3 using

368
00:18:21.830 --> 00:18:24.833
a simple SQL-like syntax. So you could do

369
00:18:24.833 --> 00:18:26.635
select columns from table,

370
00:18:26.902 --> 00:18:28.070
where, and put some simple

371
00:18:28.070 --> 00:18:29.304
where clause. There's no joins or

372
00:18:29.304 --> 00:18:30.205
anything complicated like

373
00:18:30.205 --> 00:18:31.073
that in it. It's just for

374
00:18:31.073 --> 00:18:32.674
a single table. And that avoids you

375
00:18:32.674 --> 00:18:33.775
having to retrieve large

376
00:18:33.775 --> 00:18:35.110
volumes of data over the network

377
00:18:35.277 --> 00:18:37.112
and you push the heavy lifting onto S3.

378
00:18:37.379 --> 00:18:37.779
Now, if you're doing

379
00:18:37.779 --> 00:18:38.613
something a bit more complicated

380
00:18:38.814 --> 00:18:41.216
and you're in this space, you might be

381
00:18:41.216 --> 00:18:42.250
familiar with the arrow,

382
00:18:42.451 --> 00:18:43.685
which is core to a lot of these

383
00:18:43.685 --> 00:18:45.454
data science tools, the arrow library and

384
00:18:45.454 --> 00:18:47.055
format tools built on top

385
00:18:47.055 --> 00:18:48.690
of it, like pandas and polars

386
00:18:48.690 --> 00:18:51.793
and DuckDB. These all ensure you don't

387
00:18:51.793 --> 00:18:52.561
have to read all of the

388
00:18:52.561 --> 00:18:53.829
data if you don't need it,

389
00:18:53.829 --> 00:18:55.764
particularly if you're using optimized

390
00:18:55.764 --> 00:18:57.532
column number formats like

391
00:18:57.532 --> 00:18:59.101
Parquet. All of these tools

392
00:18:59.101 --> 00:19:01.636
can intelligently like with Parquet file,

393
00:19:01.636 --> 00:19:02.504
for example, the

394
00:19:02.504 --> 00:19:03.872
metadata describing what data is

395
00:19:03.872 --> 00:19:05.607
in it is at the bottom of it. So those

396
00:19:05.607 --> 00:19:06.942
tools will go read the

397
00:19:06.942 --> 00:19:08.310
footer from the Parquet file,

398
00:19:08.510 --> 00:19:09.611
then they can figure out where the

399
00:19:09.611 --> 00:19:10.479
columns are stored in the

400
00:19:10.479 --> 00:19:12.380
file and where the row groups are

401
00:19:12.414 --> 00:19:14.316
that's split into groups. And then they

402
00:19:14.316 --> 00:19:15.317
can retrieve only the

403
00:19:15.317 --> 00:19:16.818
data you need. Polars and

404
00:19:16.818 --> 00:19:19.454
DuckDB are particularly fast when it

405
00:19:19.454 --> 00:19:20.388
comes to this kind of use

406
00:19:20.388 --> 00:19:21.723
case. They'll leverage those

407
00:19:21.723 --> 00:19:23.825
byte range queries automatically for you

408
00:19:23.825 --> 00:19:26.094
and are surprisingly fast

409
00:19:26.094 --> 00:19:27.596
in how they can run and are

410
00:19:27.596 --> 00:19:29.131
already putting a lot of engineering

411
00:19:29.131 --> 00:19:30.732
effort into optimizing things

412
00:19:30.732 --> 00:19:32.400
like object retrieval from S3.

413
00:19:32.667 --> 00:19:34.436
So you don't even have to think about it.

414
00:19:34.703 --> 00:19:35.437
So in terms of additional

415
00:19:35.437 --> 00:19:36.471
resources, we're going to

416
00:19:36.471 --> 00:19:38.173
throw a bunch of links in the show notes,

417
00:19:38.173 --> 00:19:39.307
which we hope are valuable,

418
00:19:39.641 --> 00:19:40.775
including some performance

419
00:19:40.775 --> 00:19:43.145
guidelines on S3 and design patterns.

420
00:19:43.445 --> 00:19:45.046
Apart from that, let us know if you have

421
00:19:45.046 --> 00:19:46.047
any more S3 performance

422
00:19:46.148 --> 00:19:47.682
tips. I'm sure there's more out there.

423
00:19:47.883 --> 00:19:48.583
Just let us know in the

424
00:19:48.583 --> 00:19:49.784
comments. Thanks very much for

425
00:19:49.784 --> 00:19:51.887
joining us this time, and we'll see you

426
00:19:51.887 --> 00:19:52.888
in the next episode.
