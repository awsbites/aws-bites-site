WEBVTT

1
00:00:00.640 --> 00:00:04.800
Did AWS just build an IDE to rival your favorite code editor?

2
00:00:04.800 --> 00:00:05.760
Yes, they did.

3
00:00:05.760 --> 00:00:10.800
Meet Kiro, an AI-centric take on VS Code that promises to turn an empty repo and a bunch

4
00:00:10.800 --> 00:00:15.920
of loose ideas into working code with an approach that they call specification-driven design.

5
00:00:15.920 --> 00:00:21.360
It imports your VS Code configuration so you can start fast, and then it guides you to creating

6
00:00:21.360 --> 00:00:26.400
requirements, design documents, and a clear task plan before you get your agents to work.

7
00:00:26.400 --> 00:00:31.440
We tried Kiro on a real project, and today we will share what clicked, what tripped us up,

8
00:00:31.440 --> 00:00:36.480
and what's unique about Kiro. We will also look at pricing, limits, and where it fits among tools

9
00:00:36.480 --> 00:00:41.520
like Cursor or Cloud Code. So stick around until the end because we will share what we believe the

10
00:00:41.520 --> 00:00:46.960
future of Kiro could be and whether you should switch to Kiro or look for something else instead.

11
00:00:46.960 --> 00:00:51.360
My name is Luciano and I'm here with Eoin for another episode of AWS Bites Podcast.

12
00:00:56.400 --> 00:01:04.000
This episode is brought to you by fourTheorem. Stay tuned for more details about Forteorem at the end

13
00:01:04.000 --> 00:01:09.120
of this episode. So Eoin, maybe we can get started by giving a little bit more detail about what Kiro is.

14
00:01:09.120 --> 00:01:15.200
Yeah, so Kiro is an AI-centric IDE developed by AWS.

15
00:01:15.200 --> 00:01:20.480
I don't think a lot of people saw this coming, but a few weeks ago there was a lot of hype about it for a very short period. You'll find all the info

16
00:01:20.480 --> 00:01:26.720
on Kiro.dev. It's got a dedicated site and like many other tools of its kind, it's a fork of VS Code.

17
00:01:26.720 --> 00:01:33.360
So similar to Cursor or Windsurf. And that makes it easy to move from VS Code to Kiro because it'll

18
00:01:33.360 --> 00:01:38.560
import all of your settings, including themes, plugins, and config. And one of its top features

19
00:01:38.560 --> 00:01:46.320
is that it offers an agentic workflow. So unlike just single prompt iteration like you might do in

20
00:01:46.320 --> 00:01:53.200
Copilot before or in ChatGPT, you can describe in plain English what you want and it will try to

21
00:01:53.200 --> 00:01:59.520
achieve the given outcome. So it can read and edit files, run commands, search information online,

22
00:01:59.520 --> 00:02:04.640
and more. And it basically runs then in a loop trying to achieve the given goal. So as an example,

23
00:02:04.640 --> 00:02:11.360
you can tell it to run tests to make sure the changes it makes don't break anything. If the tests fail,

24
00:02:11.360 --> 00:02:15.600
it can read the output of the tests and then try to iterate and fix the issue until it reaches a stable

25
00:02:15.600 --> 00:02:19.920
state. And you can also turn it into a more interactive collaborator. So you can tell it

26
00:02:19.920 --> 00:02:25.280
to ask clarifying questions or to request more context if it needs. And you can also tell it to

27
00:02:25.280 --> 00:02:30.080
come up with a plan and request user validation before executing it. So it's a lot more collaborative

28
00:02:30.080 --> 00:02:35.280
than previous tools of its kind. So Luciano, what do you think? What can Kiro do for you?

29
00:02:35.280 --> 00:02:40.960
Yeah, I think it's fair to try to provide some example use cases.

30
00:02:40.960 --> 00:02:45.520
One that I really like is when you are starting on a project that has been created by maybe a team that you just joined. So you don't really

31
00:02:45.520 --> 00:02:50.480
have a lot of context. You can just open Kiro, open the project and ask it to explain the structure

32
00:02:50.480 --> 00:02:54.560
of the existing code base. And I think that's a really useful feature to just get you started

33
00:02:54.560 --> 00:02:58.960
quickly and do all of the onboarding stuff. And similarly, if you need to generate some

34
00:02:58.960 --> 00:03:03.120
documentation or improve existing documentation, that's another excellent use case. You can just

35
00:03:03.120 --> 00:03:08.400
add Kiro, like maybe read that some files and update the docs. And generally, this is the kind of

36
00:03:08.400 --> 00:03:14.720
tasks where these tools really shine. And another use case is totally when you start from scratch,

37
00:03:14.720 --> 00:03:20.160
and you literally have a blank slate, and you want to start creating a new project quickly on a prototype.

38
00:03:20.160 --> 00:03:24.560
Kiro actually can help you with that. And we'll talk more about an example that we played with.

39
00:03:25.360 --> 00:03:30.800
Or even you can work on features or fixes on existing projects. So if you've used Courser,

40
00:03:30.800 --> 00:03:36.320
Windsurf, Copilot Agent Mode, Cloud Code, Open Code, Cline (or Cline) for VS Code,

41
00:03:36.320 --> 00:03:41.520
or any other of these AI-agentic tools, the experience is exactly the same. It's just that

42
00:03:41.520 --> 00:03:47.120
this is the product that AWS is building and promoting. So it's a more AWS-centric take on

43
00:03:47.120 --> 00:03:53.200
this kind of products. So one thing where I think Kiro is trying to innovate a little bit more than all of

44
00:03:53.200 --> 00:03:59.120
the competitors is what they call the spec-driven approach or specification-driven approach. And

45
00:03:59.120 --> 00:04:03.760
we'll talk a little bit more about that later. But I think it's fair at this point to mention what is

46
00:04:03.760 --> 00:04:06.240
the current status of this project since it's very new.

47
00:04:11.680 --> 00:04:17.120
Well, it was launched back in early July with an open beta and quickly moved into a closed beta with a waitlist. And we were both lucky enough to get in early. It currently supports Claude Sonnet

48
00:04:17.120 --> 00:04:26.560
models 4 and 3.7. And during the beta access, the model access was totally free. And this is a big draw

49
00:04:26.560 --> 00:04:31.040
for a lot of people because it was completely unlimited. And that's very rare these days to get access to a

50
00:04:31.040 --> 00:04:34.960
powerful model like that for free. And possibly one of the reasons why everyone was so excited to

51
00:04:34.960 --> 00:04:39.840
try it. Of course, in reality, there are limits. We haven't used it enough to hit those limits.

52
00:04:39.840 --> 00:04:44.400
We'll get into that in a sec, but it seems that a lot of people in the AWS community have reported

53
00:04:44.400 --> 00:04:48.800
that these limits are very stringent and they make it hard to really evaluate the tool. Of course,

54
00:04:48.800 --> 00:04:53.440
these limits are going to change once Kiro is out of beta and becomes a paid product like Cursor and

55
00:04:53.440 --> 00:05:00.320
the others. So let's get into all of that pricing discussion later. But one of the big differences

56
00:05:00.320 --> 00:05:05.840
with Kiro is the vibe versus spec model. Luciano, do you want to go into that?

57
00:05:05.840 --> 00:05:10.000
Luciano you might go into that.

58
00:05:10.000 --> 00:05:15.360
Yes, so as I say, this is probably the most innovating piece of Kiro, this spec-driven development. And I think to really appreciate what that means, we need to say that

59
00:05:15.360 --> 00:05:21.360
AI-driven development is all about context. And we can define context as basically the combination of

60
00:05:21.360 --> 00:05:26.400
a specific prompt that you are giving to the agent with somewhat clear instructions and expected

61
00:05:26.400 --> 00:05:31.120
outcomes, plus everything that you have in your project. So basically you are giving the agent

62
00:05:31.120 --> 00:05:37.280
access to additional information like local files, or maybe other documents that you can provide in

63
00:05:37.280 --> 00:05:43.920
some other way. Sometimes can be even diagrams, pictures, because all these models support not just

64
00:05:43.920 --> 00:05:49.280
text, but they can also read images and audio and so on. So all of that together is basically something

65
00:05:49.280 --> 00:05:55.520
we can define as context. And context also can be enriched even more if you use tools like MCP servers,

66
00:05:55.520 --> 00:06:00.240
but we're not going to deep dive too much into that. Just keep in mind that that's yet another thing

67
00:06:00.240 --> 00:06:05.840
that you can use to basically provide even more information to your AI agents. So effectively,

68
00:06:05.840 --> 00:06:10.640
the idea is very simple. The more context and the more details you can provide about your projects and

69
00:06:10.640 --> 00:06:15.040
the features that you're trying to build, the more likely is that the agent is going to do a good job,

70
00:06:15.040 --> 00:06:20.560
and you end up with a result of an acceptable quality. And if we think about that, to be honest,

71
00:06:20.560 --> 00:06:26.720
humans work more or less the same way, right? If you are working with a colleague and you can provide

72
00:06:26.720 --> 00:06:32.880
very clear details and requirements, chances are that at the end you end up with a much more fruitful

73
00:06:32.880 --> 00:06:39.520
collaboration. If you just give very loose specs, so to speak, then your management might vary, right?

74
00:06:39.520 --> 00:06:43.520
You don't know what your colleague is going to come up with because they need to make a lot of

75
00:06:43.520 --> 00:06:49.200
assumptions and you might not be happy with some of these assumptions. So the main question in general,

76
00:06:49.200 --> 00:06:53.200
and this is a question that goes even beyond here, I think it's in the industry at this stage with all

77
00:06:53.200 --> 00:06:59.840
these new AI agentic tools is how do you provide good context to an AI model?

78
00:06:59.840 --> 00:07:04.800
It's still not a perfect science and the industry and everyone is still trying to figure out the best practices. I suppose every one

79
00:07:04.800 --> 00:07:10.160
of these agentic AI tools gives you ways to enrich your prompts with extra context, but they all

80
00:07:10.160 --> 00:07:15.680
tend to be very loose and it's still not ideal. Kiro differentiates itself a bit with a very

81
00:07:15.680 --> 00:07:21.440
structured and prescriptive approach, which is what they call spec-driven AI coding. And this is

82
00:07:22.000 --> 00:07:27.440
especially useful when you're starting a new project or feature work from scratch and you want to give it

83
00:07:27.440 --> 00:07:32.800
a bit more structure. So you start by giving Kiro a loose prompt with a high level idea of your goal.

84
00:07:32.800 --> 00:07:36.320
Then Kiro will guide you through the process of creating this specification.

85
00:07:36.960 --> 00:07:40.880
And the spec is ultimately a collection of three documents that are useful to describe what you

86
00:07:40.880 --> 00:07:45.920
want the agent to achieve. And they can also serve as human readable documentation too, which is no bad

87
00:07:45.920 --> 00:07:50.880
thing. So what are these three documents?

88
00:07:50.880 --> 00:07:56.000
Yeah, the first file that Kiro generates for you when you just provide a very loose prompt and we'll give you an example, a full example later on is called

89
00:07:56.000 --> 00:08:02.400
requirements.md. So it's a markdown file and it will contain an eye level introduction and a list of user

90
00:08:02.400 --> 00:08:08.080
stories with requirements. And there is actually a very specific format to the way that these stories

91
00:08:08.080 --> 00:08:14.240
are defined. And what I really like to see is that there is a clear acceptance criteria. So there is

92
00:08:14.240 --> 00:08:18.960
this structured way of saying when something happens, then something else needs to be done.

93
00:08:18.960 --> 00:08:24.960
And you can see all these user stories written following this structure. So in a way, I like to think

94
00:08:24.960 --> 00:08:29.440
about this document as if you're working with a product manager that doesn't necessarily have lots of

95
00:08:29.440 --> 00:08:33.520
technical depth, but they can understand the product and tell you what the product needs to do

96
00:08:33.520 --> 00:08:39.280
on different features or things that are happening when users interact with the product. So when you

97
00:08:40.640 --> 00:08:45.760
when you get this document from Kiro, of course, this document is a sort of a collaboration if you

98
00:08:45.760 --> 00:08:51.120
want. So Kiro gives you a first draft and then you can update it yourself manually or you can give Kiro

99
00:08:51.120 --> 00:08:55.920
extra prompts for things that you wanted to improve on. And then when you are happy with it, you can

100
00:08:55.920 --> 00:09:01.360
effectively move on to the next phase. And Kiro is going to take your requirements.md file as an input

101
00:09:01.360 --> 00:09:08.000
and use it to generate a design.md. And the design.md is a more technical document because it contains

102
00:09:08.000 --> 00:09:13.920
things like an architecture section and it can even create diagrams in mermaid format. So you can actually

103
00:09:13.920 --> 00:09:18.880
visualize those diagrams and again, iterate on them until you feel that this is really what you want to achieve.

104
00:09:18.880 --> 00:09:24.320
But it goes deeper because for every component in your diagram, there is a component architecture.

105
00:09:24.320 --> 00:09:30.320
And for that means that for each one of these components, you'll need to work with Kiro to provide

106
00:09:30.320 --> 00:09:34.720
details like what is the purpose of this component? What are the inputs that are expected for this

107
00:09:34.720 --> 00:09:41.040
component? What kind of outputs is going to produce? And if even key methods, so for instance, Kiro is going

108
00:09:41.040 --> 00:09:46.000
to try to infer from your project what kind of programming language you want to use, or you can also tell it

109
00:09:46.000 --> 00:09:51.120
explicitly. And it's going to start to generate at this point some sketches for key methods. And this

110
00:09:51.120 --> 00:09:56.400
is actually signatures of function or classes and methods telling, okay, for this component, this is

111
00:09:56.400 --> 00:10:01.200
what I expect to generate in terms of code. It doesn't generate all the code, but just the signatures of

112
00:10:01.200 --> 00:10:06.400
the name, the inputs, the outputs, which is generally good enough to really understand what is the purpose of

113
00:10:06.400 --> 00:10:11.520
that component. Then there is an entire section dedicated to data models. So very similar to components.

114
00:10:11.520 --> 00:10:16.800
It provides details also generates some snippets of code, just to tell you these are the attributes,

115
00:10:16.800 --> 00:10:21.600
for example, that I expect to have for each of the different data models. And finally, there are

116
00:10:21.600 --> 00:10:26.960
other sections like error handling. So how do you want to handle errors? Do you want to just crash or

117
00:10:26.960 --> 00:10:31.280
have a more graceful fallback? How do you want to log these errors? How do you want to display them to the

118
00:10:31.280 --> 00:10:37.680
users? Even testing strategy. So do you want to do unit tests, integration tests, even test the data models,

119
00:10:37.680 --> 00:10:43.040
or which tools and libraries do you want to use for those? And deployment strategies as well. So of

120
00:10:43.040 --> 00:10:48.320
course, if you use Kiro, chances are you're using AWS and serverless. And this was our example as well.

121
00:10:48.320 --> 00:10:54.240
So in that case, Kiro will start to ask you, okay, you are working with lambdas. What kind of

122
00:10:54.240 --> 00:10:59.200
configuration do you expect in terms of memory? What is the trigger for that lambda? Are there specific

123
00:10:59.200 --> 00:11:04.960
code dependencies that I need to keep in mind? And even performance expectations. So this is really a very

124
00:11:04.960 --> 00:11:09.440
technical document. And I imagine like you are sitting down with a CTO or a team lead,

125
00:11:09.440 --> 00:11:14.000
or somebody that's very technical in your team, and you have to work together to come up with all

126
00:11:14.000 --> 00:11:18.800
these details. And again, this is another step in the process, very interactive. When you are happy with

127
00:11:18.800 --> 00:11:23.760
it, you can click to go to the next step. And in the next step, all that you have created so far

128
00:11:23.760 --> 00:11:30.480
becomes input for the new step, which is called tasks.md. So this is a new file that effectively is

129
00:11:30.480 --> 00:11:34.320
almost again, like you are bouncing the ball back to the product manager and saying, okay, now we have

130
00:11:34.320 --> 00:11:39.440
a very clear idea of what we need to build, how we need to build it. We just need to break it down

131
00:11:39.440 --> 00:11:44.720
into manageable tasks. So effectively, Kiro generates a to-do list with some details referencing

132
00:11:44.720 --> 00:11:49.840
the other documents. And then for each item in this to-do list, it's almost like a checkbox.

133
00:11:49.840 --> 00:11:56.000
So you will have an interactive button there close to every item saying, start to work on this task.

134
00:11:56.000 --> 00:12:00.480
And this is where you start to run the other individual tasks to the agent to effectively come up

135
00:12:00.480 --> 00:12:05.280
with the implementation for them. Okay.

136
00:12:05.280 --> 00:12:09.440
So I guess it's worth noting that all of these documents are created in order and you can tweak them manually, or you could use more prompting to get

137
00:12:09.440 --> 00:12:14.240
Kiro to do it for you before you move to the next one. So that makes it feel like it is quite a

138
00:12:14.240 --> 00:12:19.360
structured guided process and you have control over it, but you don't have to do all the work yourself.

139
00:12:19.360 --> 00:12:22.640
And what we do like is that if you don't have a lot of clarity on what you want to build,

140
00:12:22.640 --> 00:12:27.440
this process helps you to kind of brainstorm it and rubber duck it with the agent and helps you to come up

141
00:12:27.440 --> 00:12:31.760
with a better picture before you move on to the implementation. This process alone has a lot of

142
00:12:31.760 --> 00:12:36.400
value. And I say that, you know, all of these AI code tools are great, but the biggest challenge in

143
00:12:36.400 --> 00:12:41.200
software is actually understanding what you're trying to build, communicating it well, understanding

144
00:12:41.200 --> 00:12:46.080
the needs of the users and really getting that into a specification. Because once you have that clarity,

145
00:12:46.080 --> 00:12:51.200
writing software is always easier anyway, whether you're using AI or not. It is interesting to see

146
00:12:51.200 --> 00:12:57.360
that Kiro makes this clear difference between vibe and spec, where vibe, which often for a very

147
00:12:57.360 --> 00:13:01.520
good reason gets a negative connotation is intended as like, just work off a single prompt and figure

148
00:13:01.520 --> 00:13:05.920
it out yourself. Spec is more on the line of, let me give you all the details and the structured format

149
00:13:05.920 --> 00:13:10.000
we just described and let's come up with an implementation plan. Now you can still do the

150
00:13:10.000 --> 00:13:14.240
vibe mode in Kiro. You can pick the approach that feels most appropriate for what you want to do.

151
00:13:14.960 --> 00:13:19.200
If you just want to update a readme file or do something very throwaway, you can probably just vibe it.

152
00:13:19.760 --> 00:13:24.640
But if you're working on something like a complex new feature, it makes sense to probably go with

153
00:13:24.640 --> 00:13:30.640
a spec-driven approach. Luciano, you were able to put this into practice with some real-world needs,

154
00:13:31.200 --> 00:13:33.360
which is what it's supposed to be designed for. So how did it go?

155
00:13:37.600 --> 00:13:41.920
Yeah, I'm going to try to describe the use case that I was trying to work with first, because it requires a little bit of context, but it's actually a real need. So it's a realistic idea,

156
00:13:41.920 --> 00:13:47.840
which hopefully helps to appreciate Kiro a bit more. So the problem that I was trying to work with is,

157
00:13:47.840 --> 00:13:54.560
I don't know if people here ever try to share a product URL from an eCommerce like Amazon. So let's say,

158
00:13:54.560 --> 00:14:00.160
a book, for example, and you want to have some easy way to give people a URL, and they should just

159
00:14:00.160 --> 00:14:05.200
be able to see the book and buy it if they like it. But with Amazon specifically, there is a problem,

160
00:14:05.200 --> 00:14:10.640
because Amazon is not just one single eCommerce globally, but there are 20, probably even more

161
00:14:10.640 --> 00:14:16.240
than 20 stores. There is like the United States one, Australia, UK, Italy, Ireland, Turkey, etc.

162
00:14:16.240 --> 00:14:21.520
And each one of them has its own domain, for example, amazon.com, amazon.it, amazon.ie, etc.

163
00:14:22.080 --> 00:14:27.680
So if you want to link a product, you suddenly have a problem because you don't necessarily know

164
00:14:27.680 --> 00:14:32.960
the country that is going to be best for whoever is going to click the link. So the option, the most

165
00:14:32.960 --> 00:14:38.480
complete option realistically that you have is to create 20 plus URLs, one for each existing domain,

166
00:14:38.480 --> 00:14:43.120
and just put them somewhere in a page and then hope that the user is going to find and click the right

167
00:14:43.120 --> 00:14:49.680
one. So my idea was, okay, why don't we create a service, like a Lambda, for example, an HTTP Lambda,

168
00:14:49.680 --> 00:14:55.600
that acts as a single entry point, it figures out what is the user location, and then it redirects

169
00:14:55.600 --> 00:15:01.040
the user to the correct URL for that particular product. And of course, you can generalize this

170
00:15:01.040 --> 00:15:05.840
idea a little bit more. So not just focus on Amazon, which was my use case, but I thought,

171
00:15:05.840 --> 00:15:10.080
okay, let's make maybe something that can be more useful to more people. But in general, whenever you

172
00:15:10.080 --> 00:15:16.240
have the need of creating like a geo aware redirect system, you can have this entry point, single URL,

173
00:15:16.240 --> 00:15:21.040
and then some kind of routing configuration that tells you, okay, if we detect the user is from this

174
00:15:21.040 --> 00:15:25.120
particular country, this is going to be the target URL where we want to redirect the user.

175
00:15:25.120 --> 00:15:29.600
And of course, you can make this configuration a little bit fancier if you want to support multiple

176
00:15:29.600 --> 00:15:35.520
URLs, multiple countries, maybe fallback URLs if you cannot detect the country, or if the current

177
00:15:35.520 --> 00:15:40.480
country is not in the lists that you have provided. So this was kind of the use cases that I want

178
00:15:40.480 --> 00:15:47.600
key row to help me with. So let's build this Lambda with all this logic and figure out how to package

179
00:15:47.600 --> 00:15:54.240
it in a way that we can ship it to AWS and have it running. So we started the process from scratch

180
00:15:54.240 --> 00:15:59.920
in spec mode. And as we described before, the process starts in a very simple way. So you just

181
00:15:59.920 --> 00:16:04.240
need to give it an initial prompt, which doesn't have to be detailed at all. So it needs to be a very

182
00:16:04.240 --> 00:16:09.280
high level description of what you want to achieve. And what I gave it was effectively not more than two

183
00:16:09.280 --> 00:16:16.080
lines, something that goes like a Lambda function written in Rust with an HTTP trigger could be API

184
00:16:16.080 --> 00:16:21.920
Gateway or function URL that allows you to redirect the user to different URLs depending on their geo

185
00:16:21.920 --> 00:16:27.200
location. That was just the prompt that I gave Kiro. And it started by generating the first file,

186
00:16:27.200 --> 00:16:31.760
which is a requirements.md. Now I'm not going to read the entire documents because it's quite long,

187
00:16:31.760 --> 00:16:36.800
but the document that was generated at an introduction, more or less similar to the prompt that I gave at

188
00:16:36.800 --> 00:16:41.360
the beginning. But then it started to generate requirements and user story. So for instance,

189
00:16:41.360 --> 00:16:48.160
there was a first user story that said, when a user makes an HTTP request to the Lambda, then the

190
00:16:48.160 --> 00:16:53.040
system shall determine the user geographic location. When the geographic location is determined, then the

191
00:16:53.040 --> 00:16:59.280
system shall match it against a configured set of rules. And then you keep going. When you identify the

192
00:16:59.280 --> 00:17:04.400
rule, then you need to create a direct response and so on. So very structured format. And this was the first

193
00:17:04.400 --> 00:17:10.960
acceptance criteria. And there were more acceptance criteria going even into performance and security.

194
00:17:11.520 --> 00:17:17.200
And of course, it wasn't perfect as I imagined at the beginning. So this is where the collaboration is

195
00:17:17.200 --> 00:17:23.040
a very important step. I kept tweaking it a little bit, either by manual edits or by asking Kiro to fix

196
00:17:23.040 --> 00:17:28.080
certain things by itself. And at some point when I was happy with it, I clicked the button to move to the

197
00:17:28.080 --> 00:17:33.920
next phase. And that's where Kiro generated the design.md document. So the more technical document

198
00:17:33.920 --> 00:17:39.440
containing more implementation details. So here, one thing that I really appreciated is that it

199
00:17:39.440 --> 00:17:45.440
started with a high level architecture in mermaid format. It wasn't 100% correct as I imagined it,

200
00:17:45.440 --> 00:17:52.240
but it wasn't too bad either. So what I did, I basically copy pasted that mermaid specification into

201
00:17:52.240 --> 00:17:57.760
a mermaid editor. So I could see the preview real time and I did some tweaks myself, then copy pasted it

202
00:17:57.760 --> 00:18:02.720
back to the markdown and then also changed a few other details. And at that point, I think I was

203
00:18:02.720 --> 00:18:08.400
happy enough to move to the next phase, which is the generation of the tasks.md file. So this is where

204
00:18:08.400 --> 00:18:15.120
Kiro takes your design document and your requirements, and it comes up with a list of tasks to implement

205
00:18:16.320 --> 00:18:21.600
basically concrete steps. So it's not going to create very big steps only one go, but very manageable,

206
00:18:21.600 --> 00:18:25.440
small steps that incrementally, they will lead you to the final solution.

207
00:18:25.440 --> 00:18:30.240
Now, this is where things started to go a little bit wrong. So, so far, I was very happy with the

208
00:18:30.240 --> 00:18:34.240
process. Like I really enjoyed this kind of collaboration and actually realized that I had

209
00:18:34.240 --> 00:18:38.880
a few gaps in my understanding of the project. So there were a few things where Kiro actually

210
00:18:38.880 --> 00:18:43.120
throw me questions that I haven't thought about. And I had to actually think really hard, okay,

211
00:18:43.120 --> 00:18:48.400
what do we need to do in this case? Let's define a clear expectation. Once you put all of that into

212
00:18:48.400 --> 00:18:54.400
writing, I think it's a really good exercise anyway for yourself, for the agent, and even for anyone

213
00:18:54.400 --> 00:18:58.400
else that is going to join the project in the future. So all these documents, I think, become

214
00:18:58.400 --> 00:19:02.880
persistent knowledge that everyone can access to even in the future. But then yes, moving to the

215
00:19:02.880 --> 00:19:08.560
implementation phase, I actually eat a very nasty bug. So the first task that Kiro generated was about

216
00:19:08.560 --> 00:19:13.920
scaffolding the whole project using a tool that generally people use when you want to do a Lambda

217
00:19:13.920 --> 00:19:18.400
Rust. We have an episode about that. We'll have the link in the show notes that is called Cargo Lambda.

218
00:19:18.400 --> 00:19:23.920
And Cargo Lambda basically allows you to go from zero to a structured approach where you can say,

219
00:19:23.920 --> 00:19:28.560
I want an HTTP Lambda, and it generates an entire example for you that you can build on.

220
00:19:28.560 --> 00:19:35.280
So when I say we, I mean myself and Kiro, we kind of decided, okay, we want to use Cargo Lambda. So the

221
00:19:35.280 --> 00:19:38.720
first step is going to be to scaffold the project with Cargo Lambda. And because it's going to be an

222
00:19:38.720 --> 00:19:43.120
HTTP function, the first step that Cargo Lambda generally asks you is like, what kind of Lambda are you

223
00:19:43.120 --> 00:19:48.720
building? So it generates a more closer template to actually what you are trying to do. And the

224
00:19:48.720 --> 00:19:55.280
problem is that when Kiro tried to run Cargo Lambda in the terminal, it did use an argument that actually

225
00:19:55.280 --> 00:20:00.960
didn't really exist. So the command failed. And at that point, Kiro somehow didn't realize that

226
00:20:00.960 --> 00:20:05.440
the command had failed and what was the error. So it got stuck into a loop where it was working,

227
00:20:05.440 --> 00:20:10.560
waiting for the command to finish, although the command wasn't running anymore. And I was waiting for a

228
00:20:10.560 --> 00:20:14.400
while. And then eventually I had to ask, like, what's going on? Didn't you see that the command

229
00:20:14.400 --> 00:20:19.520
finished? And Kiro kind of pretended that at that point, he realized, oh, yes, the command finished,

230
00:20:19.520 --> 00:20:23.120
but it looked like he wasn't able to read the output of that command. So he didn't really know

231
00:20:23.120 --> 00:20:27.360
what was the next step to do. So I started to assume that there was something wrong, for instance,

232
00:20:27.360 --> 00:20:32.240
with my Rust configuration and tried to fix the Rust environment, rather than really understanding

233
00:20:32.240 --> 00:20:36.960
that he wasn't able to read the output of the command and that he had used a wrong command in the

234
00:20:36.960 --> 00:20:42.160
first place. So I had to do a lot of manual steering to get it to the point where he was able to run the

235
00:20:42.160 --> 00:20:46.720
command correctly. But again, even when the command was running correctly, it was stuck in this working

236
00:20:46.720 --> 00:20:51.840
mode because it didn't really understand that the command had finished successfully. So that seemed

237
00:20:51.840 --> 00:20:56.880
like a bug. And then I started to look online and many other people seem to have very similar bugs.

238
00:20:56.880 --> 00:21:03.280
So I reported it on GitHub myself and many other people are reporting that. So hopefully that's get fixed

239
00:21:03.280 --> 00:21:07.920
and it's going to make the experience much nicer because at this point, this is pretty frustrating

240
00:21:07.920 --> 00:21:12.560
from a user experience perspective. This is like the main thing you expect an agent to do,

241
00:21:12.560 --> 00:21:17.280
to be autonomous to some degree, once you have defined the tasks and the acceptance criteria.

242
00:21:17.280 --> 00:21:21.680
And if you have to continuously interact with it to fix this kind of misunderstanding of every single

243
00:21:21.680 --> 00:21:25.840
action, then you are just better off doing it yourself. Which by the way, funny enough,

244
00:21:25.840 --> 00:21:30.000
was one of the proposed solutions on GitHub is like copy paste the command yourself and plan it

245
00:21:30.000 --> 00:21:35.040
yourself. But then you're not using an agent anymore. You're just using a readme that tells you which

246
00:21:35.040 --> 00:21:41.600
commands to run. So this was our experience, although it was a bit frustrating. I think it's fair to say

247
00:21:41.600 --> 00:21:47.600
that this product is still in beta and bugs are to be expected. This can be a reasonable bug in the

248
00:21:47.600 --> 00:21:53.840
sense that everything has worked fine. The spec driven approach worked seamlessly. So I think I just

249
00:21:53.840 --> 00:21:59.920
expect all these things will be cleaned up and fixed as we go out of that beta phase. And at that

250
00:21:59.920 --> 00:22:04.080
point, I think everyone will have a nice experience with Kiro. So don't take this as negative feedback

251
00:22:04.080 --> 00:22:10.080
or as don't use Kiro. Of course, at the beginning bugs are expected, but we believe it's normal and

252
00:22:10.080 --> 00:22:14.400
it's only going to get better.

253
00:22:14.400 --> 00:22:18.960
Yeah, I hope that let's look at the GitHub issue list and keep an eye on it because it is great when Amazon tries to do a project like this in open source and on GitHub.

254
00:22:18.960 --> 00:22:24.320
But we have seen cases in the past where there's a lot of fanfare when things are open sourced at the

255
00:22:24.320 --> 00:22:31.280
beginning. But the repo does not get the attention and resourcing it deserves. So the fingers crossed

256
00:22:31.280 --> 00:22:36.400
that we'll see a bit of activity there. Maybe we should talk a little bit about a couple of other

257
00:22:36.400 --> 00:22:41.520
unique features Kiro has compared to other tools. So those are agent hooks and steering. So agent hooks

258
00:22:41.520 --> 00:22:45.840
lets you define a prompt that runs automatically when specific things happen in your IDE, like when

259
00:22:45.840 --> 00:22:51.680
a file is created, saved or deleted, as well as on a manual trigger. And this is a bit like custom

260
00:22:51.680 --> 00:22:57.040
commands in cloud code. So an examples to that for that are like, if you want to review changed files

261
00:22:57.040 --> 00:23:01.280
for potential security issues automatically, like check if you've got credentials in your code.

262
00:23:01.920 --> 00:23:07.840
Or another one might be like an internationalization helper. So when you add a new label in one language,

263
00:23:07.840 --> 00:23:12.000
make sure to highlight missing translations in other supported languages and provide an initial

264
00:23:12.000 --> 00:23:17.840
template translation. Then there's steering. So that steering is basically giving you persistent

265
00:23:17.840 --> 00:23:23.360
project knowledge stored in markdown files under dot Kiro slash steering. And Kiro will load that as

266
00:23:23.360 --> 00:23:27.680
context on every prompt. So it basically stops you from having to continuously steer it back in the kind

267
00:23:27.680 --> 00:23:35.520
of style or patterns you prefer to have. So it feels very similar to CLAUDE.md with Cloude code or Cursor rules

268
00:23:35.520 --> 00:23:41.280
if you use cursor, but it's a bit more structured. You get default files for product overview, your tech stack

269
00:23:41.280 --> 00:23:45.520
and your project structure. And you can also reference live files from the repo inside a steering file.

270
00:23:45.520 --> 00:23:50.000
And they'll be loaded as well into the context window of each prompt, which is, it seems like a nice approach.

271
00:23:50.000 --> 00:23:56.240
Now, all this is all very well and good, but it completely depends on what it costs. So what does it cost?

272
00:23:56.240 --> 00:24:02.080
Exactly. Let's talk about pricing finally. So this actually is very, very new because only last week

273
00:24:02.080 --> 00:24:08.560
AWS published a relevant blog post to disclose what they have in mind after the beta phase is completed.

274
00:24:08.560 --> 00:24:13.360
And we'll link in the show notes to that particular blog post so you can see all the details yourself.

275
00:24:13.360 --> 00:24:18.720
But let's try to give you a summary as well. So at the moment, there are four different plans.

276
00:24:18.720 --> 00:24:24.080
So there is the free, the pro, the pro plus and the power. And each plan has a different price and limits

277
00:24:24.080 --> 00:24:29.680
in terms of requests and prompts that you can run, which by the way, is quite interesting because almost

278
00:24:29.680 --> 00:24:36.240
every other competitor is based on tokens. In the case of Kiro, they look at the number of prompts, basically,

279
00:24:36.240 --> 00:24:41.600
the free plan, which is, I don't know, I feel it's a little bit looser in terms of unit,

280
00:24:41.600 --> 00:24:45.280
but might work better because it's probably closer to what a user can understand.

281
00:24:46.080 --> 00:24:51.440
So the free plan gives you, oh, by the way, there is an important difference between vibe mode and spec

282
00:24:51.440 --> 00:24:56.560
mode. We already mentioned that Kiro supports both. So vibe mode is just give it a prompt and it's going

283
00:24:56.560 --> 00:25:01.920
to try to guess what you really want based on a very loose prompt. While spec mode is that entire

284
00:25:01.920 --> 00:25:06.720
process where you work together through a series of documents before the work can actually start.

285
00:25:06.720 --> 00:25:12.480
So of course, you can imagine that vibe mode is much lighter in terms of AI usage, while spec mode

286
00:25:12.480 --> 00:25:17.920
is a much more involved process that requires a lot more interaction with AI. So more expensive from

287
00:25:17.920 --> 00:25:23.280
just a computational perspective. So when you go with the free plan, you get 50 vibe requests per month

288
00:25:23.280 --> 00:25:30.320
and zero spec requests. So no spec, if you go with the free plan, the pro plan has 225 vibe and 125

289
00:25:30.320 --> 00:25:39.440
spec, and it costs you $20 a month. The pro plus has 450 vibe and 250 spec, and it costs you $40 a month.

290
00:25:40.080 --> 00:25:45.360
So it's exactly doubled the pro plan in everything. And then there is the power plan, which is like

291
00:25:45.360 --> 00:25:52.880
2250 vibe and 1250 spec per month, and it costs you $200. So there is a steep increase there,

292
00:25:52.880 --> 00:25:58.800
but you also get a lot more usage in terms of vibe and spec. So there is actually a welcome bonus. So when

293
00:25:58.800 --> 00:26:05.520
you join the first 14 days, you have like a trial run where you can do 100 spec and 100 vibe included in that

294
00:26:05.520 --> 00:26:11.040
trial run. But of course, after the 14 days, all of this stuff is removed. So you better use it fast.

295
00:26:11.040 --> 00:26:17.040
And also you can enable pay as you go. So if you reach one of these limits, and you still need to use the tool,

296
00:26:17.040 --> 00:26:22.320
you don't necessarily need to upgrade to the next plan because you can just pay for whatever else you need.

297
00:26:22.320 --> 00:26:28.240
And the rates are $0.04 per every single vibe and $0.20 per spec. And again, I want to underline that

298
00:26:28.240 --> 00:26:34.000
the pricing is not per token. So people might wonder, okay, what does a spec gives me? And

299
00:26:34.000 --> 00:26:38.480
actually, there is a note somewhere in the article that says that if you try to do complex actions,

300
00:26:38.480 --> 00:26:44.240
you might end up consuming multiple requests. So this is something worth noting that I think you

301
00:26:44.240 --> 00:26:49.280
cannot just game the system and try to use one prompt to do 1 million things. Because I think there is

302
00:26:49.280 --> 00:26:54.960
a mechanism that realizes and it will still be built accordingly to some kind of unit that I don't

303
00:26:54.960 --> 00:26:59.920
think is super well described. But yeah, you cannot just let it do everything with just one

304
00:26:59.920 --> 00:27:05.120
ask and expect that it's going to cost you only one request. There is, by the way, a very useful usage

305
00:27:05.120 --> 00:27:10.160
dashboard that shows exactly what is your current consumption for every kind of request. And if you

306
00:27:10.160 --> 00:27:16.400
are using any of the overages in case you enable that feature. So at least you can keep things in check and

307
00:27:16.400 --> 00:27:22.960
understand where you're going with your spend. Now, this pricing has been a little bit debated in

308
00:27:22.960 --> 00:27:27.440
the AWS community. I've seen some very common complaints. And I think some of them are fair to

309
00:27:27.440 --> 00:27:32.880
share here. Like for instance, when you get at the beginning free zero spec credits, it makes it really

310
00:27:32.880 --> 00:27:38.160
hard to really evaluate one of what I believe is the best features of Kiro. So it's a little bit of a

311
00:27:38.160 --> 00:27:43.360
shame that users might not even realize that how powerful is that feature just because they are

312
00:27:43.360 --> 00:27:47.680
discouraged by either pricing or maybe because they have a free plan and they don't have any more.

313
00:27:48.240 --> 00:27:52.880
Maybe they expired the 14 days trial. So they don't effectively have a way to test if the spec thing

314
00:27:52.880 --> 00:27:57.120
is actually really good for them. The other complaint is that cost feels a little bit unpredictable.

315
00:27:57.120 --> 00:28:03.680
One task can consume multiple spec or vibe. So what happens? How much is this going to cost me? You

316
00:28:03.680 --> 00:28:07.920
don't necessarily can you cannot tell upfront when you're starting to do an action how much it's going to

317
00:28:07.920 --> 00:28:14.400
cost you. And then the spec between vibe and sorry, the split between vibe and spec. It's nice in a way,

318
00:28:14.400 --> 00:28:19.040
but also adds cognitive load because you have to always think, okay, which mode do I need to use?

319
00:28:19.040 --> 00:28:25.200
How much credit do I have left for each mode? And so it kind of makes developers work a little bit

320
00:28:25.200 --> 00:28:30.720
more just to really understand what am I going to build on? And do I actually even have the credits for

321
00:28:30.720 --> 00:28:35.680
what I want to do? So I think this it's important to say that this pricing decision doesn't really seem

322
00:28:35.680 --> 00:28:40.000
final from the AWS perspective. So probably important for you to provide feedback. If you

323
00:28:40.000 --> 00:28:45.200
have ideas or complaints, make sure you express them to AWS, because I expect this is probably the

324
00:28:45.200 --> 00:28:49.360
best phase of this product to try to influence future outcomes in this sense.

325
00:28:49.360 --> 00:28:55.200
Yeah, that makes sense. I think it's interesting. I don't know how you can make a better pricing model,

326
00:28:55.200 --> 00:28:59.840
to be honest, because I think even when you're using token based pricing, it's still very difficult

327
00:28:59.840 --> 00:29:04.080
to anticipate how many you're going to use, especially when it's agentic and the agent is generating

328
00:29:04.080 --> 00:29:08.480
prompts for you with all sorts of different contexts from all over the place. So it doesn't seem like a

329
00:29:08.480 --> 00:29:13.520
deterministic pricing model is that easy to achieve. Let's see how this one evolves because AWS do,

330
00:29:13.520 --> 00:29:20.400
from time to time, move things in a more cost-effective direction. I just wanted to ask some

331
00:29:20.400 --> 00:29:25.920
questions since you've spent a lot more time than I have with Kiro. I just wanted to get your overall

332
00:29:25.920 --> 00:29:29.360
opinion. So do you think it's valuable as a product in its own right?

333
00:29:29.360 --> 00:29:35.520
I'd say yes, more yes than no.

334
00:29:35.520 --> 00:29:40.160
And just because of the spec-driven approach is, yeah, it made me feel like I'm always working together with a product manager and a very skilled technical

335
00:29:40.160 --> 00:29:45.200
person in a team, even when I'm working alone. And I think there's lots of value in that.

336
00:29:45.200 --> 00:29:49.680
And that whole process makes you go from an idea that sometimes even you think you have a really

337
00:29:49.680 --> 00:29:54.960
clear understanding of the idea, you'd be surprised after going through the process, how many gaps you had

338
00:29:54.960 --> 00:30:00.160
on the potential implementation of that idea. So definitely there is a huge amount of value in that

339
00:30:00.160 --> 00:30:06.320
process alone. Okay. Does it have a USP, like if we compare it to other tools in the market?

340
00:30:07.040 --> 00:30:10.880
Yeah.

341
00:30:10.880 --> 00:30:16.080
And I think that's a little bit of the challenge for AWS, because I will go as far as saying yes and no, meaning that the spec-driven approach at the moment is the unique value proposition

342
00:30:16.080 --> 00:30:22.000
of this product. But to be realistic, you could recreate a similar experience with any other AI tool.

343
00:30:22.000 --> 00:30:26.880
You just need to create prompts and steps, maybe a little bit more manually yourself.

344
00:30:26.880 --> 00:30:31.920
But I think you can easily achieve a similar experience with something like Claude Code or Coursor

345
00:30:31.920 --> 00:30:38.240
or any other Agentic AI just by defining a workflow that kind of describes what we just mentioned when

346
00:30:38.240 --> 00:30:44.160
we spoke about the spec-driven approach that Kiro has built in. And in a sense, if Coursor,

347
00:30:44.160 --> 00:30:48.720
for example, just to mention one, or Claude Code, if they realize, oh, this approach is actually really

348
00:30:48.720 --> 00:30:52.640
cool and we can see lots of our users wanting something like that, how long is it going to

349
00:30:52.640 --> 00:30:56.720
take them to recreate it and make it native in their own solution? I don't think it's going to

350
00:30:56.720 --> 00:31:02.560
be a difficult thing to recreate. So that can be a bit of a problem for AWS in the sense that they

351
00:31:02.560 --> 00:31:06.320
will lose this edge really quickly because it's not really defendable.

352
00:31:06.320 --> 00:31:13.600
Okay.

353
00:31:13.600 --> 00:31:14.160
Now, biggest question for me is, do you believe Amazon is committed to making this product a success?

354
00:31:14.160 --> 00:31:20.400
Yeah, to be honest, I'm unsure.

355
00:31:20.400 --> 00:31:24.720
Part of me would like to say yes, because I think I like the product and I see lots of potential value, especially projected into the future. But there were a few

356
00:31:24.720 --> 00:31:29.520
things that made me a little bit skeptical. For instance, at the beginning, I saw lots of hype.

357
00:31:29.520 --> 00:31:35.440
And this hype was, it felt like mostly marketing driven, like if there was a big push organized

358
00:31:35.440 --> 00:31:39.840
from the entire community, which is great. I think that's something that should be done from somebody

359
00:31:39.840 --> 00:31:45.360
like AWS. But then when I went back to the repo and I saw all the open issues and very little

360
00:31:45.360 --> 00:31:50.960
engagement from AWS engineers into all these issues, that made me a little bit worried thinking,

361
00:31:50.960 --> 00:31:55.440
okay, after all that marketing push, then there isn't an equivalent push from a development

362
00:31:55.440 --> 00:32:01.200
perspective, which maybe is just right now in this flow state, AWS hasn't allocated enough people

363
00:32:01.200 --> 00:32:05.120
into the project. So that's something that can be easily fixed, in my opinion. But at the moment,

364
00:32:05.120 --> 00:32:10.480
there's a little bit of a warning sign that maybe the hype is not well balanced with the actual

365
00:32:10.480 --> 00:32:11.920
development on the product.

366
00:32:11.920 --> 00:32:17.680
Yeah.

367
00:32:17.680 --> 00:32:23.040
And I'd reiterate, I think there are a few projects where we can say we've seen AWS invest in open source on a continued basis. I'm thinking primarily of the AWS Lambda power tools, particularly

368
00:32:23.040 --> 00:32:28.560
the Python one, where the open source contributions have been fantastic and sustained over a long

369
00:32:28.560 --> 00:32:33.360
period of time. But I think it's an outlier. And a lot of projects we see launched with hype

370
00:32:33.920 --> 00:32:38.800
tend to fade and gather dust. We really hope that doesn't happen here. Do you think it's worth

371
00:32:38.800 --> 00:32:42.640
migrating at this point from whatever IDE you're using right now to Kiro?

372
00:32:42.640 --> 00:32:47.840
That's a difficult one to generalize. I think it's very up to the individuals.

373
00:32:47.840 --> 00:32:52.800
I think if people are already using VS code, there is very minimal difference. Like even the team gets imported,

374
00:32:52.800 --> 00:32:59.120
so you don't even feel like you are changing an IDE. So in that sense, it's not a big deal. Although I

375
00:32:59.120 --> 00:33:05.920
think there is an important thing to call out that because Kiro as Cursor and Windsurf are forks of

376
00:33:05.920 --> 00:33:10.400
VS code, I think there is a huge amount of work that needs to happen behind the scenes to keep that fork in

377
00:33:10.400 --> 00:33:16.640
sync with the evolution of VS code. And to keep it always compatible, as the two products of this

378
00:33:16.640 --> 00:33:22.880
multiple forks go ahead in their own history. So if AWS is not really committed to invest in that,

379
00:33:22.880 --> 00:33:27.120
then eventually Kiro is not going to be a VS code fork anymore. It's just going to be its own thing,

380
00:33:27.120 --> 00:33:32.560
and it's going to be impossible to migrate from one to the other without losing features or losing

381
00:33:32.560 --> 00:33:37.360
configuration or whatever. So that's probably the risk in the long term. But in the short term,

382
00:33:37.360 --> 00:33:42.480
if you use VS code, you're literally not going to see any difference. So the migration is just like the

383
00:33:42.480 --> 00:33:49.200
name of the binary that you run effectively. But I would also say that if you come from other ideas

384
00:33:49.200 --> 00:33:53.440
or editors, I don't think there is a compelling enough story there for you to move on because

385
00:33:53.440 --> 00:33:58.560
that will require a lot of mental effort and just embracing a totally different tool. So in those

386
00:33:58.560 --> 00:34:03.360
cases, you might be better off with something more CLI driven, like Claude code is something that I really

387
00:34:03.360 --> 00:34:09.600
like because you can run it in parallel in another terminal window, and it doesn't affect your main workflow

388
00:34:09.600 --> 00:34:13.600
with your IDE. But if you like that experience and you want to use something that is a little bit

389
00:34:13.600 --> 00:34:19.280
closer to AWS, you can use Amazon Q developer CLI, which is somewhat similar to cloud code.

390
00:34:19.280 --> 00:34:24.240
Yeah. Yeah.

391
00:34:24.240 --> 00:34:29.920
I tend to agree with that because I'm someone who likes to switch between Vim and VS code and then specific tools, specific languages. Like I find VS code not good enough for Python in general.

392
00:34:30.560 --> 00:34:35.600
So I use PyCharm for that. So it would suit me better to use the CLI and allow me to control the editor

393
00:34:35.600 --> 00:34:42.800
separately. But given that AWS is moving into having its own IDE, maybe entering the same space

394
00:34:42.800 --> 00:34:50.080
as Microsoft with VS code, is there a larger opportunity for AWS with this tool beyond just

395
00:34:50.080 --> 00:34:56.640
agentic AI?

396
00:34:56.640 --> 00:35:02.960
Yeah, I think this is actually the big topic for us where we can make some guesses and maybe give some suggestions to AWS in this episode. I think there is a good opportunity here, not necessarily

397
00:35:02.960 --> 00:35:08.080
in the current form. I think the current form is just driven by the AI hype that is still there,

398
00:35:08.080 --> 00:35:14.240
it hasn't faded away yet. But I think the larger opportunity for AWS is if they are investing into

399
00:35:14.240 --> 00:35:19.920
creating their own IDE, it should be much more tightly integrated with the whole AWS ecosystem.

400
00:35:19.920 --> 00:35:24.720
So AI, of course, should be a prevalent feature because these days you cannot have an IDE without

401
00:35:24.720 --> 00:35:30.320
AI. And we can see that even with very new projects like the Zed editor, which is a really nice

402
00:35:30.320 --> 00:35:35.680
project that is trying to disrupt the IDE space in their own way, they are also investing a huge

403
00:35:35.680 --> 00:35:41.360
amount into AI. So AI definitely needs to be a cornerstone in any IDE going forward. I think here

404
00:35:41.360 --> 00:35:47.840
AWS, as you said, can take a big step forward and trying to imagine Kiro as the equivalent of

405
00:35:47.840 --> 00:35:53.600
VS Code, sorry, Visual Studio, not VS Code, the full Visual Studio IDE that it is for Azure,

406
00:35:53.600 --> 00:35:59.440
try to use Kiro in a way that it becomes that central place where every AWS developer goes

407
00:35:59.440 --> 00:36:05.680
to do anything related to AWS. So from scaffolding a new project, writing it, testing it, deploying

408
00:36:05.680 --> 00:36:11.520
it, monitoring, operating it in production. When I've seen people using Visual Studio, I see that

409
00:36:11.520 --> 00:36:17.120
they only use the IDE to interact with everything in Azure, which is quite impressive. I think Kiro

410
00:36:17.120 --> 00:36:22.320
can have an opportunity to become that for the AWS world. So maybe, I don't know, maybe that place

411
00:36:22.320 --> 00:36:26.800
doesn't share this vision, but I think that would become a pretty powerful product if they invest

412
00:36:26.800 --> 00:36:30.960
in that kind of vision. What do you think? Do you agree with the stake or is it too wild?

413
00:36:34.560 --> 00:36:39.360
I think there's a huge number of users out there who would really like that, especially new users who need more of a guided approach. And especially if you're coming to AWS for the first time these

414
00:36:39.360 --> 00:36:45.840
days, the AWS console is so overwhelming and all the other tools can be too. If your IDE could have

415
00:36:45.840 --> 00:36:52.160
much more of a guided experience to help users there. We like to do everything with infrastructure as

416
00:36:52.160 --> 00:36:58.640
code and SDKs and CLIs, but we don't necessarily represent the majority of users out there.

417
00:36:58.640 --> 00:37:03.760
And if you, like you did look at users who are embedded in the Microsoft ecosystem,

418
00:37:03.760 --> 00:37:09.440
the tendency tends to be more around using the IDE and visual tooling. And those users need to be

419
00:37:09.440 --> 00:37:13.760
served as well. Like it's not necessarily that our approach is the one approach. So maybe there is

420
00:37:13.760 --> 00:37:18.240
an opportunity for AWS in terms of greater adoption of AWS compared to Azure.

421
00:37:18.240 --> 00:37:22.560
Yeah. And I think this brings us to the end of this episode, but before giving you the closing

422
00:37:22.560 --> 00:37:27.520
notes, I want to say thank you to Forteorem for sponsoring yet another episode of this podcast.

423
00:37:27.520 --> 00:37:31.520
At Forteorem, we believe that the cloud should be simple, scalable, and cost-effective,

424
00:37:31.520 --> 00:37:35.840
and we help teams to just achieve that. So whether you're diving into containers,

425
00:37:35.840 --> 00:37:41.040
stepping into event-driven architecture or scaling global SaaS platforms on AWS, or even just trying

426
00:37:41.040 --> 00:37:47.920
to keep cloud spend under control, our team can help you out and we have your back. So visit forteorem.com

427
00:37:47.920 --> 00:37:53.360
to see how we can help you and see our customer stories. And hopefully we get to work together.

428
00:37:53.360 --> 00:37:59.280
So don't hesitate to reach out. Now, just to give you the closing notes, we did a very good overview

429
00:37:59.280 --> 00:38:04.320
of Kiro. We really enjoyed the spec-driven approach, and we believe that there is a lot of potential for

430
00:38:04.320 --> 00:38:10.320
this product in the future if AWS really commits to polish it out and maybe expand a little bit beyond

431
00:38:10.320 --> 00:38:17.520
just the AI focus to integrate it into the bigger AWS ecosystem. Of course, this is just our opinion,

432
00:38:17.520 --> 00:38:22.640
so we're really curious to hear what you think. Have you tried it? Do you see yourself using it

433
00:38:22.640 --> 00:38:26.800
more in the future or maybe you just don't like the idea, you prefer other tools? What do you think

434
00:38:26.800 --> 00:38:31.600
of the current pricing? And yes, if you have any answers to the questions, we'd really like to know.

435
00:38:31.600 --> 00:38:38.000
So reach out or leave us a comment. We definitely love your opinion and we'll use that for sure in

436
00:38:38.000 --> 00:38:50.880
the following episodes. So stay tuned for more. Thank you and see you in the next one.
