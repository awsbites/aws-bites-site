WEBVTT

1
00:00:00.000 --> 00:00:04.720
Hello everyone, today we're going to answer the question what can you do with Kinesis data

2
00:00:04.720 --> 00:00:09.680
streams and today we're going to explore this topic and talk about what are the main differences

3
00:00:09.680 --> 00:00:15.120
between data streams and queues or message buses, how Kinesis can let you process large

4
00:00:15.120 --> 00:00:21.920
batches of messages in near real time, why you might want to use Kinesis as a queue or a pub-sub

5
00:00:21.920 --> 00:00:27.520
in some particular scenarios and also we're going to explore a few different ways to use Kinesis

6
00:00:27.520 --> 00:00:33.600
with the focus on avoiding too much complexity. My name is Luciano and I'm joined by Eoin

7
00:00:33.600 --> 00:00:35.600
and this is AWS Bites podcast.

8
00:00:42.960 --> 00:00:50.320
So this is one of our last episodes in our series of AWS events services and we are now focusing on

9
00:00:50.320 --> 00:00:56.080
streaming data. So I suppose the first question that we should try to answer is what is streaming,

10
00:00:56.080 --> 00:01:01.520
what do we mean by that and in particular in the context of Kinesis data streams what are the

11
00:01:02.080 --> 00:01:07.600
pieces of functionality that we get from this particular service. What do you think Eoin?

12
00:01:09.600 --> 00:01:15.040
Kinesis data streams we're talking about, so this is a fully managed event streaming service,

13
00:01:15.040 --> 00:01:19.840
so yeah like you say streaming is different to queuing and pub-sub systems, the ones we've

14
00:01:19.840 --> 00:01:25.200
talked about already, so we should probably talk about what streaming is and how it's subtly but

15
00:01:25.200 --> 00:01:31.280
quite different. With streaming you're talking about processing continuous streams of events

16
00:01:31.280 --> 00:01:38.080
in near real time and typically in batches right, larger batches with SNS or SQS you might be

17
00:01:38.080 --> 00:01:44.720
talking about individual messages normally they're standalone units but with pub-subs you're talking

18
00:01:44.720 --> 00:01:51.360
about single message to fanning out to multiple consumers but streaming you're typically talking

19
00:01:51.360 --> 00:01:56.560
about larger volumes of messages from multiple producers being processed in bulk so in batches

20
00:01:56.560 --> 00:02:03.520
by one or more consumers and more or less in real time so you're really talking about a continuous

21
00:02:03.520 --> 00:02:09.680
stream of batches of records and another difference with streaming with things like

22
00:02:09.680 --> 00:02:15.520
Kinesis and Kafka it retains the records even after they've been processed so you can always

23
00:02:15.520 --> 00:02:23.520
have new consumers join or you can reprocess data by going back to the data that's stored

24
00:02:23.520 --> 00:02:29.360
depending on how long you've configured the retention of your streams.

25
00:02:29.360 --> 00:02:34.480
Yeah that can be very useful also when you have a bug in your code and you realize that maybe you you're processing

26
00:02:34.480 --> 00:02:39.600
didn't really do what you wanted to do in the first place you can fix the bug and then basically

27
00:02:39.600 --> 00:02:47.040
rewind your ingestion start from scratch and re-ingest everything again.

28
00:02:47.040 --> 00:02:52.560
Yeah that's true that's true I mean we should also say that even though we're clarifying the differences between

29
00:02:52.560 --> 00:02:58.640
streaming and queues or pub-sub it's actually very common well not uncommon I would say for people to

30
00:02:58.640 --> 00:03:06.400
use Kinesis or Kafka as a queuing system or as a pub-sub system and then there's the question why

31
00:03:06.400 --> 00:03:11.360
would you do that and I suppose you'd only really do that if you need some of the specific features

32
00:03:11.360 --> 00:03:17.040
that Kinesis or Kafka provides that aren't provided with SQS or SNS so those we'll go into

33
00:03:17.040 --> 00:03:23.360
those in a bit more detail but we should probably do our usual rundown through some of the use cases

34
00:03:23.360 --> 00:03:30.720
for Kinesis data streams where should we start?

35
00:03:30.720 --> 00:03:37.360
Yeah I always like our e-commerce example so in the context of an e-commerce how can we avail of Kinesis data stream like what kind of utility can

36
00:03:37.360 --> 00:03:44.640
we get from from this service and one example that we mentioned before in one of our other episodes

37
00:03:44.640 --> 00:03:52.320
was if you need to collect clicks let's say or mouse movements from the users in the e-commerce

38
00:03:52.320 --> 00:03:58.320
because that will give us an information what kind of products they're possibly interested in what we

39
00:03:58.320 --> 00:04:04.400
could do is that we can collect this data almost in real time from the UI send it to a Kinesis data

40
00:04:04.400 --> 00:04:09.360
stream and then we can have some processing logic that it's getting the data in real time

41
00:04:09.360 --> 00:04:15.360
figuring out which products maybe are relevant for the users and we can send this data back maybe to

42
00:04:15.360 --> 00:04:22.880
a web socket or some other API and refresh the UI in real time with interesting suggestions so that's

43
00:04:22.880 --> 00:04:31.440
a cool use case and we could definitely implement that with Kinesis data streams. Also another thing

44
00:04:31.440 --> 00:04:37.280
that I have done in the past is basically you can capture logs for instance from CloudWatch logs

45
00:04:37.280 --> 00:04:43.280
or other sources and you can store them in Kinesis data streams and then you can let

46
00:04:44.160 --> 00:04:49.840
the Lambda integration process these logs pretty much in real time and you can do all sorts of

47
00:04:49.840 --> 00:04:56.320
things with that. One use case I've done before is basically if you store things that allow you

48
00:04:56.320 --> 00:05:01.440
to extrapolate metrics then from your Lambda you can actually ingest this information as

49
00:05:02.160 --> 00:05:09.440
CloudWatch metrics so you can basically transform logs into metrics by using Kinesis data stream as

50
00:05:09.440 --> 00:05:16.640
a quick way to transport the data and then start some processing. Any other example comes to mind

51
00:05:16.640 --> 00:05:21.600
on your side?

52
00:05:22.640 --> 00:05:29.360
Yeah, speaking of metrics there are quite often a few cases where AWS, CloudWatch metrics for some services they're missing some of the metrics you want. Often for

53
00:05:29.360 --> 00:05:35.680
things like when you're trying to track the number of resources for pricing you know you want to be

54
00:05:35.680 --> 00:05:42.240
alerted when you're using too many containers or number of vc2 instances you can use the last time

55
00:05:42.240 --> 00:05:47.760
we were talking about event bridge events that come from AWS out of the box so you'll get state

56
00:05:47.760 --> 00:05:54.000
transition events when a container starts or stops similar with EC2 instances. With event bridge it

57
00:05:54.000 --> 00:05:59.680
integrates into Kinesis data streams quite easily so you can set a data stream as your target for

58
00:05:59.680 --> 00:06:04.640
an event bridge rule you can take all of those events that are coming relating to ECS containers

59
00:06:04.640 --> 00:06:11.520
and then you can process them in in batches in lambda or another consumer and use it to figure

60
00:06:11.520 --> 00:06:15.520
out okay at any given point in time how many containers are running how many containers are

61
00:06:15.520 --> 00:06:21.680
running in each state what is the duration of a running container and you can create your own

62
00:06:21.680 --> 00:06:27.520
custom metrics then. This is something I've done a few times with things like ECS and AWS batch

63
00:06:27.520 --> 00:06:32.320
where the metrics out of the box have a few gaps and it works pretty well.

64
00:06:32.320 --> 00:06:37.760
I suppose you also see other interesting use cases like people are building a delivery service you

65
00:06:37.760 --> 00:06:42.800
know like uber deliveroo that kind of service if you can imagine an architecture for that system

66
00:06:42.800 --> 00:06:47.040
you've got a lot of real-time event processing so you're collecting orders you're collecting

67
00:06:47.040 --> 00:06:52.720
responses from drivers all of those cases are things where you would say okay this is a

68
00:06:52.720 --> 00:07:00.800
delivery stream I could use Kinesis or Kafka for this. Yeah absolutely. So I think that's

69
00:07:00.800 --> 00:07:07.200
a good thing. Yeah absolutely.

70
00:07:07.200 --> 00:07:14.320
Yeah we should maybe talk now about some of the main features of Kinesis Data Stream. So we said that the data is going to stay there but of course it's not

71
00:07:14.320 --> 00:07:20.240
going to stay there indefinitely you can configure a retention time by default is 24 hours but you

72
00:07:20.240 --> 00:07:25.520
can scale that up to one year so you can keep your data around for a very long time if you want to.

73
00:07:25.520 --> 00:07:33.440
Another thing that is worth mentioning is that you get very very good latency it's under a second to

74
00:07:35.360 --> 00:07:40.560
basically when you store that first record from when you actually consume it

75
00:07:42.800 --> 00:07:48.480
and can be around a second or 70 milliseconds depending on how you use it so we will talk

76
00:07:48.480 --> 00:07:55.520
more about this later on. And then messages in Kinesis are called records as you might have

77
00:07:55.520 --> 00:08:01.520
guessed at this point but a record generally has a sequence number and a partition key

78
00:08:01.520 --> 00:08:06.880
and then there is of course a date of art so the payload itself which is the part you are

79
00:08:06.880 --> 00:08:13.840
interested in processing. Another thing that we mentioned to some extent but is worth highlighting

80
00:08:13.840 --> 00:08:19.360
a little bit more in detail is the concept of shards. Shards are the unit of scale for

81
00:08:19.360 --> 00:08:26.800
Kinesis and I suppose you can imagine shards as different locations where the data is being

82
00:08:26.800 --> 00:08:34.880
distributed and partition keys are basically is the concept used to select given a record in which

83
00:08:34.880 --> 00:08:40.400
shard is going to end up so this is very similar to many other distributed systems so it's not

84
00:08:40.400 --> 00:08:44.880
magic in that sense it uses the same principles as many other distributed systems.

85
00:08:45.680 --> 00:08:51.040
And of course that gives us other guarantees so you're not going to have absolute ordering

86
00:08:51.040 --> 00:08:56.720
of messages but you will have relative ordering per shard so only the data ending up in the same

87
00:08:56.720 --> 00:09:03.040
shard will respect partial ordering there but if you look if you fetch data from different shards

88
00:09:03.040 --> 00:09:09.360
they will not necessarily be in order.

89
00:09:09.360 --> 00:09:16.800
Exactly that's a little bit like what we talked about SQS and message group IDs it's a similar principle yeah and of course what that means is that with

90
00:09:17.920 --> 00:09:24.560
guaranteed ordering you always have physics getting in the way and putting limits on you

91
00:09:24.560 --> 00:09:29.520
so we should talk about those limits because the limits of Kinesis and what you can do with a

92
00:09:29.520 --> 00:09:35.040
single shard really dictate the architecture of your system so normally we talk about quotas and

93
00:09:35.040 --> 00:09:39.760
limits at the end but we're going to talk about this a little bit earlier because you get very

94
00:09:39.760 --> 00:09:45.120
fixed capacity and you have to think about that and how it impacts the architecture the scalability

95
00:09:45.120 --> 00:09:50.000
and the level of concurrency. It makes your architecture a little bit more complex and it

96
00:09:50.000 --> 00:09:54.400
kind of makes you realize that streaming data applications are inherently more complex than

97
00:09:54.400 --> 00:10:00.000
queues and pubsub so it's probably worth saying at this point if you don't need any of the specific

98
00:10:00.000 --> 00:10:05.360
characteristics of these services it's always better to stick with something simple like SQS

99
00:10:05.360 --> 00:10:11.680
and SNF Enbridge because they do give you you can get low latency and scale and massive concurrency

100
00:10:11.680 --> 00:10:17.680
with those systems you don't need a streaming data system to get that it's only if you really have

101
00:10:17.680 --> 00:10:24.080
specific needs that some of the Kinesis or Kafka features will give you just around the number of

102
00:10:24.080 --> 00:10:29.600
messages you can get in a batch for example or the integrations with specific other systems

103
00:10:29.600 --> 00:10:34.000
those are the only reasons where you really need to reach for those more complex streaming

104
00:10:34.000 --> 00:10:40.080
applications but anyway with that out of the way what are these limits so we have strict limits of

105
00:10:40.640 --> 00:10:47.520
one megabyte write per shard or a thousand records per second write capacity so that's how much you

106
00:10:47.520 --> 00:10:54.080
can write per shard in a second or you can read two megabytes or two thousand records per second

107
00:10:54.080 --> 00:10:58.800
from a shard so the right read capacity is double the right capacity and it's very easy to remember

108
00:10:58.800 --> 00:11:04.320
because it's one megabyte and one thousand for right but you're limited to how often you

109
00:11:09.280 --> 00:11:14.800
on this one i want to mention sunday because the first time i noticed these limits i was a little bit confused i was thinking okay why can you write at a certain speed and then you can read

110
00:11:14.800 --> 00:11:19.680
a double the speed and that might seem counterintuitive at first but we need to keep

111
00:11:19.680 --> 00:11:23.920
in mind that you might have multiple consumers so you are writing from one side but you have

112
00:11:23.920 --> 00:11:29.680
multiple consumer on the other side and these limits needs to be accounted for all the consumers

113
00:11:35.360 --> 00:11:40.880
at the same time so they they compound you they are not specific for consumers exactly yeah and you also sometimes need to read more than you're writing because you might be catch up you might

114
00:11:40.880 --> 00:11:45.760
be reading from older records in the stream so you have to catch up so you can't catch up if the

115
00:11:45.760 --> 00:11:51.680
limits would be only the same as the the right limit but there's also the five get you can only

116
00:11:51.680 --> 00:11:56.720
call get records you can only have five read transactions per shard per second as well which

117
00:11:56.720 --> 00:12:00.960
is another interesting interesting one so you could that means you can read up like with a

118
00:12:00.960 --> 00:12:06.080
single read transaction you can actually read 10 000 records so remember we were both talking about

119
00:12:06.080 --> 00:12:09.840
this is about batches that gives you an indication right in one read transaction

120
00:12:10.480 --> 00:12:16.160
you might be reading 10 000 records or 50 megabytes so you just need to think about that

121
00:12:16.160 --> 00:12:21.280
when you're thinking about latency you might say okay i can get like 50 milliseconds i i i've

122
00:12:21.280 --> 00:12:25.200
observed that i can get messages in 50 milliseconds so if i just call get records

123
00:12:25.840 --> 00:12:32.960
20 times a second that's fine but you can you can only call it um five times per second so that's

124
00:12:32.960 --> 00:12:38.640
really the unit of scale the size you can think about if you if you know what rate you're going

125
00:12:38.640 --> 00:12:43.760
to be ingesting at and reading at then you can do the maths and figure figure the rest out as

126
00:12:43.760 --> 00:12:49.760
regards other limits soft limits you have a soft limit of either 200 or 500 shards per stream

127
00:12:49.760 --> 00:12:55.680
depending on the region but you can always increase that to i think tens of thousands of shards

128
00:12:56.400 --> 00:13:03.200
so you can really get high volumes through kinesis and i guess since we're talking about

129
00:13:03.760 --> 00:13:10.720
units of scale we know the limits what do you do then how do you scale how does kinesis scale for

130
00:13:16.480 --> 00:13:23.280
you yeah that's an interesting one and it's a little bit of a controversial topic because in some cases you will hear kinesis being addressed as a serverless service but i suppose

131
00:13:23.280 --> 00:13:28.800
that really depends on the definition of serverless that you have in mind yeah sometimes the argument

132
00:13:28.800 --> 00:13:33.680
to that is that it doesn't really scale to zero that means that you have to think about how do

133
00:13:33.680 --> 00:13:41.040
you provision kinesis data streams up front and once you do that if you don't use them they don't

134
00:13:41.040 --> 00:13:48.560
automatically scale to zero so an interesting news on this field was that in the last reinvent

135
00:13:48.560 --> 00:13:56.560
aws announced the on-demand mode for kinesis data stream which helps a little bit to see kinesis data

136
00:13:56.560 --> 00:14:01.520
stream in a more serverless way but again they don't scale to zero so you have to worry less

137
00:14:01.520 --> 00:14:07.360
about provisioning them in advance but they will never scale to zero and even if you don't use them

138
00:14:07.360 --> 00:14:13.680
there is always some cost that you will need to pay anyway so it's interesting like you could

139
00:14:13.680 --> 00:14:21.120
argue it's serverless but not quite anyway talking about scalability we at this point we understand

140
00:14:21.120 --> 00:14:27.920
that the shard is probably the primary unit to understand how kinesis data stream will scale

141
00:14:27.920 --> 00:14:37.840
and the interesting thing is that if you use the provision mode it's up to you to basically do all

142
00:14:37.840 --> 00:14:43.360
the calculations up front and allocate the number of shards that you think are going to be enough

143
00:14:43.360 --> 00:14:51.120
for you to sustain your read and write throughput you can change that over time like if you realize

144
00:14:51.120 --> 00:14:56.080
at some point you need more or you over provision and you want to scale it down you can do that but

145
00:14:56.080 --> 00:15:04.080
there are restrictions you can do it only 10 times per day meaning a 24-hour period and then

146
00:15:04.080 --> 00:15:11.760
it's interesting that you can only either double or decrease to half the original number of shards

147
00:15:12.560 --> 00:15:19.760
funny enough you can do arbitrary amounts if you use the web ui but you can see that the value

148
00:15:19.760 --> 00:15:24.960
fluctuates until it actually converts to the value one so there is some magic there if you use the

149
00:15:24.960 --> 00:15:30.240
web ui looks like you can go to any arbitrary number but there is still this restriction where

150
00:15:30.240 --> 00:15:36.240
you are doubling and decreasing enough until you get to the number you really want to use yeah and

151
00:15:40.800 --> 00:15:45.440
of course the reason for that essentially is because if you look at the apis for doing it if you're implementing this programmatically as a lot of people do especially before on-demand mode came

152
00:15:45.440 --> 00:15:51.280
out the way you increase the number of shards is by splitting existing shards and the way you

153
00:15:51.280 --> 00:15:55.120
and the way you reduce the number of shares is by merging two existing shards together

154
00:15:55.120 --> 00:16:00.080
so that's where the doubling and the half comes from but i guess yeah you don't have to do that

155
00:16:06.640 --> 00:16:12.880
so much so how does on-demand mode work then yeah on-demand mode is pretty much aws will figure it out for you and it's based on the actual throughput that you have while working on the kinesis data

156
00:16:12.880 --> 00:16:19.120
stream so you start with a default write capacity of four megabytes per second or four thousand

157
00:16:19.120 --> 00:16:24.240
records which is probably for shards behind the scenes we just don't have to worry too much about

158
00:16:24.240 --> 00:16:30.000
the concept of shards in this case and if you keep writing and reading more so if you will need more

159
00:16:30.000 --> 00:16:35.840
capacity the on-demand mode will automatically scale the stream and you will be able to go up

160
00:16:35.840 --> 00:16:45.680
to 200 megabits per second or 200,000 records for writing into the stream of course it doesn't scale

161
00:16:45.680 --> 00:16:52.960
instantaneously so be careful with that like if you have spikes that are like instantaneously

162
00:16:53.680 --> 00:17:00.480
doubling or tripling your throughput don't expect to scale immediately it will take a little bit of

163
00:17:00.480 --> 00:17:06.320
time i think it's around 15 minutes before it will decide to double the capacity so you might still

164
00:17:13.600 --> 00:17:19.040
get throttled with with this approach if you have spikes so be careful with that yeah i also think it's kind of worth mentioning that while it says you you get a default write capacity of four

165
00:17:19.040 --> 00:17:24.400
megabytes and four thousand records and like you say that equates to four shards and you might think

166
00:17:24.400 --> 00:17:29.440
oh that's great i don't have to worry about my shards anymore of course at the consumption side

167
00:17:30.080 --> 00:17:35.680
you need to think about the read uh the limits because you still have a per-shard read limit

168
00:17:35.680 --> 00:17:41.040
and if you've got four shards you kind of need to know about that because it affects the concurrency

169
00:17:41.040 --> 00:17:46.880
of your consumers and if we'll talk a little bit more about lambda but with lambda the number of

170
00:17:46.880 --> 00:17:51.360
invocations of lambda will depend on the number of shards so if you don't know the number of shards

171
00:17:51.360 --> 00:17:56.720
it's very difficult to predict how many lambdas are going to be invoked so you always need to

172
00:17:56.720 --> 00:18:02.720
kind of think about that anyway that's true even if even if it's happening in an on-demand fashion

173
00:18:11.600 --> 00:18:19.280
you should probably do some monitoring on that absolutely yeah do we want to mention also there is another mode called enhanced fan out which it's it makes sense it's relevant only for consumers

174
00:18:19.280 --> 00:18:25.520
and it's a different way that allows you to consume the data because in this case you basically

175
00:18:25.520 --> 00:18:34.480
get a pipe so every consumers will have a pipe and the capacity of how much data you can read

176
00:18:34.480 --> 00:18:40.320
per second is basically per consumer in this case and it goes up to two megabytes per second per

177
00:18:47.600 --> 00:18:53.040
shard if i remember correctly so the interesting thing is that i guess the sorry to jenna but yeah i guess the interesting thing here is that with these limits we talked you mentioned the read

178
00:18:53.040 --> 00:18:58.160
limit of 2000 and how it's greater than the right limit but it's shared with your consumers so

179
00:18:58.720 --> 00:19:03.840
like you said you've got five if you have let's say two consumers they're sharing that they get

180
00:19:03.840 --> 00:19:10.400
a thousand each or a megabyte each and that can be quite difficult if you've got multiple consumers

181
00:19:10.400 --> 00:19:15.520
if you've got you know one consumer that's aggregating events one that's sending them to

182
00:19:15.520 --> 00:19:22.240
firehose and another one that's doing another lambda based aggregation with enhanced fan out

183
00:19:22.240 --> 00:19:28.080
you're basically saying give me a dedicated pipe and it's using http2 and instead of you're pulling

184
00:19:28.080 --> 00:19:35.920
the events it's pushing them to you so you essentially get 2000 records or two megabytes

185
00:19:35.920 --> 00:19:42.000
per shard per consumer per shard per consumer right instead of per shard which is really good

186
00:19:42.000 --> 00:19:47.360
which is really good yeah and you also get lower latency for free as well because it's push mode

187
00:19:47.360 --> 00:19:52.960
it can it can give you that latency of yeah i think it says average 70 milliseconds

188
00:20:01.840 --> 00:20:07.120
instead of the average of 200 milliseconds with a standard shared consumer yeah thanks for clarifying that do you want to mention something quickly about the different pricing model

189
00:20:14.720 --> 00:20:19.520
especially comparing the on-demand and the provision mode yeah this is this was a surprise because a lot of people have been anticipating an on-demand or kind of serverless version of kinesis

190
00:20:19.520 --> 00:20:25.600
for a while and the slight disappointment came from the pricing because it looks like in order

191
00:20:25.600 --> 00:20:29.040
to take advantage of on-demand mode it doesn't immediately make it free but it's because it

192
00:20:29.040 --> 00:20:37.360
doesn't scale down to zero so the kind of entry level pricing for each if you compare them on

193
00:20:37.360 --> 00:20:42.480
demand is actually more expensive than provisioned because with on-demand you pay per stream per hour

194
00:20:43.440 --> 00:20:50.400
and with provision you pay per shard per hour so if you if you go with provisioned the lowest

195
00:20:50.400 --> 00:20:58.480
provisioned level which is one shard you'll pay about a third almost a quarter of the price of the

196
00:20:58.480 --> 00:21:04.080
on-demand baseline which is around four and a half cents per hour because on-demand is charging you

197
00:21:04.080 --> 00:21:09.360
per stream it's giving you four shards out of the box but if you don't use any of those shards

198
00:21:09.360 --> 00:21:14.640
you're still being charged right so the baseline is higher for on-demand and then with on-demand

199
00:21:14.640 --> 00:21:19.040
you're being it is kind of more senseless and serverless in the sense that it's charging you

200
00:21:19.040 --> 00:21:23.920
by the data that's flowing through the system the data ingested and the data retrieved whereas with

201
00:21:23.920 --> 00:21:29.040
provisioned you're paid by the shard and then the shard gives you a capacity you don't pay as you

202
00:21:29.040 --> 00:21:36.320
read so it depends i think the the the if you're trying to judge which is the right mode from a

203
00:21:36.320 --> 00:21:40.960
pricing point of view you just have to compare your use case it's going to vary for everybody

204
00:21:41.680 --> 00:21:46.240
some cases on demand will be cheaper in other cases provision will be cheaper it depends on

205
00:21:46.240 --> 00:21:52.240
your trade-offs between performance scalability cost and the value you're getting out of this

206
00:21:59.520 --> 00:22:04.160
feature so it's yeah it's really a business context how frequent do you actually write and read to and from the stream like is it a constant stream or is it something that can be a little bit more spiky

207
00:22:04.160 --> 00:22:14.320
yeah yeah all right in terms of observability because we slightly mentioned that before

208
00:22:14.320 --> 00:22:21.520
but yeah let's leave let's see maybe what are the most interesting metrics to look after to to see

209
00:22:21.520 --> 00:22:27.200
if we are actually using the data streams correctly so of course the the first one and

210
00:22:27.200 --> 00:22:35.920
probably the most obvious is the iterator age which can basically tell you the age of let's say

211
00:22:35.920 --> 00:22:41.360
that the message the latest messages you still have to process so it's kind of an indicator of

212
00:22:41.360 --> 00:22:49.440
how far behind are you in the stream in consuming it so it's a good way to see if your read capacity

213
00:22:49.440 --> 00:22:56.960
is is not well tuned as opposed to the rate of producing data so keep that in mind because that

214
00:22:56.960 --> 00:23:02.880
might might be very useful for you to to guarantee that you are actually producing and consuming data

215
00:23:02.880 --> 00:23:08.800
as in real time as possible another one is throttling and this is a little bit of a

216
00:23:08.800 --> 00:23:17.200
controversial topic in my in my opinion because it's you can get accurate throttling metrics

217
00:23:17.200 --> 00:23:23.600
because of course you'll get a data point every time you get throttled but if you want to try to

218
00:23:23.600 --> 00:23:28.240
anticipate throttling you have to do a little bit of maths on your own and you can look at the get

219
00:23:28.240 --> 00:23:33.520
record and put record matrix and the problem with those metrics is that the ones you get by default

220
00:23:33.520 --> 00:23:42.000
in cloud watch they are aggregated by minute so if you have very bursty data producing and

221
00:23:42.000 --> 00:23:47.840
consuming the data then you don't really know in a minute how much are you doing for instance in a

222
00:23:47.840 --> 00:23:53.520
second so you only see the minute value so you might see a value that looks okay but then you

223
00:23:53.520 --> 00:23:59.040
see that at the same time you got a throttling for that particular minute so be careful with that

224
00:23:59.040 --> 00:24:04.480
and if you really have bursty use cases maybe you want to do something a little bit more custom

225
00:24:04.480 --> 00:24:09.760
and maybe record metrics on your own to make sure that you understand if you want to understand in

226
00:24:09.760 --> 00:24:14.880
advance when you might incur in throttling otherwise the simple way of looking at this is

227
00:24:14.880 --> 00:24:20.000
just look at the matrix for when the throttling actually happens in reading and writing so when

228
00:24:20.000 --> 00:24:26.640
you exceed the capacity and then you can adjust your shards or you can adjust your process

229
00:24:26.640 --> 00:24:31.360
to avoid the throttling in the future sometimes even a little bit of throttling can be fine

230
00:24:31.360 --> 00:24:37.680
because of course the sdk will retry for you so if that's not really slowing down your pipeline

231
00:24:38.960 --> 00:24:42.960
probably you don't even need to change the chart so keep a look at this matrix because they will

232
00:24:42.960 --> 00:24:48.000
be telling you a lot and you can understand whether you need to change some configuration

233
00:24:48.000 --> 00:24:51.120
and how you read and write the data or the number of shards itself

234
00:24:51.120 --> 00:24:59.360
At this point maybe we should talk I think you probably have a fair idea on how to use

235
00:24:59.360 --> 00:25:05.440
kinesis data stream but this may be good to do a recap and maybe provide a little bit more details

236
00:25:05.440 --> 00:25:13.840
right?

237
00:25:13.840 --> 00:25:17.840
Yeah okay I'll try there's generally one way I usually try to use kinesis but I'll talk about that last because there are kind of three different ways to use kinesis and I'll talk about

238
00:25:17.840 --> 00:25:23.840
that last because there are kind of three different ways to use it there's the api there's the libraries

239
00:25:23.840 --> 00:25:28.400
and then you've got lambda and if we talk about the api usage first it probably gives you a sense

240
00:25:28.400 --> 00:25:33.200
of how it works under the hood even if you use some of the abstractions so when you're producing

241
00:25:33.200 --> 00:25:38.880
messages and sending them into kinesis there's a put records api and it allows you to put 500

242
00:25:38.880 --> 00:25:45.120
records at a given api request and it does that really quickly as well so when you're again when

243
00:25:45.120 --> 00:25:51.120
you're comparing to queuing or pubsub kinesis is all about big lots of messages big batches you can

244
00:25:51.120 --> 00:25:57.120
put in 500 in a single request you'll remember like with sns and sqs it's 10 with the batch api's

245
00:25:58.000 --> 00:26:03.200
so you can put in a megabyte total per record or up to five megabytes for the whole request

246
00:26:04.000 --> 00:26:08.880
so there's a bit of maths to be done there as well and when you specify that you put in the

247
00:26:08.880 --> 00:26:16.160
partition key which you already mentioned so the partition key is useful for dictating ordering

248
00:26:16.160 --> 00:26:21.600
and also the shard it's allocated to so aws will take your partition key produce a hash of it

249
00:26:22.400 --> 00:26:28.800
and use that hash to dictate which shard your message goes into because every shard basically

250
00:26:28.800 --> 00:26:37.360
has a range of hash keys that it will accept so it's just basically an integer allocation for each

251
00:26:37.360 --> 00:26:42.000
shard a range of integers but if you want to override that and you want to be really have

252
00:26:42.000 --> 00:26:46.240
lots of fine control over which shard a message goes into you can actually override the key and

253
00:26:46.240 --> 00:26:51.440
specify that integer in the message as a decimal value and that's called the explicit hash key

254
00:26:52.320 --> 00:26:55.920
generally you don't have to do that but in some cases if you want to be really

255
00:26:57.200 --> 00:27:01.200
if you want to control that ordering and the shard allocation yourself you can do that

256
00:27:01.200 --> 00:27:06.320
I suppose since you're putting 500 messages as well it's also really important I think a lot of

257
00:27:06.320 --> 00:27:12.000
people using Kinesis have been here if you use the put records api you have to ensure that you

258
00:27:12.000 --> 00:27:16.640
handle the errors that come back because you can get partial success and the put records api will

259
00:27:16.640 --> 00:27:24.320
tell you which ones have failed and then you need to reprocess those so it's not like a you're

260
00:27:24.320 --> 00:27:29.680
going to get an exception or just an error code back you have to look at the error response and

261
00:27:29.680 --> 00:27:34.160
figure out which ones have succeeded and which ones have failed and redrive so that's the

262
00:27:34.160 --> 00:27:41.120
production side the producer but if we look at the consumer side retrieving manually using the api

263
00:27:41.120 --> 00:27:46.720
there's quite a lot of complexity to it or at least there's a lot of heavy lifting because

264
00:27:46.720 --> 00:27:52.400
you've got multiple shards you can re you can call get records for a single shard so then you need to

265
00:27:52.400 --> 00:27:58.400
get first of all find out how many shards there are you establish an integer and then you can

266
00:27:58.400 --> 00:28:04.000
you establish an iterator by calling get shard iterator and the iterator is like a pointer

267
00:28:04.000 --> 00:28:09.120
that the service is maintaining for you and then with that pointer you call get records

268
00:28:10.480 --> 00:28:15.200
but when you establish your connection get an iterator you can specify whether you want to

269
00:28:15.200 --> 00:28:20.960
read from the latest message the oldest message in the stream or you can specify a specific point in

270
00:28:20.960 --> 00:28:27.360
time or a specific record and then once you have your iterator you call get records in sequence

271
00:28:27.360 --> 00:28:34.000
and you can do it up to five times per second and every like we said already i think you can get

272
00:28:34.000 --> 00:28:39.520
10 000 messages in each get records request then you just it's essentially like pagination after

273
00:28:39.520 --> 00:28:44.880
that but of course like there's a bit of complexity in that managing multiple shards

274
00:28:45.520 --> 00:28:51.200
you might need like multi-threading to do that you have to keep track of where each thread is storing

275
00:28:59.040 --> 00:29:04.160
it's you know is what chart each thread is retrieving from and that's one one good analogy that we can use to understand really what's going on there is that imagine that every single shard

276
00:29:04.160 --> 00:29:10.160
is a file that where some all the producers are pretty much appending more and more data

277
00:29:10.720 --> 00:29:15.440
while at the same time you have consumers that have a pointer in every single file

278
00:29:15.440 --> 00:29:19.360
you're trying to track okay this is the point where i arrived consuming the data

279
00:29:19.360 --> 00:29:24.960
and they need to figure out how to move forward not just on one file but for every single shard

280
00:29:24.960 --> 00:29:31.520
you have like one file yeah multiple files multiple pointers with data coming in all the time

281
00:29:39.680 --> 00:29:44.320
in every single file yeah i mean these systems are ultimately very fully featured distributed logs and i do like that i think that's really good analogy if you think of each shard or partition

282
00:29:44.320 --> 00:29:49.600
as just a text file and every record is on a line and then you just need to keep track of

283
00:29:49.600 --> 00:29:57.200
the line number and that's like your iterator um the yeah i mentioned that there's complexity here

284
00:29:57.200 --> 00:30:03.200
so the kinesis client library is a consumer library written in java that aws provides to

285
00:30:03.200 --> 00:30:09.040
make this a bit easier now you do have to understand how it works a little bit it manages

286
00:30:09.040 --> 00:30:16.080
that pool of workers and multi-threading for you and it uses dynamo db to track the state um so it's

287
00:30:16.720 --> 00:30:21.200
has it can recover and it can keep track of things as shards increase and decrease

288
00:30:22.000 --> 00:30:26.640
it does it is written in java it does have some findings for other languages like node js and

289
00:30:26.640 --> 00:30:34.320
python that essentially use the java process running as a daemon and use s standard input

290
00:30:34.320 --> 00:30:40.560
and standard output to communicate with the node js or the python process so that's the consumer

291
00:30:40.560 --> 00:30:46.800
library but there's also a producer library the kpl and that allows you to send messages but it

292
00:30:46.800 --> 00:30:53.040
has multi-threading retry logic batching in there for you and it can also try to reduce the chances

293
00:30:53.040 --> 00:30:58.800
that you're going to get throttled on you know the number of messages per second limit by packing

294
00:30:58.800 --> 00:31:05.360
large numbers of small messages into a single record and that's something that might be complex

295
00:31:05.360 --> 00:31:09.440
to implement yourself but if you use the producer library and the consumer library together

296
00:31:10.240 --> 00:31:15.520
it happens seamlessly for you so i think especially if you're in a java ecosystem and

297
00:31:15.520 --> 00:31:22.480
you're using instances or containers with kinesis those libraries are a good fit but there's still

298
00:31:23.600 --> 00:31:26.800
you still have to understand how they work you still have to manage the extra resources

299
00:31:26.800 --> 00:31:34.160
so the third way of using kinesis is definitely my favorite and that's with lambda so i i've

300
00:31:34.160 --> 00:31:39.680
i've talked enough about the first two do you want to try cover um how lambda works with the

301
00:31:43.520 --> 00:31:49.360
event source mapping that we talked about previously sure yeah i'll try to explain how that works but feel free to add more if i'm missing any important either so we already

302
00:31:49.360 --> 00:31:56.160
explore something similar when we talk about sqs where basically we say sqs has a bunch of api

303
00:31:56.160 --> 00:32:01.120
is for you to fetch the data but then when you use it with lambda it becomes a little bit more

304
00:32:01.120 --> 00:32:05.680
magic and you get a lot of stuff magically integrated and working well out of the box

305
00:32:06.320 --> 00:32:12.480
and the reason why that happens is because lambda has this component called event source mapping

306
00:32:13.040 --> 00:32:19.840
which is basically something that can be used to pull information and trigger a lambda for you

307
00:32:19.840 --> 00:32:25.200
so in the case of kinesis this integration exists as well and basically what you can do you can just

308
00:32:25.200 --> 00:32:31.920
say use a kinesis stream as a source for a lambda and what happens is that as new data is available

309
00:32:31.920 --> 00:32:37.440
in the stream your lambda will be triggered and you will get an event that describes the data

310
00:32:37.440 --> 00:32:43.360
in the stream a little bit more involved than that of course because you might want to configure

311
00:32:43.360 --> 00:32:50.000
how you get the data how many lambda gets executed concurrently and things like that so of course

312
00:32:50.000 --> 00:32:56.160
these integrations don't you can configure and there are specific parameters you can use you can

313
00:32:56.160 --> 00:33:03.680
also do things like aggregations i think it's called tumbling window aggregation so you could

314
00:33:03.680 --> 00:33:09.760
configure this integration too as it's going through the stream aggregate some data and then

315
00:33:09.760 --> 00:33:16.000
trigger your lambda with already a partial aggregated result so you can even let the this

316
00:33:16.000 --> 00:33:21.360
event source mapping do some of the work for you and just trigger the lambda with some partial

317
00:33:21.360 --> 00:33:27.840
value already calculated other interesting thing is that you could define rules to filter events

318
00:33:27.840 --> 00:33:33.280
so you could specify a filter that tells you i'm only interested in triggering the lambda for

319
00:33:33.280 --> 00:33:42.400
events that match certain conditions another interesting one is the batch size window count

320
00:33:42.400 --> 00:33:49.280
uh count so for instance you could say i want to receive let's say i don't know batches with 30

321
00:33:49.280 --> 00:33:56.160
messages so i want to trigger a lambda when i accumulate 30 messages but you can also say unless

322
00:33:56.800 --> 00:34:01.760
maybe a certain amount of time has passed so i want to receive a smaller batch if i'm waiting

323
00:34:01.760 --> 00:34:07.840
too long so you could configure this batch size and window to say what's the maximum amount of

324
00:34:07.840 --> 00:34:13.600
time you want to wait or if you can produce batches of a certain size within that unit

325
00:34:13.600 --> 00:34:19.280
start to trigger the lambda anyway another interesting one is the parallelization factor

326
00:34:19.920 --> 00:34:24.720
which is what is going to tell us how many lambdas we are going to potentially spin up

327
00:34:24.720 --> 00:34:30.320
concurrently for processing that particular data stream and basically what what you can

328
00:34:30.320 --> 00:34:39.200
say you specify this value and that value gives you the number of lambda concurrent repair shard

329
00:34:39.200 --> 00:34:46.480
so let's make an example if you have two shards and you say that parallelization factor is four

330
00:34:52.960 --> 00:34:58.480
i think you get eight up to eight concurrent lambdas at any given point right yeah yeah am i missing an interesting thing i just wanted to chime in there to mention you might be we

331
00:34:58.480 --> 00:35:05.520
mentioned that ordering is strict per shard so if you if you haven't dealt with this with lambda

332
00:35:05.520 --> 00:35:09.200
before you might be wondering well if ordering is strict per shard how can it do concurrent

333
00:35:10.080 --> 00:35:16.800
multiple concurrent lambdas for one shard and event source mapping also manages that for you so

334
00:35:17.360 --> 00:35:23.040
what it means is that if you've got the same partition key so the partition key is quite

335
00:35:23.040 --> 00:35:27.120
important here if you've got the same partition key for a message it will guarantee that messages

336
00:35:27.120 --> 00:35:33.760
for the same partition key will still be order guaranteed for each concurrent lambda processor

337
00:35:33.760 --> 00:35:39.200
so even though the hash key is different it'll it'll it'll let the hash key will allow it to

338
00:35:39.200 --> 00:35:45.120
give that concurrency per shard but you'll still get strict ordering per partition key

339
00:35:46.160 --> 00:35:51.680
within that so it's like an extra level of order guarantee there so it's um it works

340
00:35:51.680 --> 00:35:55.200
pretty well but you just have to make sure that the ordering guarantee matches your expectation

341
00:36:02.160 --> 00:36:06.640
that's an interesting one i was not aware of that one okay do we want to get to the end of this episode by talking maybe maybe about some of the integrations that you will get

342
00:36:07.200 --> 00:36:10.240
with kinesis data streams and other aws services

343
00:36:17.360 --> 00:36:21.440
yeah we mentioned event bridge already because we said we you could take events from event bridge and put them into kinesis data streams to make metrics and all sorts of useful things but there's

344
00:36:21.440 --> 00:36:26.880
also a couple of interesting kind of change data capture possibilities you can do with data streams

345
00:36:27.760 --> 00:36:30.720
you know when people are using streaming applications one of the other use cases we

346
00:36:30.720 --> 00:36:38.080
didn't really talk about is kind of like event sourcing or you're using a complete history of

347
00:36:38.080 --> 00:36:44.720
events to accumulate the state of a system like in a financial application so change data capture is

348
00:36:44.720 --> 00:36:49.520
is quite common in some fields and people are using the changes in the database as an event

349
00:36:49.520 --> 00:36:55.520
it changes in the database as an event source for aggregation for reporting but also for

350
00:36:56.480 --> 00:37:04.160
real-time calculations and you can integrate kinesis data streams into dynamo db and get a

351
00:37:04.160 --> 00:37:11.040
change data capture and also for aurora in rds so it'll give you a continuous stream of database

352
00:37:11.040 --> 00:37:17.520
changes coming from your tables and you can either aggregate that or use it to build accumulate state

353
00:37:17.520 --> 00:37:26.000
based on a history of records so you also got the other two products in the kinesis family and this

354
00:37:26.000 --> 00:37:30.960
is sometimes you know the branding and naming confusion but we talk about kinesis sometimes as

355
00:37:30.960 --> 00:37:34.880
if there's only kinesis data streams but you've also got the other ones do you want to talk about

356
00:37:41.600 --> 00:37:48.320
what those are and what they can give you yeah so you have kinesis data analytics which is if you ever use fling apache fling is something very close to that probably implements the same api or

357
00:37:48.320 --> 00:37:57.600
probably is using yeah but it's basically you can define processing logic and aggregation in real

358
00:37:57.600 --> 00:38:06.960
time directly on the stream so you basically define yeah how to get the data aggregated and

359
00:38:06.960 --> 00:38:13.520
produce new data so it's kind of that analytics use case is the best use case for seeing this

360
00:38:13.520 --> 00:38:21.920
particular kinesis variation the other one is kinesis pharaohs which is also quite common and

361
00:38:21.920 --> 00:38:27.920
the idea is that sometimes you just want to flush all the data in a stream somewhere so rather than

362
00:38:27.920 --> 00:38:33.440
writing all that integration yourself you can use pharaohs and integrates automatically with things

363
00:38:33.440 --> 00:38:41.040
like s3 redshift elastic search or even apis through api gateway or directly calling http

364
00:38:41.040 --> 00:38:47.120
endpoints so that's a good way when you just want to store the data or propagate it somewhere else

365
00:38:47.120 --> 00:38:51.920
you just use pharaohs write it to the stream and let pharaohs do the rest of the integration

366
00:38:55.360 --> 00:39:00.560
you can also use that by the way to connect different kinesis data streams together because

367
00:39:00.560 --> 00:39:05.920
you could use pharaohs to say move the data from one stream to another so the destination

368
00:39:05.920 --> 00:39:13.040
on pharaohs can be another kinesis data stream there is another one i think related to videos

369
00:39:13.040 --> 00:39:17.520
you can even have kinesis video streams but i will leave that aside for this episode because

370
00:39:17.520 --> 00:39:23.280
it's a little bit of a snowflake i think it's the naming is confusing in reality it's in the family

371
00:39:35.280 --> 00:39:40.960
of video services should we mention maybe some material for deep diving on the topic there's there's a must read on kinesis actually i believe because the documentation can be difficult as it

372
00:39:40.960 --> 00:39:49.920
often is but there's a two-part blog post by anahit pogosova which is almost like the de facto manual

373
00:39:49.920 --> 00:39:55.120
i think for kinesis at this point so we'll provide the links to those in the show notes

374
00:39:55.760 --> 00:40:00.800
and everything here we've covered is covered in really just comprehensive detail really well in

375
00:40:00.800 --> 00:40:07.760
those articles we mentioned that we'll be talking about kafka as well so there's a comparison

376
00:40:08.480 --> 00:40:14.960
by the cloud and us guys between kinesis and managed streaming for kafka which is definitely

377
00:40:14.960 --> 00:40:20.160
worth checking out there's accompanying video with that i also saw a really good one in reinvent

378
00:40:20.160 --> 00:40:27.040
2020 which is a deep dive on using lambda specifically with kinesis by hiki park and we'll

379
00:40:27.040 --> 00:40:32.080
provide the link to that one too that talks a lot about how it's implemented under the hood and how

380
00:40:32.080 --> 00:40:37.440
standard consumers work versus enhanced fan out really worth checking out so if you're looking at

381
00:40:37.440 --> 00:40:42.880
kinesis because you have to consider the how they work and the limits so much there's a little bit

382
00:40:42.880 --> 00:40:47.680
more investment in your time as an architect or developer with kinesis and streaming data in

383
00:40:47.680 --> 00:40:53.920
general i think it's worth taking you know a couple of hours looking at those resources and

384
00:41:01.360 --> 00:41:06.880
you'll feel much more prepared that's great yeah i think with this we have covered a lot this is probably our longest episode ever so by the way feel feel free to let us know if you prefer longer

385
00:41:06.880 --> 00:41:11.040
and more in-depth episodes or if you prefer the shorter ones because of course we are always

386
00:41:11.040 --> 00:41:17.840
experimenting and it's great to have your feedback on that with that let's keep in touch make sure to

387
00:41:17.840 --> 00:41:22.400
follow and subscribe if you want to be notified about new episodes especially if you're liking

388
00:41:22.400 --> 00:41:28.240
this event and messaging series you can get notified when we publish the next one which as

389
00:41:28.240 --> 00:41:33.760
owen said is going to be about kafka and again don't forget to connect we are looking forward

390
00:41:33.760 --> 00:41:38.400
for all your opinions and if you have used kinesis we're curious to know your use cases

391
00:41:38.400 --> 00:41:43.600
if you had any trouble with it surprises because all of that it's something that we can share

392
00:41:43.600 --> 00:42:08.800
and learn from each other see you in the next episode bye
