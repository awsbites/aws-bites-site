WEBVTT

1
00:00:00.000 --> 00:00:01.840
Hello, today we are going to answer the question,

2
00:00:01.840 --> 00:00:04.440
what can you do with Kafka on AWS?

3
00:00:04.440 --> 00:00:07.040
We're gonna take you through managed streaming for Kafka

4
00:00:07.040 --> 00:00:10.580
or MSK and the main differences between MSK and Kinesis.

5
00:00:10.580 --> 00:00:12.680
We're also gonna talk about all the features MSK provides

6
00:00:12.680 --> 00:00:15.880
and the advantages over other Kafka options.

7
00:00:15.880 --> 00:00:17.920
We'll talk about scaling characteristics, pricing,

8
00:00:17.920 --> 00:00:21.760
and then how MSK works with a lot of other AWS services.

9
00:00:21.760 --> 00:00:23.800
My name is Eoin, I'm here with Luciano

10
00:00:23.800 --> 00:00:25.720
and this is the AWS Bites podcast.

11
00:00:25.720 --> 00:00:30.720
This is the final episode in our AWS event series.

12
00:00:36.360 --> 00:00:38.080
So the last time we talked about Kinesis

13
00:00:38.080 --> 00:00:40.520
and streaming data, and we're continuing to talk

14
00:00:40.520 --> 00:00:42.480
about streaming data today with Kafka.

15
00:00:42.480 --> 00:00:44.920
So I think Luciano, the last time we said that streaming

16
00:00:44.920 --> 00:00:47.200
is all about processing patches of messages

17
00:00:47.200 --> 00:00:50.320
that are retained in a stream for a longer period of time

18
00:00:50.320 --> 00:00:51.480
so you can replay them.

19
00:00:52.640 --> 00:00:54.640
And it's good for a lot of use cases.

20
00:00:54.640 --> 00:00:57.240
Like we talked about real-time analytics,

21
00:00:57.240 --> 00:01:00.480
stream processing, cool things like event sourcing

22
00:01:00.480 --> 00:01:02.860
and then audit logs, that kind of thing.

23
00:01:02.860 --> 00:01:05.600
I guess Kafka became very popular

24
00:01:05.600 --> 00:01:07.500
for microservices communication as well

25
00:01:07.500 --> 00:01:10.760
because it has such low latency, good delivery guarantees

26
00:01:10.760 --> 00:01:13.320
and has now a really rich ecosystem.

27
00:01:15.640 --> 00:01:18.760
One of the things before we get into the details is,

28
00:01:18.760 --> 00:01:20.680
I think it's fair to say that we don't have as much

29
00:01:20.680 --> 00:01:22.720
experience with Kafka as we do with all the other services

30
00:01:22.720 --> 00:01:24.820
we've talked about in this series.

31
00:01:24.820 --> 00:01:26.760
Like we've both used it in the past,

32
00:01:26.760 --> 00:01:28.640
but a lot of features that we're gonna talk about today,

33
00:01:28.640 --> 00:01:30.040
particularly around MSK,

34
00:01:30.040 --> 00:01:31.380
are things we've used in production.

35
00:01:31.380 --> 00:01:34.200
So we have done the research and evaluated MSK

36
00:01:34.200 --> 00:01:36.640
in various different ways, but we're really interested

37
00:01:36.640 --> 00:01:39.680
if you have any hands-on experience with Kafka and MSK.

38
00:01:39.680 --> 00:01:40.960
Want to share your thoughts and opinions

39
00:01:40.960 --> 00:01:44.400
and how it compares to the alternatives, please reach out.

40
00:01:44.400 --> 00:01:45.760
Yeah, that'd be awesome.

41
00:01:46.640 --> 00:01:48.240
What are the options?

42
00:01:48.240 --> 00:01:50.600
We've talked about, we're not just gonna talk about Kafka

43
00:01:50.600 --> 00:01:53.080
because it's AWS, we're just gonna focus on MSK,

44
00:01:53.080 --> 00:01:56.400
but there's other options out there for cloud-based Kafka

45
00:01:56.400 --> 00:01:58.600
if you don't want to manage it yourself, is that right?

46
00:02:02.140 --> 00:02:04.200
I know at least about two of them that are Confluent Cloud, which historically probably the first one

47
00:02:04.200 --> 00:02:06.040
that they came up with a service like this.

48
00:02:06.040 --> 00:02:08.060
So managed Kafka for you and Confluent,

49
00:02:08.060 --> 00:02:10.240
they are the experts in the market.

50
00:02:10.240 --> 00:02:13.040
They're all about Kafka, they build numbers of plugins,

51
00:02:13.040 --> 00:02:15.480
they contribute to the project itself.

52
00:02:15.480 --> 00:02:18.280
So probably they know their stuff,

53
00:02:18.280 --> 00:02:20.360
but there is also a very new one

54
00:02:20.360 --> 00:02:21.400
that is called AppStash.

55
00:02:21.400 --> 00:02:23.400
We mentioned it previously

56
00:02:23.400 --> 00:02:26.080
regarding their serverless offering for Redis

57
00:02:26.080 --> 00:02:29.240
and they recently launched also an MSK,

58
00:02:29.240 --> 00:02:33.920
equivalent let's say, so managed Kafka on AppStash servers.

59
00:02:33.920 --> 00:02:36.480
So you might want to look at this other alternatives,

60
00:02:36.480 --> 00:02:38.120
maybe they have a different feature set,

61
00:02:38.120 --> 00:02:39.860
maybe different pricing.

62
00:02:39.860 --> 00:02:42.000
So if you're looking for managed Kafka,

63
00:02:42.000 --> 00:02:44.540
don't limit yourself to look at AWS for sure.

64
00:02:46.800 --> 00:02:49.000
Yeah, do we want to start to have a quick walk

65
00:02:49.000 --> 00:02:51.000
through the features of Kafka?

66
00:02:52.520 --> 00:02:53.680
Yeah, let's do that.

67
00:02:53.680 --> 00:02:58.680
So I think with Kinesis you've got, obviously the AWS API,

68
00:02:59.200 --> 00:03:00.960
the SDK for putting messages.

69
00:03:00.960 --> 00:03:03.100
We talked about all that the last time around.

70
00:03:03.100 --> 00:03:06.720
And I know that Kafka has like a producer API,

71
00:03:06.720 --> 00:03:09.080
which does what you would expect.

72
00:03:09.080 --> 00:03:11.600
It's for producing messages and a consumer API, right?

73
00:03:11.600 --> 00:03:13.560
So those are fairly similar concepts

74
00:03:13.560 --> 00:03:14.600
to what we talked about with Kinesis,

75
00:03:14.600 --> 00:03:16.000
but it's got some other APIs as well.

76
00:03:16.000 --> 00:03:17.660
What are those?

77
00:03:19.100 --> 00:03:21.980
Yeah, there is a streams API, which is like a consumer on steroid

78
00:03:21.980 --> 00:03:24.920
and allows you to build like processing pipelines

79
00:03:24.920 --> 00:03:26.680
in real time where you can do aggregation,

80
00:03:26.680 --> 00:03:28.280
filtering, transformation.

81
00:03:28.280 --> 00:03:30.780
And this is probably an alternative to Apache Flink.

82
00:03:30.780 --> 00:03:32.080
Like I don't really,

83
00:03:32.080 --> 00:03:33.320
I'm not really sure how it compares

84
00:03:33.320 --> 00:03:34.440
like pound to pound to Flink,

85
00:03:34.440 --> 00:03:36.020
but it seems that there is a good overlap

86
00:03:36.020 --> 00:03:37.400
in terms of feature set and things

87
00:03:37.400 --> 00:03:39.160
that you can do with this.

88
00:03:39.160 --> 00:03:41.400
Then there is also a connect API,

89
00:03:41.400 --> 00:03:44.600
which is kind of a simplified way

90
00:03:44.600 --> 00:03:48.780
to put data into the Kafka streams

91
00:03:48.780 --> 00:03:51.540
or to read and consume this data from the streams

92
00:03:51.540 --> 00:03:53.220
and maybe move it somewhere else.

93
00:03:53.220 --> 00:03:55.880
Examples that we can find are, I don't know,

94
00:03:55.880 --> 00:03:57.440
for instance, get data from S3

95
00:03:57.440 --> 00:04:00.440
or write data from Kafka to S3

96
00:04:00.440 --> 00:04:02.240
or integrations with Elasticsearch,

97
00:04:02.240 --> 00:04:04.620
maybe for implementing search features

98
00:04:04.620 --> 00:04:09.620
or the Bizium, which I think is a change detection system

99
00:04:11.000 --> 00:04:13.300
that allows you to basically store all the change logs

100
00:04:13.300 --> 00:04:15.360
from your databases into Kafka.

101
00:04:15.360 --> 00:04:16.760
And then you can probably do,

102
00:04:18.000 --> 00:04:19.540
build like event-based systems

103
00:04:19.540 --> 00:04:22.680
from changes happening in your databases.

104
00:04:22.680 --> 00:04:23.540
Yeah, that's cool.

105
00:04:23.540 --> 00:04:26.300
So there's a lot more in terms of the rich feature set

106
00:04:26.300 --> 00:04:28.080
around Kafka than Kinesis,

107
00:04:28.080 --> 00:04:31.440
which is, I suppose, more of a single purpose streaming,

108
00:04:31.440 --> 00:04:32.280
right?

109
00:04:32.280 --> 00:04:34.680
It's just about producing and consuming events.

110
00:04:36.040 --> 00:04:37.920
Yeah, I think there is a little bit of an overlap

111
00:04:37.920 --> 00:04:39.220
with Kinesis Fyros,

112
00:04:39.220 --> 00:04:41.400
but Fyros is only thinking about

113
00:04:41.400 --> 00:04:43.040
once you have the data in your stream,

114
00:04:43.040 --> 00:04:44.680
how do you move it somewhere else?

115
00:04:44.680 --> 00:04:46.840
Here you can also have like data sources

116
00:04:46.840 --> 00:04:50.080
and let them push data into your streams.

117
00:04:50.080 --> 00:04:52.120
So I think it's a richer ecosystem

118
00:04:52.120 --> 00:04:54.320
with more use cases being supported.

119
00:04:55.320 --> 00:04:56.480
Yeah.

120
00:04:56.480 --> 00:04:58.360
And with Kafka, you have the admin API as well,

121
00:04:58.360 --> 00:04:59.440
I suppose that's worth mentioning,

122
00:04:59.440 --> 00:05:02.880
for creating topics and managing your cluster.

123
00:05:02.880 --> 00:05:04.560
Of course, with AWS and MSK,

124
00:05:04.560 --> 00:05:08.400
you can also use the AWS SDK and API

125
00:05:08.400 --> 00:05:10.360
for managing those things as well,

126
00:05:10.360 --> 00:05:11.680
but it doesn't allow you to create topics.

127
00:05:11.680 --> 00:05:14.880
That's something you would do with the Kafka API.

128
00:05:15.880 --> 00:05:18.600
I think Kafka often is so closely associated

129
00:05:18.600 --> 00:05:20.600
with the like enterprise Java ecosystems

130
00:05:20.600 --> 00:05:21.440
and Java based community.

131
00:05:21.440 --> 00:05:23.080
So there's a lot of Java based libraries

132
00:05:23.080 --> 00:05:25.160
and Scala based libraries,

133
00:05:25.160 --> 00:05:27.280
which provide really rich capabilities

134
00:05:27.280 --> 00:05:28.760
and a lot more than you would get

135
00:05:28.760 --> 00:05:31.840
with just the consumer and producer sending messages

136
00:05:31.840 --> 00:05:33.280
and receiving the messages.

137
00:05:34.360 --> 00:05:35.320
Yeah, absolutely.

138
00:05:36.640 --> 00:05:38.720
I know you've used like the Node.js client

139
00:05:38.720 --> 00:05:42.280
and there's other APIs or software packages out there

140
00:05:42.280 --> 00:05:44.040
for working with Kafka.

141
00:05:44.040 --> 00:05:45.520
They're probably not as rich, I guess,

142
00:05:45.520 --> 00:05:47.200
as the Java ones, right?

143
00:05:47.200 --> 00:05:49.040
Yeah, Java, I think is kind of the default

144
00:05:49.040 --> 00:05:51.720
and the one that gets all the new shiny features

145
00:05:51.720 --> 00:05:53.360
before everyone else.

146
00:05:53.360 --> 00:05:55.240
But I suppose, depending on your use cases

147
00:05:55.240 --> 00:05:57.920
and the languages that you are using for your project,

148
00:05:57.920 --> 00:05:59.720
you'll find good enough clients

149
00:05:59.720 --> 00:06:02.080
for pretty much most of the mainstream

150
00:06:02.080 --> 00:06:03.240
programming languages.

151
00:06:03.240 --> 00:06:06.240
Yeah, probably maintained by the community, I guess, right?

152
00:06:06.240 --> 00:06:08.480
Rather than the Kafka core teams.

153
00:06:08.480 --> 00:06:10.000
So what are the two different terms?

154
00:06:10.000 --> 00:06:12.520
I know that they tend to use different terms

155
00:06:12.520 --> 00:06:14.240
for the same thing between Kinesis and Kafka.

156
00:06:14.240 --> 00:06:16.920
So what are the one-to-one mappings here?

157
00:06:16.920 --> 00:06:18.080
Yeah, that's an interesting topic

158
00:06:18.080 --> 00:06:20.480
because if you are coming from Kinesis

159
00:06:20.480 --> 00:06:22.480
and looking at Kafka or vice versa,

160
00:06:22.480 --> 00:06:24.520
coming from Kafka and looking at Kinesis,

161
00:06:24.520 --> 00:06:26.600
it might be a little bit confusing to get used

162
00:06:26.600 --> 00:06:30.200
to slightly different terminology for similar concepts.

163
00:06:30.200 --> 00:06:32.640
But the first concept that exists only in Kafka

164
00:06:32.640 --> 00:06:34.000
is the idea of a broker,

165
00:06:34.000 --> 00:06:36.520
which is not really applicable to Kinesis data stream

166
00:06:36.520 --> 00:06:38.920
because that concept is totally abstracted to you.

167
00:06:38.920 --> 00:06:41.080
A broker is literally an instance

168
00:06:41.080 --> 00:06:43.360
that is part of your Kafka cluster.

169
00:06:43.360 --> 00:06:45.880
And we don't get to see that in Kinesis

170
00:06:45.880 --> 00:06:49.480
because AWS is kind of hiding all of that complexity.

171
00:06:49.480 --> 00:06:51.280
Then we have the concept of a topic,

172
00:06:51.280 --> 00:06:53.360
which in Kafka is called topic

173
00:06:53.360 --> 00:06:55.960
and it's pretty much equivalent to stream in Kinesis.

174
00:06:55.960 --> 00:06:59.640
So it's the idea of one logical stream

175
00:06:59.640 --> 00:07:00.600
where you put your data,

176
00:07:00.600 --> 00:07:03.120
you will call that topic in Kafka.

177
00:07:03.120 --> 00:07:04.800
Then we have the idea of partition.

178
00:07:04.800 --> 00:07:06.480
Again, partition is the Kafka topic,

179
00:07:06.480 --> 00:07:09.720
but we used to call that shard in Kinesis.

180
00:07:09.720 --> 00:07:12.400
So the idea of once you have a topic or a stream,

181
00:07:12.400 --> 00:07:16.040
how do you distribute the data in that topic

182
00:07:16.040 --> 00:07:18.120
into multiple instances?

183
00:07:18.120 --> 00:07:21.200
And then we have the concept of producers and consumer,

184
00:07:21.200 --> 00:07:23.640
which surprisingly is the only terminology

185
00:07:23.640 --> 00:07:25.960
that matches in both systems.

186
00:07:25.960 --> 00:07:29.360
And finally we have offset, which is a Kafka terminology

187
00:07:29.360 --> 00:07:31.560
and iterator is the equivalent in Kinesis.

188
00:07:31.560 --> 00:07:34.040
So the idea that as you are consuming the data,

189
00:07:34.040 --> 00:07:36.040
you are like reading a transaction log.

190
00:07:36.040 --> 00:07:38.520
So you have a pointer that is basically used

191
00:07:38.520 --> 00:07:42.400
to keep track of where are you at reading all this data.

192
00:07:42.400 --> 00:07:43.680
So the data is always coming in.

193
00:07:43.680 --> 00:07:44.840
So you're trying to catch up

194
00:07:44.840 --> 00:07:46.400
and process the data real time.

195
00:07:46.400 --> 00:07:50.320
So that offset or iterator is what tells the whole system

196
00:07:50.320 --> 00:07:52.760
what to read next, basically.

197
00:07:52.760 --> 00:07:53.600
Interesting.

198
00:07:53.600 --> 00:07:55.440
And I know we were talking about watching the iterator age

199
00:07:55.440 --> 00:07:56.720
when you were talking about Kinesis.

200
00:07:56.720 --> 00:08:00.600
I think there's also like this offset lag metric in Kafka,

201
00:08:00.600 --> 00:08:03.480
which is, I guess, pretty much one-to-one.

202
00:08:03.480 --> 00:08:04.840
Yeah, probably it is, yeah.

203
00:08:04.840 --> 00:08:09.120
Okay, so should we maybe mention more differences

204
00:08:09.120 --> 00:08:10.240
with Kinesis?

205
00:08:10.240 --> 00:08:12.880
Is there something else that comes to mind for you?

206
00:08:12.880 --> 00:08:15.880
Yeah, I think when we were talking about this earlier,

207
00:08:15.880 --> 00:08:19.560
you made the point that comparing Kafka sync,

208
00:08:19.560 --> 00:08:22.560
Kafka's, Kinesis and Kafka is like comparing SQS

209
00:08:22.560 --> 00:08:23.520
to RabbitMQ.

210
00:08:24.600 --> 00:08:27.600
One is much more simpler, one is much more feature rich.

211
00:08:27.600 --> 00:08:29.280
And so Kafka has a lot of features

212
00:08:29.280 --> 00:08:30.720
and configuration options,

213
00:08:30.720 --> 00:08:32.920
but in exchange for that richer set of features,

214
00:08:32.920 --> 00:08:35.680
you get increased complexity as you might expect.

215
00:08:36.520 --> 00:08:38.240
And you also talked about these brokers.

216
00:08:38.240 --> 00:08:40.800
So Kafka has this cluster provisioning model

217
00:08:40.800 --> 00:08:42.040
where you need to scale brokers

218
00:08:42.040 --> 00:08:44.920
and think about disk size and memory and network,

219
00:08:44.920 --> 00:08:46.520
all those wonderful things.

220
00:08:46.520 --> 00:08:50.160
And you can create as many topics as you want,

221
00:08:50.160 --> 00:08:54.240
and you just need to scale your resources accordingly.

222
00:08:54.240 --> 00:08:56.360
And you can also create lots of consumers.

223
00:08:57.560 --> 00:09:00.080
There's a whole complexity

224
00:09:00.080 --> 00:09:02.280
around managing cluster state as well.

225
00:09:02.280 --> 00:09:03.960
I wanna go into that.

226
00:09:03.960 --> 00:09:07.920
Does this whole duality with Kafka

227
00:09:07.920 --> 00:09:10.000
where you need to think about your Kafka configuration

228
00:09:10.000 --> 00:09:13.920
and your Zookeeper configuration, what's that all about?

229
00:09:13.920 --> 00:09:17.160
Yeah, so basically the way that Kafka works,

230
00:09:17.160 --> 00:09:18.800
because of course it's a distributed system,

231
00:09:18.800 --> 00:09:21.760
it needs to replicate data across multiple nodes.

232
00:09:21.760 --> 00:09:24.680
And also you have consumers and the system needs

233
00:09:24.680 --> 00:09:28.040
to keep track of the state of each consumer.

234
00:09:28.040 --> 00:09:29.720
So there is a lot of information

235
00:09:29.720 --> 00:09:30.800
that is kind of distributed

236
00:09:30.800 --> 00:09:34.280
and needs to be kept in sync across different nodes.

237
00:09:34.280 --> 00:09:37.280
And all of that, as many other Apache projects,

238
00:09:37.280 --> 00:09:40.640
is managed by another system that is called Zookeeper.

239
00:09:40.640 --> 00:09:42.720
And Zookeeper is something that needs to be provisioned

240
00:09:42.720 --> 00:09:46.280
in a multi instance mode as well.

241
00:09:46.280 --> 00:09:49.840
And we need to make sure it's highly available

242
00:09:49.840 --> 00:09:51.160
and resilient because of course,

243
00:09:51.160 --> 00:09:54.080
that the cluster is healthy only

244
00:09:54.080 --> 00:09:56.240
if Zookeeper is available all the time.

245
00:09:56.240 --> 00:09:58.360
So it's an additional piece of complexity

246
00:09:58.360 --> 00:09:59.320
that you get with Kafka.

247
00:09:59.320 --> 00:10:01.840
But the interesting thing is that in MSK,

248
00:10:01.840 --> 00:10:04.640
all this complexity is managed by AWS for you.

249
00:10:04.640 --> 00:10:07.800
And also the pricing, this is actually the interesting bit,

250
00:10:07.800 --> 00:10:11.000
is something that you don't pay any additional costs

251
00:10:11.000 --> 00:10:12.040
for Zookeeper.

252
00:10:12.040 --> 00:10:14.480
So it's something that it's somewhat included

253
00:10:14.480 --> 00:10:16.000
in your MSK offering.

254
00:10:16.000 --> 00:10:19.160
So AWS is kind of absorbing that cost for you

255
00:10:19.160 --> 00:10:21.760
or kind of abstracting that cost in different ways

256
00:10:21.760 --> 00:10:23.480
in the whole MSK offering.

257
00:10:23.480 --> 00:10:25.080
But it's not something you need to think about

258
00:10:25.080 --> 00:10:27.840
in terms how many instances I'm gonna use for Zookeeper,

259
00:10:27.840 --> 00:10:30.880
what kind of size and how that is gonna impact cost.

260
00:10:30.880 --> 00:10:35.240
It's not really affecting the cost scheme in MSK.

261
00:10:35.240 --> 00:10:38.000
An interesting thing is that I think this has been

262
00:10:38.000 --> 00:10:41.000
a long running conversation in the Kafka community

263
00:10:41.000 --> 00:10:44.040
on whether they should get eventually read on Zookeeper

264
00:10:44.040 --> 00:10:45.760
and have this kind of internal mechanism

265
00:10:45.760 --> 00:10:47.800
to synchronize all the data.

266
00:10:47.800 --> 00:10:50.680
And as far as I can tell by reading some blog posts,

267
00:10:50.680 --> 00:10:52.040
there has been a lot of progress.

268
00:10:52.040 --> 00:10:56.320
And since version 2.8, I think it starts to be feasible

269
00:10:56.320 --> 00:10:59.480
to run a Kafka cluster without Zookeeper at all.

270
00:10:59.480 --> 00:11:02.040
I don't think it's the recommended approach so far.

271
00:11:02.040 --> 00:11:05.840
And also in MSK, it's not really clear what happens

272
00:11:05.840 --> 00:11:07.520
if you use 2.8.

273
00:11:07.520 --> 00:11:10.280
I think it still uses Zookeeper,

274
00:11:10.280 --> 00:11:13.040
but you don't get like a flag, use Zookeeper or not.

275
00:11:13.040 --> 00:11:15.320
It doesn't matter, I guess, with MSK anyway, really, right?

276
00:11:15.320 --> 00:11:16.800
If it's all managed for you. Exactly.

277
00:11:16.800 --> 00:11:17.640
Yeah.

278
00:11:17.640 --> 00:11:19.240
Okay, cool.

279
00:11:19.240 --> 00:11:22.280
I know that as related with all AWS services,

280
00:11:22.280 --> 00:11:23.720
Kinesis uses HTTP,

281
00:11:23.720 --> 00:11:26.440
but Kafka has its own TCP based protocols.

282
00:11:26.440 --> 00:11:29.160
I guess some efficiency can come from that.

283
00:11:30.240 --> 00:11:33.400
There's also changed a difference in the delivery guarantees.

284
00:11:33.400 --> 00:11:35.200
We've talked a lot across this whole series

285
00:11:35.200 --> 00:11:37.480
about at least once processing

286
00:11:37.480 --> 00:11:39.560
and at most once processing.

287
00:11:39.560 --> 00:11:42.680
Kafka is one of the rare things that actually has support

288
00:11:42.680 --> 00:11:45.760
for exactly once delivery of messages.

289
00:11:45.760 --> 00:11:47.360
But I think this doesn't work for all consumers.

290
00:11:47.360 --> 00:11:49.360
You need to be really sure of what you're doing

291
00:11:49.360 --> 00:11:51.560
and understand how Kafka transactions work.

292
00:11:51.560 --> 00:11:54.320
But it is supported in things like Kafka Streams.

293
00:11:54.320 --> 00:11:57.800
So that can be important for me, right?

294
00:11:57.800 --> 00:12:00.760
If you don't want to have to build IAM potency

295
00:12:00.760 --> 00:12:02.640
and you really need those guarantees.

296
00:12:04.000 --> 00:12:05.040
So the provisioning model then,

297
00:12:05.040 --> 00:12:06.560
we talked about brokers and everything.

298
00:12:06.560 --> 00:12:09.080
Kinesis uses throughput provisioning.

299
00:12:09.080 --> 00:12:10.840
We talked about that and it's very clear.

300
00:12:10.840 --> 00:12:12.080
The number of shards,

301
00:12:12.080 --> 00:12:14.800
a single shard has very clear throughput limits.

302
00:12:14.800 --> 00:12:17.720
And if you want more throughput, you need more shards.

303
00:12:17.720 --> 00:12:20.320
But you have limits with the number of consumers then, right?

304
00:12:20.320 --> 00:12:22.120
Because if you've got a consumer,

305
00:12:22.120 --> 00:12:26.960
you can only read like a megabyte a second from that shard

306
00:12:26.960 --> 00:12:29.000
and you've got these enhanced consumers to help a little bit.

307
00:12:29.000 --> 00:12:31.120
But Kafka, you can really have as many consumers

308
00:12:31.120 --> 00:12:32.280
as you want, right?

309
00:12:32.280 --> 00:12:33.160
You just need to again,

310
00:12:33.160 --> 00:12:37.120
make sure you've got the CPU storage and partition setup.

311
00:12:37.120 --> 00:12:40.120
Yeah, I think Kafka is a little bit more traditional way

312
00:12:40.120 --> 00:12:42.640
of thinking about a cloud service

313
00:12:42.640 --> 00:12:44.760
where you have a set of instances

314
00:12:44.760 --> 00:12:46.280
that are taking the heat for everything

315
00:12:46.280 --> 00:12:47.920
you want to do with them.

316
00:12:47.920 --> 00:12:50.960
And you might have, I don't know, very small topics

317
00:12:50.960 --> 00:12:53.400
and very few big topics,

318
00:12:53.400 --> 00:12:55.880
and maybe your cluster will be able to deal

319
00:12:55.880 --> 00:12:57.680
with all of them at the scale you need.

320
00:12:57.680 --> 00:12:59.760
So you don't really get to think in terms of topics,

321
00:12:59.760 --> 00:13:02.160
but more what are, like is the system under stress?

322
00:13:02.160 --> 00:13:05.480
Is the CPU or the storage enough for my workload?

323
00:13:05.480 --> 00:13:07.360
So you need to look at all these metrics

324
00:13:07.360 --> 00:13:09.760
rather than having like a fixed unit

325
00:13:09.760 --> 00:13:12.920
and you just scale based proportionally on that unit.

326
00:13:12.920 --> 00:13:14.760
Yeah, so it could be much more complicated,

327
00:13:14.760 --> 00:13:16.640
but also I suppose more flexible

328
00:13:16.640 --> 00:13:19.520
if you have very diverse type of topics

329
00:13:19.520 --> 00:13:22.960
and very diverse throughput logics or functions,

330
00:13:22.960 --> 00:13:25.480
I guess, across different topics.

331
00:13:25.480 --> 00:13:27.240
Okay, okay.

332
00:13:27.240 --> 00:13:28.520
And what about retention?

333
00:13:28.520 --> 00:13:30.160
Because Kinesis has,

334
00:13:30.160 --> 00:13:31.920
they actually increased the maximum retention

335
00:13:31.920 --> 00:13:35.000
from seven days to one year, not so long ago,

336
00:13:35.000 --> 00:13:37.240
but Kafka doesn't have any limits, right?

337
00:13:37.240 --> 00:13:38.880
Yeah, I suppose the idea with Kafka is,

338
00:13:38.880 --> 00:13:40.760
again, it's up to you to decide.

339
00:13:40.760 --> 00:13:43.160
And if you have enough disk space,

340
00:13:43.160 --> 00:13:45.120
you can start the data as long as you want.

341
00:13:45.120 --> 00:13:50.120
There is no intrinsic limit after which the data is lost.

342
00:13:52.560 --> 00:13:54.240
Yeah, there's a clear benefit there if you're using it for advanced sourcing

343
00:13:54.240 --> 00:13:55.560
and if you want to rebuild your state

344
00:13:55.560 --> 00:13:57.560
at any time in the future.

345
00:13:57.560 --> 00:14:00.280
Are there any other differences between Kinesis and Kafka

346
00:14:00.280 --> 00:14:02.400
that we should cover off?

347
00:14:02.400 --> 00:14:04.560
Yeah, an interesting one we mentioned

348
00:14:04.560 --> 00:14:07.440
is a little bit already is that being an open source project

349
00:14:07.440 --> 00:14:09.200
has been around for a long time

350
00:14:09.200 --> 00:14:10.840
and it's probably has been like the promoter

351
00:14:10.840 --> 00:14:13.240
and like the first real project in this space

352
00:14:13.240 --> 00:14:16.440
that then maybe started Kinesis and everything else.

353
00:14:17.760 --> 00:14:19.400
There is a lot of history there

354
00:14:19.400 --> 00:14:21.560
and of course the ecosystem is really good

355
00:14:21.560 --> 00:14:23.640
and there are a lot of open source tools.

356
00:14:23.640 --> 00:14:26.680
For instance, you can find all sorts of different admin UIs

357
00:14:26.680 --> 00:14:30.760
that can help you to build the data in a cluster

358
00:14:30.760 --> 00:14:32.440
and understand what's going on.

359
00:14:32.440 --> 00:14:35.600
Or also there are tools that allow you to define schema

360
00:14:35.600 --> 00:14:37.840
and have this kind of validation

361
00:14:37.840 --> 00:14:40.040
that all the data you ingest in your Kafka

362
00:14:40.040 --> 00:14:43.400
is somewhat compliant with schema you defined

363
00:14:43.400 --> 00:14:46.280
or to do discovery of you have been ingesting

364
00:14:46.280 --> 00:14:49.400
different messages that they will extrapolate the schema

365
00:14:49.400 --> 00:14:51.720
from your messages and you can easily visualize that.

366
00:14:51.720 --> 00:14:54.520
So all this kind of interesting stuff is available to you

367
00:14:55.400 --> 00:14:56.920
because there is an entire community

368
00:14:56.920 --> 00:14:59.000
that are building tools and building products

369
00:14:59.000 --> 00:15:01.200
on top of Kafka and sharing what they learn.

370
00:15:03.080 --> 00:15:04.840
Okay, yeah, I guess that sounds like it.

371
00:15:04.840 --> 00:15:07.080
I mean, other benefits, I think in terms of latency

372
00:15:07.080 --> 00:15:08.960
they both have a pretty low latency,

373
00:15:08.960 --> 00:15:10.880
you know, like 100 millisecond latency.

374
00:15:10.880 --> 00:15:13.000
So they're pretty similar in that regard.

375
00:15:14.280 --> 00:15:16.960
So let's talk about how you get going with MSK

376
00:15:16.960 --> 00:15:17.920
and how you set it up.

377
00:15:17.920 --> 00:15:20.600
So there's two modes we're gonna talk about

378
00:15:20.600 --> 00:15:23.080
because we've got MSK as it has existed

379
00:15:23.080 --> 00:15:24.080
for a couple of years now

380
00:15:24.080 --> 00:15:26.960
but we've also got the preview for MSK serverless.

381
00:15:26.960 --> 00:15:30.600
So for the brokers first, I know that we talked about

382
00:15:30.600 --> 00:15:31.760
what you have to scale.

383
00:15:31.760 --> 00:15:34.760
So when you set it up, you have to create,

384
00:15:34.760 --> 00:15:36.160
you have to select your instance type.

385
00:15:36.160 --> 00:15:38.320
So you get a number of options there

386
00:15:38.320 --> 00:15:40.120
and the minimum kind of production level one

387
00:15:40.120 --> 00:15:41.680
is like an M5 large.

388
00:15:42.680 --> 00:15:44.480
You can also, they do offer a small one

389
00:15:44.480 --> 00:15:46.000
for development workloads

390
00:15:46.000 --> 00:15:48.880
but generally because it's a distributed system

391
00:15:48.880 --> 00:15:50.560
and it needs a core room in order to make sure

392
00:15:50.560 --> 00:15:52.000
that state is reliable,

393
00:15:52.000 --> 00:15:54.800
you need to kind of want three brokers minimum.

394
00:15:54.800 --> 00:15:57.160
You probably wanna set up three brokers

395
00:15:57.160 --> 00:15:59.280
across three availability zones.

396
00:15:59.280 --> 00:16:00.960
So you might think about that.

397
00:16:00.960 --> 00:16:03.280
I'm not sure what the story is with inter AZ traffic.

398
00:16:03.280 --> 00:16:04.760
Usually that's something you have to pay for.

399
00:16:04.760 --> 00:16:09.760
So I would be observing that if I was using a cluster

400
00:16:10.400 --> 00:16:15.280
in AWS with a lot of traffic, think about the cost there.

401
00:16:15.280 --> 00:16:18.120
And then you can set the number of brokers in each AZ.

402
00:16:18.120 --> 00:16:23.120
So you might end up with a six broker set up by default.

403
00:16:23.440 --> 00:16:24.840
Probably get away with three,

404
00:16:26.360 --> 00:16:28.560
you need to then think about EBS volumes

405
00:16:28.560 --> 00:16:29.760
for your data storage, right?

406
00:16:29.760 --> 00:16:31.480
If you're gonna use infinite storage,

407
00:16:31.480 --> 00:16:33.480
you need to know where it's gonna be held

408
00:16:33.480 --> 00:16:36.760
and of course, because it's an instance based thing,

409
00:16:36.760 --> 00:16:37.840
you need to set up a VPC.

410
00:16:37.840 --> 00:16:41.400
It needs networking and security groups, private subnets.

411
00:16:42.600 --> 00:16:44.280
So there's all of that to set up.

412
00:16:45.440 --> 00:16:48.240
In terms of security then, I think you'll have to select

413
00:16:48.240 --> 00:16:49.920
which authentication mechanism you support

414
00:16:49.920 --> 00:16:52.400
and it supports five options.

415
00:16:52.400 --> 00:16:54.640
One of them being no authentication at all.

416
00:16:54.640 --> 00:16:56.480
So I could probably exclude that one.

417
00:16:58.000 --> 00:16:58.840
Don't do that.

418
00:16:58.840 --> 00:17:01.640
But you have username password authentication

419
00:17:01.640 --> 00:17:05.000
to have this SaaS protocol you can use.

420
00:17:05.000 --> 00:17:07.480
And you put this as with like you would with RDS,

421
00:17:07.480 --> 00:17:10.200
you can put the password and username in secrets manager

422
00:17:10.200 --> 00:17:12.280
and MSK will use that.

423
00:17:12.280 --> 00:17:13.880
And then you can use that on your clients.

424
00:17:13.880 --> 00:17:15.880
You can also use TLS authentication.

425
00:17:15.880 --> 00:17:18.040
And the interesting one there with MSK,

426
00:17:18.040 --> 00:17:19.160
which is different to other options

427
00:17:19.160 --> 00:17:21.400
is that you can use IAM authentication.

428
00:17:21.400 --> 00:17:25.320
So they, you can imagine AWS have patched Kafka

429
00:17:25.320 --> 00:17:27.680
to support IAM as an authentication mechanism.

430
00:17:29.560 --> 00:17:30.400
So that's setting it up.

431
00:17:30.400 --> 00:17:33.440
And then once you set it up, you would create a topic.

432
00:17:33.440 --> 00:17:36.040
So this is a slight difference because when with Kinesis,

433
00:17:36.040 --> 00:17:40.560
you would configure a stream as a resource,

434
00:17:40.560 --> 00:17:41.600
as an AWS resource.

435
00:17:41.600 --> 00:17:42.760
With MSK, you don't, right?

436
00:17:42.760 --> 00:17:44.840
You configure the cluster as the resource

437
00:17:44.840 --> 00:17:47.980
and then you use the Kafka API to create your topics.

438
00:17:47.980 --> 00:17:48.980
And when you create a topic,

439
00:17:48.980 --> 00:17:51.560
then you can specify how many partitions

440
00:17:51.560 --> 00:17:54.600
and how many brokers you need to replicate that across.

441
00:17:54.600 --> 00:17:57.160
So how do you think that sounds?

442
00:17:57.160 --> 00:17:59.040
There's quite a lot in there.

443
00:17:59.040 --> 00:18:01.040
It feels again, a little bit more traditional,

444
00:18:01.040 --> 00:18:03.800
like comparing, I don't know, RDS to DynamoDB as well,

445
00:18:03.800 --> 00:18:07.160
where RDS you provision, like I want to use, I don't know,

446
00:18:07.160 --> 00:18:08.560
an instance of Postgres,

447
00:18:08.560 --> 00:18:11.640
but then you maybe you don't create any table in it, right?

448
00:18:11.640 --> 00:18:13.760
Creating a table means you connect to the database,

449
00:18:13.760 --> 00:18:15.980
you run SQL and you create tables.

450
00:18:15.980 --> 00:18:19.200
While in DynamoDB, when you decide to create a table,

451
00:18:19.200 --> 00:18:20.680
then you are creating an AWS resource

452
00:18:20.680 --> 00:18:22.220
that represents that table.

453
00:18:22.220 --> 00:18:25.400
So I think it's a similar kind of mindset

454
00:18:25.400 --> 00:18:29.540
when it comes to comparing MSK with Kinesis.

455
00:18:29.540 --> 00:18:30.780
Yeah.

456
00:18:30.780 --> 00:18:32.120
Yeah.

457
00:18:32.120 --> 00:18:33.880
So to make all this easier,

458
00:18:33.880 --> 00:18:37.140
last year we had an announcement that MSK serverless

459
00:18:37.140 --> 00:18:38.980
was in preview mode.

460
00:18:38.980 --> 00:18:40.620
So, and it's in preview.

461
00:18:40.620 --> 00:18:42.420
When I used MSK serverless,

462
00:18:42.420 --> 00:18:45.260
it was only available in US East to Ohio,

463
00:18:45.260 --> 00:18:46.280
but hot off the press,

464
00:18:46.280 --> 00:18:50.280
it's now available in EU West one, Dublin, Ireland as well.

465
00:18:51.580 --> 00:18:53.620
So how, what kind of a difference do you think

466
00:18:53.620 --> 00:18:55.420
that will make and how does it function compared

467
00:18:55.420 --> 00:18:57.900
to the laborious configuration,

468
00:18:57.900 --> 00:18:59.500
how do you set up by just talk through

469
00:18:59.500 --> 00:19:01.340
for the provision mode?

470
00:19:01.340 --> 00:19:04.180
Yeah, my expectation is that MSK serverless

471
00:19:04.180 --> 00:19:07.180
will try to remove a lot of these concerns

472
00:19:07.180 --> 00:19:08.820
that we just discussed in terms,

473
00:19:08.820 --> 00:19:10.280
how do you even get started?

474
00:19:10.280 --> 00:19:13.020
How do you, like before you create a topic, what do you do?

475
00:19:13.020 --> 00:19:17.380
So I think this will try to give you a more immediate usage

476
00:19:17.380 --> 00:19:20.220
and provisioning of MSK that is probably similar

477
00:19:20.220 --> 00:19:22.580
to the user experience you will get with Kinesis.

478
00:19:22.580 --> 00:19:25.540
And in fact, there is a very clear unit of scale,

479
00:19:25.540 --> 00:19:27.820
which is the right throughput.

480
00:19:29.380 --> 00:19:32.980
And you can, you have like limits that are more set in stone

481
00:19:32.980 --> 00:19:36.300
because of course AWS will take a lot of the work for you.

482
00:19:36.300 --> 00:19:38.780
So they will need to work with certain limits

483
00:19:38.780 --> 00:19:40.140
and you have storage limits,

484
00:19:40.140 --> 00:19:44.220
I think it's 250 gigabytes per partition,

485
00:19:44.220 --> 00:19:45.900
one day retention,

486
00:19:45.900 --> 00:19:50.260
and then you have a maximum of 120 partition, I believe,

487
00:19:50.260 --> 00:19:51.820
which maybe can be increased.

488
00:19:51.820 --> 00:19:53.660
Correct me if I'm wrong.

489
00:19:55.380 --> 00:19:57.860
Yeah, I think this is probably just because it's in preview mode and they just put a cap on it,

490
00:19:57.860 --> 00:20:00.180
but yeah, you would expect all those limits to increase

491
00:20:00.180 --> 00:20:03.180
because they're not particularly high.

492
00:20:03.180 --> 00:20:05.020
Yeah, yeah, yeah, definitely.

493
00:20:05.020 --> 00:20:07.940
And then you have IAM authentication only.

494
00:20:07.940 --> 00:20:09.780
And one interesting thing is that you might think,

495
00:20:09.780 --> 00:20:12.880
okay, I'm gonna, maybe I want to work with Kafka

496
00:20:12.880 --> 00:20:14.800
because this is what I'm using for my product.

497
00:20:14.800 --> 00:20:17.200
I'm migrating to AWS.

498
00:20:17.200 --> 00:20:19.980
Probably the safest bet is to start with MSK.

499
00:20:19.980 --> 00:20:21.860
And then if you are starting to do okay,

500
00:20:21.860 --> 00:20:23.500
but eventually I would want to serverless

501
00:20:23.500 --> 00:20:26.380
because that will remove a lot of the complexity for me.

502
00:20:26.380 --> 00:20:28.820
Then what you could probably do in the future is

503
00:20:28.820 --> 00:20:32.020
you start with MSK and then you can transition

504
00:20:32.020 --> 00:20:34.740
to MSK serverless by migrating all your data.

505
00:20:34.740 --> 00:20:37.280
And one of the tools that I think is one of the most common

506
00:20:37.280 --> 00:20:39.020
used in Kafka is mirror maker

507
00:20:39.020 --> 00:20:42.260
to move data across Kafka clusters.

508
00:20:42.260 --> 00:20:45.240
So you can probably do that to migrate your data

509
00:20:45.240 --> 00:20:50.240
from traditional MSK to MSK serverless.

510
00:20:51.740 --> 00:20:55.540
Yeah, should we talk about monitoring maybe?

511
00:20:55.540 --> 00:20:58.540
Like what do you do once you have everything up and running?

512
00:20:58.540 --> 00:21:01.260
How do we make sure it's actually doing what we want

513
00:21:01.260 --> 00:21:02.860
and it's healthy?

514
00:21:02.860 --> 00:21:05.240
Yeah, well, more configuration will inevitably mean

515
00:21:05.240 --> 00:21:06.980
more things to monitor.

516
00:21:06.980 --> 00:21:10.180
And that's something you'll get with Kafka.

517
00:21:10.180 --> 00:21:13.060
So you could configure the monitoring level

518
00:21:13.060 --> 00:21:13.900
three different options.

519
00:21:13.900 --> 00:21:17.740
You can set it to be like per broker, per topic

520
00:21:17.740 --> 00:21:20.020
or per topic per partition.

521
00:21:20.020 --> 00:21:22.580
And that will give you, I think it's like between

522
00:21:22.580 --> 00:21:26.620
around 40 and 90 metrics to monitor with MSK.

523
00:21:26.620 --> 00:21:28.500
And that depends on the level of the,

524
00:21:28.500 --> 00:21:30.740
obviously the monitoring level you have set.

525
00:21:30.740 --> 00:21:33.660
So the fact that there you have up to 90 metrics to monitor

526
00:21:33.660 --> 00:21:36.980
will give you some indication of the kind of infrastructure

527
00:21:36.980 --> 00:21:40.980
and maintenance complexity with a traditional Kafka.

528
00:21:40.980 --> 00:21:44.440
It's also worth mentioning that built into MSK support

529
00:21:44.440 --> 00:21:46.760
for open monitoring with Prometheus,

530
00:21:47.800 --> 00:21:49.400
a lot of people will be using.

531
00:21:49.400 --> 00:21:50.360
And then in terms of logging,

532
00:21:50.360 --> 00:21:51.600
you can set up your broker logs

533
00:21:51.600 --> 00:21:55.760
like to go to CloudWatch logs or S3 or firehose.

534
00:21:55.760 --> 00:21:58.580
So that's obviously you want to create a lot of alarms

535
00:21:58.580 --> 00:22:00.880
and keep an eye on all those metrics.

536
00:22:00.880 --> 00:22:04.560
And there's also a lot of integrations between MSK

537
00:22:04.560 --> 00:22:07.680
and for something that's relatively new,

538
00:22:07.680 --> 00:22:11.080
it's pretty impressive the list of integrations.

539
00:22:11.080 --> 00:22:12.480
I know that Kinesis Data Analytics

540
00:22:12.480 --> 00:22:14.800
not doesn't just work with Kinesis Data Streams.

541
00:22:14.800 --> 00:22:17.620
You can use it with Kafka as well.

542
00:22:17.620 --> 00:22:19.060
So then you can do stream processing.

543
00:22:19.060 --> 00:22:20.880
If you don't want to use the streams API in Kafka,

544
00:22:20.880 --> 00:22:23.640
you could use Flink on Kinesis Data Analytics

545
00:22:23.640 --> 00:22:26.200
because that is essentially a managed Flink.

546
00:22:26.200 --> 00:22:28.280
You can also run Flink on EMR.

547
00:22:28.280 --> 00:22:31.440
So you can integrate your streams with EMR.

548
00:22:31.440 --> 00:22:33.040
And I also noticed that you were talking about,

549
00:22:33.040 --> 00:22:35.120
when you're talking about schema registry support

550
00:22:35.120 --> 00:22:37.640
within Kafka, there's a product called the Glue

551
00:22:37.640 --> 00:22:40.520
Schema Registry as well, which is essentially

552
00:22:40.520 --> 00:22:43.840
a schema registry for real-time streaming.

553
00:22:43.840 --> 00:22:47.440
So you can have like Avro schemas and JSON schemas

554
00:22:47.440 --> 00:22:50.620
and protobuf schemas and enforce the data structure

555
00:22:50.620 --> 00:22:53.220
on the producer side and consumer side using that.

556
00:22:55.000 --> 00:22:57.560
But I think the most interesting is probably Lambda, right?

557
00:22:57.560 --> 00:22:58.560
Lambda integration.

558
00:22:59.820 --> 00:23:00.840
Yeah, yeah.

559
00:23:00.840 --> 00:23:03.440
And this is again, something which is,

560
00:23:03.440 --> 00:23:05.640
has they've had a lot of features

561
00:23:05.640 --> 00:23:08.720
because they haven't just added Lambda integration for MSK.

562
00:23:08.720 --> 00:23:10.680
They've also added support for Lambda integration

563
00:23:10.680 --> 00:23:11.880
with your own managed Kafka.

564
00:23:11.880 --> 00:23:14.600
So you don't have to use MLK to integrate with Lambda.

565
00:23:14.600 --> 00:23:17.700
And it uses the same event source mapping feature

566
00:23:17.700 --> 00:23:20.720
that we talked about when we covered Kinesis and SQS.

567
00:23:20.720 --> 00:23:23.800
So it also supports MSK, but not different options

568
00:23:23.800 --> 00:23:28.160
are supported depending on what your event source is.

569
00:23:28.160 --> 00:23:30.300
And we obviously talked about Kinesis

570
00:23:30.300 --> 00:23:32.360
and how you've got your shared level,

571
00:23:32.360 --> 00:23:35.020
but then if you want like 10 Lambdas processing messages

572
00:23:35.020 --> 00:23:38.480
from each chart, you can set this parallelization factor

573
00:23:38.480 --> 00:23:41.440
configuration and get more parallelism.

574
00:23:41.440 --> 00:23:44.120
You don't do that with MSK or with Kafka.

575
00:23:44.120 --> 00:23:46.960
Instead, you have to think about it a bit differently.

576
00:23:46.960 --> 00:23:51.960
By default, you just get one consumer for your MSK topic.

577
00:23:53.040 --> 00:23:56.400
And then Lambda can scale up

578
00:23:56.400 --> 00:23:58.760
based on the number of partitions in that topic.

579
00:23:58.760 --> 00:24:00.560
But the maximum scaling is one consumer

580
00:24:00.560 --> 00:24:02.440
per partition per topic.

581
00:24:02.440 --> 00:24:05.040
So again, this is all very use case specific

582
00:24:05.040 --> 00:24:07.560
and it depends on what your partitioning level is

583
00:24:07.560 --> 00:24:09.040
and your volume of messages,

584
00:24:09.040 --> 00:24:10.840
but it'll only scale up every three minutes.

585
00:24:10.840 --> 00:24:14.160
So it might not be reactive enough for your needs,

586
00:24:14.160 --> 00:24:15.480
which is a pity because I think Lambda

587
00:24:15.480 --> 00:24:17.660
is the ideal use case for these things.

588
00:24:19.800 --> 00:24:22.280
If you look at like the Streams API or the Consumer API,

589
00:24:22.280 --> 00:24:23.640
you still have to have something running,

590
00:24:23.640 --> 00:24:26.820
something that's pretty stateful to consume these messages.

591
00:24:26.820 --> 00:24:30.080
Whereas with Lambda, you could have a lot of power,

592
00:24:30.080 --> 00:24:31.600
but the scalability, you just have to check

593
00:24:31.600 --> 00:24:34.200
if it's gonna work for your use case.

594
00:24:34.200 --> 00:24:35.040
Yeah, exactly.

595
00:24:35.040 --> 00:24:37.280
Especially if you don't have like a continuous stream

596
00:24:37.280 --> 00:24:39.820
of data with more or less constant throughput,

597
00:24:39.820 --> 00:24:43.720
but it's very, very bursty ingestion of data.

598
00:24:43.720 --> 00:24:46.980
You'll probably suffer because of these three minutes

599
00:24:46.980 --> 00:24:48.800
chunks of scaling because yeah,

600
00:24:48.800 --> 00:24:51.100
it will kind of go very slow at the beginning.

601
00:24:53.520 --> 00:24:57.400
Yeah, and then as regards security between Lambda

602
00:24:57.400 --> 00:25:00.440
and Kafka, it's kind of different to what you'd expect.

603
00:25:00.440 --> 00:25:03.600
And there's authentication, you can use IAM authentication,

604
00:25:03.600 --> 00:25:06.860
but you can also use your username password authentication

605
00:25:06.860 --> 00:25:10.080
and TLS to integrate Lambda with your cluster.

606
00:25:10.080 --> 00:25:12.760
Obviously is required if you're not using MSK,

607
00:25:14.140 --> 00:25:17.640
but also you need a VPC for your cluster,

608
00:25:17.640 --> 00:25:19.680
but your Lambda function doesn't have to run in that VPC.

609
00:25:19.680 --> 00:25:21.840
So it's slightly different than the mental model

610
00:25:21.840 --> 00:25:24.160
you might imagine for this setup.

611
00:25:24.160 --> 00:25:26.400
Instead, you need to give the cluster's VPC

612
00:25:26.400 --> 00:25:30.400
access to the Lambda service and also the STS service.

613
00:25:30.400 --> 00:25:32.760
So that usually means either you give it access

614
00:25:32.760 --> 00:25:35.360
to the internet with like a NAT gateway,

615
00:25:35.360 --> 00:25:36.960
which might set off a few alarm bells

616
00:25:36.960 --> 00:25:40.600
based on their pricing episode a few months back.

617
00:25:40.600 --> 00:25:43.360
But so you might instead use VPC endpoints

618
00:25:43.360 --> 00:25:45.360
and create a direct route between your VPC

619
00:25:45.360 --> 00:25:46.760
and Lambda service.

620
00:25:46.760 --> 00:25:49.040
So that's one thing you might not expect.

621
00:25:49.040 --> 00:25:51.820
You might think just because the resource runs in,

622
00:25:52.920 --> 00:25:53.760
cluster itself runs in a VPC,

623
00:25:53.760 --> 00:25:56.640
that the Lambda has to be in that VPC, but it doesn't.

624
00:25:56.640 --> 00:25:58.740
And it kind of works the other way around.

625
00:25:58.740 --> 00:26:00.740
Yeah, that's interesting.

626
00:26:00.740 --> 00:26:05.240
I'm gonna talk very quickly about pricing.

627
00:26:05.240 --> 00:26:08.640
And basically, well, the first case is provisioned.

628
00:26:08.640 --> 00:26:11.460
You are of course paying by the number of brokers

629
00:26:11.460 --> 00:26:13.600
and the size that you pick for these brokers.

630
00:26:13.600 --> 00:26:15.820
For instance, if you go for an M5 large,

631
00:26:15.820 --> 00:26:18.720
that's about 24 cents per hour.

632
00:26:18.720 --> 00:26:20.560
And depending on how many do you have,

633
00:26:20.560 --> 00:26:22.600
you can do the math and see how much are you gonna pay.

634
00:26:22.600 --> 00:26:24.880
But of course there is also storage in the equation.

635
00:26:24.880 --> 00:26:27.040
So you have certain amount of cost,

636
00:26:27.040 --> 00:26:30.600
I think it's around 10 or 11 cents per gigabyte per month.

637
00:26:30.600 --> 00:26:33.960
And yeah, that will add to the cost.

638
00:26:33.960 --> 00:26:34.960
If you go serverless,

639
00:26:34.960 --> 00:26:36.840
there are actually a bunch of dimensions

640
00:26:36.840 --> 00:26:38.700
that will influence your cost.

641
00:26:38.700 --> 00:26:43.700
So there is a certain fee that is $075 per cluster per hour.

642
00:26:45.840 --> 00:26:48.500
So you pay a certain fee per hour

643
00:26:48.500 --> 00:26:50.380
just by speeding up a cluster.

644
00:26:50.380 --> 00:26:52.640
Then depending on the number of partitions you have,

645
00:26:52.640 --> 00:26:55.760
there is an additional fee on partition per hour.

646
00:26:55.760 --> 00:26:58.440
And of course, storage as well will add costs.

647
00:26:58.440 --> 00:27:00.480
So the number of gigabytes per month.

648
00:27:00.480 --> 00:27:02.960
And then you also pay for data transfer,

649
00:27:02.960 --> 00:27:06.260
both data in and data out in terms of gigabytes.

650
00:27:07.720 --> 00:27:10.700
Yeah, so just do the maths and based on use cases,

651
00:27:10.700 --> 00:27:13.560
try to figure out what's the pricing.

652
00:27:13.560 --> 00:27:17.380
The interesting thing that I guess we realized,

653
00:27:17.380 --> 00:27:19.440
it might change depending on your use cases,

654
00:27:19.440 --> 00:27:22.760
but instinctively it looks like that Kinesis is way cheaper

655
00:27:22.760 --> 00:27:24.360
for lower volumes,

656
00:27:24.360 --> 00:27:26.800
but then MSK can be more effective

657
00:27:26.800 --> 00:27:28.800
if you're really running many, many shards,

658
00:27:28.800 --> 00:27:30.960
if you're really running data processing at scale

659
00:27:30.960 --> 00:27:32.460
and ingesting a lot of data.

660
00:27:32.460 --> 00:27:33.800
So that can be interesting.

661
00:27:33.800 --> 00:27:34.920
Maybe it's for a startup,

662
00:27:34.920 --> 00:27:35.920
you can start with Kinesis

663
00:27:35.920 --> 00:27:37.760
because it's easier to start with

664
00:27:37.760 --> 00:27:40.180
and you probably don't need the big volumes,

665
00:27:40.180 --> 00:27:41.980
but if you're running serious workloads,

666
00:27:41.980 --> 00:27:45.040
maybe that the investment in Kafka could be worth it.

667
00:27:46.160 --> 00:27:48.960
Okay, so it's another serverless option

668
00:27:48.960 --> 00:27:50.920
that doesn't scale to zero in terms of pricing,

669
00:27:50.920 --> 00:27:53.080
which is a bit of a pity.

670
00:27:53.080 --> 00:27:54.920
So that's maybe something we can hope for

671
00:27:54.920 --> 00:27:56.720
at some point in the future.

672
00:27:56.720 --> 00:28:00.200
Should we close this episode by trying to have a recap

673
00:28:00.200 --> 00:28:04.660
between why would you use MSK over Kinesis or vice versa?

674
00:28:04.660 --> 00:28:06.040
What's the decision tree?

675
00:28:06.040 --> 00:28:07.200
Yeah, exactly.

676
00:28:08.120 --> 00:28:11.800
So yeah, I'm gonna say that first of all,

677
00:28:11.800 --> 00:28:15.120
when you have a large number of consumers,

678
00:28:15.120 --> 00:28:18.400
probably MSK is a better solution

679
00:28:18.400 --> 00:28:20.600
because you can be more flexible there.

680
00:28:20.600 --> 00:28:24.940
Also, if you need Kafka Streams or Kafka Connect

681
00:28:24.940 --> 00:28:26.420
because you already built a solution

682
00:28:26.420 --> 00:28:27.620
that uses those technologies,

683
00:28:27.620 --> 00:28:29.540
or maybe you have expertise with those technologies

684
00:28:29.540 --> 00:28:31.100
and you want to leverage that expertise,

685
00:28:31.100 --> 00:28:34.560
of course, again, MSK is an obvious winner there.

686
00:28:36.200 --> 00:28:38.920
And similarly, if you just have experience

687
00:28:38.920 --> 00:28:41.700
or you prefer to work with a technology like Kafka

688
00:28:41.700 --> 00:28:42.680
because it's open source

689
00:28:42.680 --> 00:28:45.600
and you can easily port it also to other cloud providers,

690
00:28:45.600 --> 00:28:48.640
again, that's a winner over Kinesis.

691
00:28:48.640 --> 00:28:50.300
But of course there are disadvantages,

692
00:28:50.300 --> 00:28:52.800
like we already mentioned that there is more complexity,

693
00:28:52.800 --> 00:28:54.660
so you need to keep that into account.

694
00:28:55.620 --> 00:28:59.300
Also in terms of MSK, so Kafka on AWS

695
00:28:59.300 --> 00:29:00.860
is a relatively new service.

696
00:29:00.860 --> 00:29:02.480
So sometimes you might struggle

697
00:29:02.480 --> 00:29:04.180
to find documentation or examples,

698
00:29:04.180 --> 00:29:06.820
so that's also something else to keep in mind.

699
00:29:06.820 --> 00:29:09.660
And it's less serverless because you need to think about,

700
00:29:09.660 --> 00:29:12.380
as we said, VPC, EC2,

701
00:29:12.380 --> 00:29:14.920
rather than just thinking about how much are you scaling,

702
00:29:14.920 --> 00:29:16.500
give me one dimension for scale

703
00:29:16.500 --> 00:29:19.620
and everything else will be managed for me.

704
00:29:19.620 --> 00:29:21.760
Here you really need to think about many, many concerns,

705
00:29:21.760 --> 00:29:24.700
many, many metrics, so everything becomes more complicated.

706
00:29:25.580 --> 00:29:28.860
And one final remark that I have is,

707
00:29:28.860 --> 00:29:32.780
again, you might not even need stream processing at all,

708
00:29:32.780 --> 00:29:34.560
so always keep that in mind.

709
00:29:34.560 --> 00:29:36.420
Sometimes you can go a long way

710
00:29:36.420 --> 00:29:39.940
with just using like SQS, SNS or EventBridge.

711
00:29:41.000 --> 00:29:42.540
So keep that in mind

712
00:29:42.540 --> 00:29:45.820
because if you don't really need streams,

713
00:29:45.820 --> 00:29:49.660
whether that's Kinesis or Kafka, doesn't really matter,

714
00:29:49.660 --> 00:29:51.860
but if you don't need that level of complexity at all,

715
00:29:51.860 --> 00:29:53.780
and you can go with SQS, SNS and EventBridge,

716
00:29:53.780 --> 00:29:56.080
you can probably make your life easier.

717
00:29:56.080 --> 00:29:58.260
And those services will also scale to zero,

718
00:29:58.260 --> 00:30:00.740
so you could also save a lot of money

719
00:30:00.740 --> 00:30:03.100
by using those as an alternative.

720
00:30:03.100 --> 00:30:05.340
So try to really nail down your use cases

721
00:30:05.340 --> 00:30:08.200
and the technology you could use for your use cases.

722
00:30:09.460 --> 00:30:10.300
Yeah, yeah.

723
00:30:10.300 --> 00:30:13.860
Plus one for me from starting with SQS and EventBridge,

724
00:30:13.860 --> 00:30:16.980
for example, you can get a lot done and you can always migrate.

725
00:30:19.300 --> 00:30:22.100
So to conclude then, we have a few resources.

726
00:30:22.100 --> 00:30:23.940
I know we've collected a few links here,

727
00:30:23.940 --> 00:30:25.180
which we'll put it in the show notes,

728
00:30:25.180 --> 00:30:26.660
just some really good ones.

729
00:30:26.660 --> 00:30:28.700
One of the interesting things that you might find

730
00:30:28.700 --> 00:30:31.020
is that Amazon actually provide a pricing spreadsheet,

731
00:30:31.020 --> 00:30:35.140
an Excel spreadsheet that you can use for pricing your MSK.

732
00:30:35.140 --> 00:30:36.660
We have a link to that,

733
00:30:36.660 --> 00:30:39.540
and we have some pretty good talks.

734
00:30:39.540 --> 00:30:41.020
So we've one on whether your startup

735
00:30:41.020 --> 00:30:42.260
should use Kinesis or MSK,

736
00:30:42.260 --> 00:30:43.460
even if you're not in a startup,

737
00:30:43.460 --> 00:30:44.500
that's an Amazon talk.

738
00:30:44.500 --> 00:30:45.660
Even if you're not in the startup,

739
00:30:45.660 --> 00:30:47.700
that's useful comparison between the two.

740
00:30:49.420 --> 00:30:51.060
We've got another intro to MSK talk

741
00:30:51.060 --> 00:30:53.500
way back from its launch in 2018.

742
00:30:53.500 --> 00:30:56.940
And you wanted to highlight the Frank Munns talk as well,

743
00:30:56.940 --> 00:30:58.060
right Luciano?

744
00:30:58.060 --> 00:31:00.500
Yeah, I really like it because it's not just an intro

745
00:31:00.500 --> 00:31:03.060
with a demo on how to use MSK,

746
00:31:03.060 --> 00:31:05.060
but there is also a little bit of a preamble

747
00:31:05.060 --> 00:31:06.660
that gives you a lot of insights

748
00:31:06.660 --> 00:31:09.620
about why would you need stream processing

749
00:31:09.620 --> 00:31:11.860
and all the value of data over time

750
00:31:11.860 --> 00:31:13.700
and the value that you can extrapolate

751
00:31:13.700 --> 00:31:17.220
if you are able to make sense of that data

752
00:31:17.220 --> 00:31:19.580
as soon as it's available in your system.

753
00:31:19.580 --> 00:31:20.980
So I really like that

754
00:31:20.980 --> 00:31:23.100
not just as a technical introduction to MSK,

755
00:31:23.100 --> 00:31:25.580
but also as a way to reason about

756
00:31:25.580 --> 00:31:28.260
whether you really need that type of capability or not

757
00:31:28.260 --> 00:31:30.820
and what kind of advantages you could get from it.

758
00:31:31.980 --> 00:31:34.420
Okay, maybe the last one we can mention to wrap up then

759
00:31:34.420 --> 00:31:37.860
is there's another really useful versus comparison,

760
00:31:37.860 --> 00:31:41.220
which the Cloud and Not guys do pretty regularly.

761
00:31:41.220 --> 00:31:42.140
They've got a comparison table,

762
00:31:42.140 --> 00:31:44.780
but also an episode comparing Kinesis and MSK,

763
00:31:44.780 --> 00:31:46.220
which we reckon you should check out.

764
00:31:46.220 --> 00:31:48.540
It's got a demo of MSK in there as well.

765
00:31:48.540 --> 00:31:50.260
I think this wraps up not just this episode,

766
00:31:50.260 --> 00:31:53.020
but the whole series on AWS event services.

767
00:31:53.020 --> 00:31:54.540
And the next time we'll be back

768
00:31:54.540 --> 00:31:56.180
with something completely different.

769
00:31:56.180 --> 00:31:57.820
So we've really appreciated all the great feedback

770
00:31:57.820 --> 00:31:58.700
we've got on this series.

771
00:31:58.700 --> 00:32:02.580
It's actually helped to change how we present them.

772
00:32:02.580 --> 00:32:03.860
I know some of these talks have been,

773
00:32:03.860 --> 00:32:06.100
these episodes have been longer than previously,

774
00:32:06.100 --> 00:32:08.380
but hopefully it's been worth it for people.

775
00:32:08.380 --> 00:32:10.500
And we're really interested in your feedback

776
00:32:10.500 --> 00:32:13.220
on how we can make shorter or longer episodes in the future

777
00:32:13.220 --> 00:32:14.740
and what topics you want to cover.

778
00:32:14.740 --> 00:32:16.300
So thanks for all your feedback.

779
00:32:16.300 --> 00:32:17.140
We really appreciate it

780
00:32:17.140 --> 00:32:18.940
and we'll see you in the next episode.

781
00:32:18.940 --> 00:32:40.220
—
