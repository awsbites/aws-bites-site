WEBVTT

1
00:00:00.000 --> 00:00:09.000
Migrating monoliths to the cloud can be scary, expensive, and time-consuming, but you don't have to massively re-engineer your application to do that.

2
00:00:09.000 --> 00:00:15.000
Today, we are going to present a case study and a potential strategy to move a monolith to AWS with minimal drama.

3
00:00:15.000 --> 00:00:22.000
We will discuss how a typical on-premise, three-tier web application can be migrated to AWS and made scalable and resilient.

4
00:00:22.000 --> 00:00:26.000
We will discuss some of the steps that you can take to make that happen.

5
00:00:26.000 --> 00:00:33.000
And finally, we will present some of the new challenges, but also opportunities that come once you shift an application to the cloud.

6
00:00:33.000 --> 00:00:37.000
My name is Luciano, and today I'm joined by Eoin, and this is AWS Bites podcast.

7
00:00:45.000 --> 00:00:49.000
Luciano, this is based on an article you wrote that's now available on InfoQ.

8
00:00:49.000 --> 00:00:52.000
It's called a recipe to migrate and scale monoliths in the cloud.

9
00:00:52.000 --> 00:00:54.000
We'll put a link to that article in the show notes.

10
00:00:54.000 --> 00:00:59.000
I think it's really good because it's a very clear process on how you think about this kind of migration.

11
00:00:59.000 --> 00:01:06.000
There's also a really good case study that gives a context for all the steps that follow, and there's a really good checklist in it.

12
00:01:06.000 --> 00:01:08.000
Maybe we can start with that case study.

13
00:01:08.000 --> 00:01:10.000
You talk about a fictitious legal company.

14
00:01:10.000 --> 00:01:13.000
What's the story with that? What's the context?

15
00:01:13.000 --> 00:01:21.000
Yeah, it's a fictitious company, but a reality that kind of company and the kind of project reflects the reality of many, many projects that I've seen in my career.

16
00:01:21.000 --> 00:01:25.000
And even projects that we are seeing every day at Forteorum.

17
00:01:25.000 --> 00:01:32.000
So I think it represents very well a good class of solutions that are still out there and that can benefit from moving to the cloud.

18
00:01:32.000 --> 00:01:39.000
In this particular case, just to set the stage, we can imagine that we have this startup that operates in the legal space.

19
00:01:39.000 --> 00:01:42.000
They've built a CMS for legal practices.

20
00:01:42.000 --> 00:01:50.000
So you can imagine that they offer this product to legal practices, and what they can do with it is that every practice can upload their legal documents.

21
00:01:50.000 --> 00:02:00.000
And there is like a search index mechanism that happens behind the scenes, and then people logging in in the system, they can use keywords to find documents that have been uploaded before.

22
00:02:00.000 --> 00:02:06.000
So it's effectively a way to make legal documents easily searchable within the context of a legal practice.

23
00:02:06.000 --> 00:02:17.000
And we can assume that the current solution that exists today, like let's call it the MVP for this startup, is something built on premise in a very standard fashion.

24
00:02:17.000 --> 00:02:21.000
It's like a three tier web application where you have a front end, a back end, and a database.

25
00:02:21.000 --> 00:02:26.000
And we can imagine just for reference that, I don't know, the technology can be Python.

26
00:02:26.000 --> 00:02:35.000
So maybe they're using Django as a web framework and the database can be a relational database, let's say Postgres, just to mention one technology as a reference.

27
00:02:35.000 --> 00:02:40.000
So that's the system that we are operating in right now.

28
00:02:40.000 --> 00:02:42.000
Yep, it sounds very familiar.

29
00:02:42.000 --> 00:02:53.000
And I suppose that brings the question, so why do they have a problem? Why do they need to migrate? And what's the background story there? What are they actually trying to solve by migrating to the cloud?

30
00:02:53.000 --> 00:03:02.000
So right now, the whole application is hosted on premise on one machine. So everything is running in this like one monolithic server.

31
00:03:02.000 --> 00:03:13.000
And that has been working fine for the MVP. But of course, we know that it's not something that scales long term. And right now, this company is starting to grow a little bit because they released this MVP.

32
00:03:13.000 --> 00:03:23.000
They are working with sales to get new customers. And it turns out that they have been very lucky. They got quite a big legal practice that wants to try out this platform.

33
00:03:23.000 --> 00:03:28.000
So what's happening is that suddenly they have a bunch of new users using the system all at the same time.

34
00:03:28.000 --> 00:03:33.000
And that's creating a lot of additional stress to the servers. So there is too much load on one machine.

35
00:03:33.000 --> 00:03:39.000
The whole application is sometimes slow and unresponsive, sometimes even unavailable.

36
00:03:39.000 --> 00:03:46.000
And the other thing is that this is a system that stores files. So right now, everything is monolithic in one server.

37
00:03:46.000 --> 00:03:50.000
So there is literally a bunch of files that are being accumulated in the file system.

38
00:03:50.000 --> 00:03:58.000
So it has been happening a few times that the file system was totally full and somebody had to manually allocate more space, more disks.

39
00:03:58.000 --> 00:04:07.000
And while that was happening, the whole application was unresponsive and it was effectively a downtime and an incident that needed to be managed by somebody.

40
00:04:07.000 --> 00:04:11.000
So the customers were a little bit disappointed with all of that.

41
00:04:11.000 --> 00:04:18.000
And similarly, you can imagine there is stress also in the database because if everything is in the same machine, everything is competing for resources.

42
00:04:18.000 --> 00:04:25.000
So as soon as something is stressed, everything else doesn't have the necessary resources to work optimally.

43
00:04:25.000 --> 00:04:29.000
So all of that is basically one single big point of failure.

44
00:04:29.000 --> 00:04:38.000
If anything fails for any reason, the whole application is failing, going down, being unreachable and customers cannot use the application.

45
00:04:38.000 --> 00:04:43.000
They cannot search for their file and they cannot ultimately do their job.

46
00:04:43.000 --> 00:04:53.000
So the prompt that we got from this scenario is, okay, but if I move everything into the cloud, everything is going to be better.

47
00:04:53.000 --> 00:05:01.000
But at the same time, the feeling is that if you move to the cloud, it's a very big and scary investment that might take a lot of money and time.

48
00:05:01.000 --> 00:05:06.000
So it's like, how do we find a trade-off there that makes everyone happy?

49
00:05:06.000 --> 00:05:13.000
Yeah, I guess that's an important question. We covered this before in one of the previous episodes on how do you migrate to the cloud.

50
00:05:13.000 --> 00:05:16.000
There's a lot of different options. It can be very overwhelming.

51
00:05:16.000 --> 00:05:25.000
So I suppose you have to bear in mind what are the skills, how many people, how much cloud awareness do you have, as well as real world problems.

52
00:05:25.000 --> 00:05:27.000
What are they going to solve? How much time do they have?

53
00:05:27.000 --> 00:05:38.000
And ultimately, really, they've got to get this out there in time for customers to achieve success with it, not impact existing customers and scale with their growth.

54
00:05:38.000 --> 00:05:40.000
So what do you suggest?

55
00:05:40.000 --> 00:05:51.000
Yeah, so my suggestion would be that trying to reach the best outcome with the minimum amount of investment in terms of time, money, effort.

56
00:05:51.000 --> 00:06:07.000
So an idea could be, can we find an architecture that is not dramatically different from the current one, but that at the same time allows us to move everything to the cloud and make it more resilient and scalable, which are the main problems that we are facing right now.

57
00:06:07.000 --> 00:06:12.000
The system doesn't scale, and if there is any crash, everything burns, basically.

58
00:06:12.000 --> 00:06:21.000
So that's kind of the line that I would like to keep here, so that the challenge is literally, how do we make that happen?

59
00:06:21.000 --> 00:06:33.000
And at the same time, we are working with a small team, so how do we minimize also the amount of information overload on that team that will need to actually do the work and learn all the new concepts that come with the cloud?

60
00:06:33.000 --> 00:06:42.000
Yeah, I guess it's a difficult thing to resist the temptation to adopt all of the new tools and toys you get with the cloud and to try and simplify.

61
00:06:42.000 --> 00:06:56.000
So what do you think is a reasonable approach that solves all the problems, gets some of the advantages of the cloud, achieves the business goals of scaling for the new customers, but doesn't overwhelm the team with a whole lot of new learnings and distractions?

62
00:06:56.000 --> 00:07:11.000
So the architecture that I had in mind is something actually quite common when it comes to cloud architectures, especially if we look at the very beginning of the cloud, it's like more traditional three-tier application cloud version, if you want.

63
00:07:11.000 --> 00:07:20.000
And basically, the idea is that you have an application load balancer, which is kind of the entry point to the entire architecture, so it's where we receive the requests from the users.

64
00:07:20.000 --> 00:07:35.000
Then that load balancer is going to forward all these requests, not to just one machine, but at this point you can use as many machines as you need, so you have this kind of pool of EC2 instances, and they all run the exact same copy of the application code.

65
00:07:35.000 --> 00:07:45.000
So it's literally just taking the monolith and multiplying it n times, where n is going to be a factor of the traffic that you get and how much resources do you need to run the application.

66
00:07:45.000 --> 00:08:04.000
And of course, another big problem that we mentioned is files, and those files cannot live in a file system. Well, I suppose they could, but it's more ideal once you are in the cloud to use something like S3, which has been literally built with that goal of making it easier to host files in a safe and distributed way.

67
00:08:04.000 --> 00:08:16.000
So definitely, we should try to leverage S3, and if you have used S3, you know it's not dramatically complicated. It's a reasonable change to make in the architecture.

68
00:08:16.000 --> 00:08:24.000
And we can also discuss some tricks to make it easier at the beginning if you don't have time to kind of adopt the SDK and do a lot of code changes.

69
00:08:24.000 --> 00:08:39.000
And then, for instance, another big problem that comes with having multiple instances is that you cannot have a local state anymore. You need to, for instance, if you have users that log in, you need to manage their sessions, and this session cannot live in one machine.

70
00:08:39.000 --> 00:08:45.000
And again, it could if you use TikiSessions, but that's not the best way of doing it.

71
00:08:45.000 --> 00:08:56.000
So the best thing to do is to use a session storage. Maybe something like Redis can be used to host all that data. So connecting all the instances to Redis is another part of the architecture.

72
00:08:56.000 --> 00:09:04.000
And finally, the database. We mentioned that the recurrent solution is essentially a process running in line in the same machine.

73
00:09:04.000 --> 00:09:12.000
What we want to do is to ideally remove all of that from inside the machine and have it independent and scalable and resilient on its own.

74
00:09:12.000 --> 00:09:22.000
And there is a perfect service for that in AWS, which is RDS, that being a managed service allows you to get a Postgres database running, make it distributed.

75
00:09:22.000 --> 00:09:31.000
You can have read replica. You can have all the features you need, just a click away from you. You don't need to manually write the scripts to provision all that stuff yourself.

76
00:09:31.000 --> 00:09:42.000
Okay, I like that. I mean, it's, I guess, a sane approach to this problem, right? It's not overwhelming the team with new things like serverless architecture and containers.

77
00:09:42.000 --> 00:09:53.000
And so it keeps a lot of the skills in their comfort zone, right? And it minimizes the amount of new cloud technologies they have to adopt and sets them up pretty well for the future.

78
00:09:53.000 --> 00:10:03.000
So I hope a lot of people would kind of copy this model, especially when you're working with a team that's compromised in terms of the amount of time they have to adopt new skills.

79
00:10:03.000 --> 00:10:11.000
And no, this is a good first step, I think. So maybe we can talk about the steps to actually make this happen.

80
00:10:11.000 --> 00:10:20.000
So now we've got the target architecture in mind. We need a roadmap, right, to get there. So where do we start? What are the first things we need to start preparing?

81
00:10:20.000 --> 00:10:27.000
Yeah, I will definitely start by, of course, creating an AWS account. So let's create the target environment.

82
00:10:27.000 --> 00:10:41.000
And one thing that I will try to do straight away, and this is probably a little bit of a burden to the team if it's something that they haven't done before, but I consider it almost necessary if you want to be successful in the cloud, is to start to adopt infrastructure as code.

83
00:10:41.000 --> 00:10:47.000
So everything you do in the cloud is not something you do manually by going to the web console and clicking around.

84
00:10:47.000 --> 00:10:53.000
Of course, you can do that while you're learning, but when you're building production-ready solutions, you should use infrastructure as code.

85
00:10:53.000 --> 00:11:01.000
So this is a step where the team needs to maybe invest a little bit of time and play a little bit around with it and learn the basic concept.

86
00:11:01.000 --> 00:11:14.000
And of course, they can select whatever tool feels more natural to them. We have another episode dedicated to that, but CDK, Platform, Terraform, Pulumi, there are many tools out there.

87
00:11:14.000 --> 00:11:20.000
Whatever feels more natural, they are all good enough for the goal that we want to achieve.

88
00:11:20.000 --> 00:11:30.000
And then finally, the other thing we need to do as something that is needed to set the stage is to create a network where the whole application will be deployed.

89
00:11:30.000 --> 00:11:37.000
So that can be also a little bit of a learning curve if the team doesn't have experience with building visual networks in the cloud.

90
00:11:37.000 --> 00:11:45.000
And in particular, with AWS, there are some concepts that you need to learn. What is a VPC? What are availability zones? What are public and private subnets?

91
00:11:45.000 --> 00:12:06.000
And how to configure all of that. If you use CDK, maybe you can get some defaults, but we spoke in another episode how that can also be dangerous because you might end up not really understanding what's going on in the architecture and maybe provisioning things that you don't really need and end up with an expensive setup, like NAT gateways and all this stuff.

92
00:12:06.000 --> 00:12:21.000
So yeah, this is probably another point where the team needs to spend a little bit of time, learn at least the basics, do a few experiments, and once they are comfortable, they can start to use that learning from the infrastructure as code to provision the VPC.

93
00:12:21.000 --> 00:12:32.000
And at that point, we have an AWS account, minimal understanding of infrastructure as code, and a virtual private network that we can use to host the entire application.

94
00:12:32.000 --> 00:12:49.000
I think those points you just made give a good outline of why you don't want to burden a team with too much when you're migrating to the cloud, because even with this simplified, sane approach, you already have an AWS account and possibly AWS organization fundamentals to understand.

95
00:12:49.000 --> 00:12:59.000
You have infrastructure as code to understand. And the basics of AWS networking, like what's a private subnet? What's a public subnet? What's an internet gateway and a NAT gateway?

96
00:12:59.000 --> 00:13:09.000
What are the pricing impacts and security impacts of all of these components? So there's enough there in terms of good, solid AWS foundations to understand.

97
00:13:09.000 --> 00:13:15.000
I think it's probably enough for the first dive into AWS.

98
00:13:15.000 --> 00:13:31.000
So with those fundamentals in place, I think with migrations in general, data is key and data retention and avoiding data loss is important. So data is probably a good topic for the next phase of this journey.

99
00:13:31.000 --> 00:13:47.000
What do we have to think about? You mentioned file storage. I think moving from an on-premise disk or an on-premise NAS to S3 is one of the lowest overhead parts of this and one of the biggest benefits because you can suddenly stop worrying about disks filling up.

100
00:13:47.000 --> 00:13:54.000
And it's one of the biggest wins, I think. So is that where you'd start with the file migration?

101
00:13:54.000 --> 00:14:10.000
Probably, yes. I think in general, as you said, if you can show the customer that all the data is already in the new environment and all the data gets replicated automatically or as automatic as possible to the new environment, that gives a lot of confidence boost.

102
00:14:10.000 --> 00:14:22.000
Because as you said, the data is king and that's the main concern. Like maybe I'm not too concerned about being offline for a few hours while I migrate, but I'm definitely going to be concerned if I'm going to lose some data.

103
00:14:22.000 --> 00:14:36.000
So if we can reassure a customer, a company that that's not going to be the case, that there are ways to actually keep the data in sync as we move through two different systems, I think that that's literally a big win and we should aim to that.

104
00:14:36.000 --> 00:14:44.000
So I agree that this is a good next step to address to build more and more confidence that we are going in the right direction.

105
00:14:44.000 --> 00:14:58.000
So yeah, talking about S3, the easiest thing that I could think of is, okay, let's start by creating an S3 bucket and let's make sure that every new file that gets created in the old system is also created in S3.

106
00:14:58.000 --> 00:15:17.000
So that might require code changes, but there are tricks there. I mentioned that before. For instance, you can use virtual file system like Fuses 3 and things like that to keep the code as unchanged as possible because the code is good at reading and writing files from the file system.

107
00:15:17.000 --> 00:15:30.000
With a virtual file system, you will only have like a different virtual folder that you use to read and write and that virtual file system will take the burden of actually using the AWS APIs to actually read and write into S3.

108
00:15:30.000 --> 00:15:43.000
I don't necessarily recommend that because there are problems that come with that solution, but at the same time, if you don't want to change the code too much because you don't have the time, it's something else you need to learn, it's new dependencies that you need to bring into the application.

109
00:15:43.000 --> 00:15:52.000
And maybe at that moment in time, it's not easy to do that. That can be a solution right now to just start to see the data popping into the S3 bucket.

110
00:15:52.000 --> 00:16:08.000
Then another thing you can do once you have new data being written also to S3 is to just go into the current machine, the current monolith, and do an S3 sync from the CLI and that will copy all the existing files over into the bucket as well.

111
00:16:08.000 --> 00:16:17.000
So at that point, you have all the new data coming in, but you also copied all the historic data. So at that point, you have S3 perfectly in line.

112
00:16:17.000 --> 00:16:29.000
The next problem is the database data. And that's also a big one because if you have a relational database, how do you keep it in sync with another copy of the relational database, right?

113
00:16:29.000 --> 00:16:39.000
Then it's going to be running in AWS. We mentioned you can use RDS. So the next thing you should do is just go to RDS and create a cluster for your Postgres.

114
00:16:39.000 --> 00:16:46.000
And then how do you actually bring the data from the current system to this new RDS cluster?

115
00:16:46.000 --> 00:16:50.000
And there is actually a service dedicated to that. It's called Database Migration Service.

116
00:16:50.000 --> 00:17:10.000
And one of the things that it does other than just helping you to migrate all your schema and copying the data, but it can also work in the original system, so in the on-premise system, and make sure that every time there is new data in that on-premise database, this data is also replicated to the RDS database.

117
00:17:10.000 --> 00:17:26.000
So this way, again, we are creating that system that allows not just to copy the data once, but also to keep copying new data as it arrives, which gives us confidence that we can take all the time that is needed for this migration without having to put the system offline.

118
00:17:26.000 --> 00:17:34.000
So that the old system can still work and new data will be replicated, and we can switch over to the new system whenever we feel ready.

119
00:17:34.000 --> 00:17:41.000
That sounds like a good pragmatic set of decisions there. I think you also have the option of manually migrating your database data.

120
00:17:41.000 --> 00:17:47.000
But maybe that's a little bit more difficult than it was with S3 where you can use the AWS CLI to do an S3 sync.

121
00:17:47.000 --> 00:17:57.000
Similarly, you could probably go a step further and migrate your S3 data using Storage Gateway and have more of a pattern like you have with the Database Migration Service.

122
00:17:57.000 --> 00:18:05.000
But S3 is probably just a little bit simpler to migrate because you don't have to think about all the transactional updates happening and file systems are a little bit simpler to reason about.

123
00:18:05.000 --> 00:18:14.000
So you've got options there, but you don't have to go all in and choose Storage Gateway, which has lots of options and its own set of complexities.

124
00:18:14.000 --> 00:18:21.000
Yeah, and then the last thing is to provision Redis, and you can do that in a managed way on AWS using something like Elasticash, for instance.

125
00:18:21.000 --> 00:18:31.000
And the good thing about Redis is that it tends to be quite schema-less, so you don't need to really worry too much right now about, I don't know, how are you going to structure the data in Redis.

126
00:18:31.000 --> 00:18:37.000
So just spinning up the cluster is probably enough for you right now to get started.

127
00:18:37.000 --> 00:18:52.000
Okay, so Redis, I suppose the important thing is to size it correctly, make sure you have enough memory, and it's going to work for your performance, but assuming, it depends on what you're using it for, and that probably brings us to the application and how the application leverages Redis.

128
00:18:52.000 --> 00:18:59.000
And I think we've talked about preparation, we've got our data migrations started. So this is everything in the right order so far, I think.

129
00:18:59.000 --> 00:19:06.000
Probably a good time to start thinking about compute and the application itself. So is it just a lift and shift? Do we need to make much change there?

130
00:19:06.000 --> 00:19:14.000
I would say almost, but there is like a big mindset shift, I think, when it comes to this kind of architecture.

131
00:19:14.000 --> 00:19:22.000
And the reason why is because in the initial state, we have only one machine. So you can imagine that machine to be like totally stateful.

132
00:19:22.000 --> 00:19:29.000
Everything that happens, connections, sessions, are all managed. They could be managed in memory in that one machine.

133
00:19:29.000 --> 00:19:38.000
The problem is that as soon as you have multiple machines, even just two machines, the load balancer will route traffic to them in kind of a round robin fashion.

134
00:19:38.000 --> 00:19:45.000
So it's not guaranteed that a user sending a request the first time will end up in the same machine when they send a request the second time.

135
00:19:45.000 --> 00:19:57.000
They might be bouncing between two or more machines. So if the state is not somehow available to all the machines, that becomes a problem because a user might log in into one machine, then send that request to another machine.

136
00:19:57.000 --> 00:20:02.000
And basically the second machine doesn't have any clue about that particular session.

137
00:20:02.000 --> 00:20:08.000
So the problem is how do we keep all the instances as stateless as possible?

138
00:20:08.000 --> 00:20:14.000
Which means we need to put the state somewhere else that is shared. And that's why we created the Redis cluster.

139
00:20:14.000 --> 00:20:22.000
And for this particular application, I expect that the main kind of state that we need to keep track of is just user sessions.

140
00:20:22.000 --> 00:20:34.000
So we can kind of simplify it that way. We already say that files will be copied in S3 so that that kind of decouples as well the statefulness of the application into something a little bit more stateless.

141
00:20:34.000 --> 00:20:45.000
But there is another interesting thing to bring in mind that is you cannot, you could probably do it, but you shouldn't do it, that you can SSH into one of the machines to do operational stuff.

142
00:20:45.000 --> 00:20:56.000
And operational stuff could be, I don't know, tail logs because you're trying to troubleshoot something or even just install updates or do code changes because you're trying to fix or update something.

143
00:20:56.000 --> 00:21:03.000
That doesn't make any sense anymore because you, first of all, if you're looking for logs, you have no guarantee that the logs are being produced.

144
00:21:03.000 --> 00:21:13.000
The logs you are looking for are being produced in the machine that you just connected to. It might be any other of the machines or maybe that original machines that where you saw a potential bug doesn't even exist anymore.

145
00:21:13.000 --> 00:21:22.000
Because you have to think these machines are dynamically, they could be configured to dynamically appear and created and destroyed to be elastically scalable.

146
00:21:22.000 --> 00:21:30.000
So that that concept of I'm just going to SSH to do operation. I think it's a big no no when you move to this kind of architectures.

147
00:21:30.000 --> 00:21:41.000
So what is the solution? The solution is to use images, machine images like AMIs to provision your instances. So you make sure every instance is literally the same.

148
00:21:41.000 --> 00:21:46.000
Everything is stateless. So we said we move all the state outside the instance.

149
00:21:46.000 --> 00:21:52.000
But also you'll need to start adopting observability tools for things like logs and metrics.

150
00:21:52.000 --> 00:21:59.000
And that makes also all this information in a way stateless, meaning that it's moved outside the instance itself.

151
00:21:59.000 --> 00:22:04.000
That sounds good. And I guess people can make their own judgment as to whether they need an auto scaling group.

152
00:22:04.000 --> 00:22:09.000
You might also just decide to bring up a number of instances, like three instances and multiple AZs.

153
00:22:09.000 --> 00:22:16.000
And if you know your traffic is never going to exceed the compute amounts of three instances and you're just doing it for high availability.

154
00:22:16.000 --> 00:22:21.000
That's completely OK, too. You can decide to adopt an auto scaling group at a later stage.

155
00:22:21.000 --> 00:22:27.000
Absolutely. So we talked about some of the networking fundamentals, public and private subnets.

156
00:22:27.000 --> 00:22:32.000
You've mentioned the application and we've got auto scaling. We talked about multiple AZs.

157
00:22:32.000 --> 00:22:38.000
What are the other, I suppose, front facing networking considerations that we need to take?

158
00:22:38.000 --> 00:22:44.000
So we're starting to wire our application closer to our user. What are the parts that we need to think about there?

159
00:22:51.000 --> 00:22:59.000
Yeah, one thing that we didn't mention is HTTPS, which, of course, it's going to be a critical thing for a system like this, where users are logging in and there is sensitive information being uploaded. So we definitely need to have HTTPS.

160
00:22:59.000 --> 00:23:05.000
The good news is that in AWS, there are ways to make that somewhat simple and managed,

161
00:23:05.000 --> 00:23:11.000
because you can use services like ACM to create the certificates and manage the lifecycle of the certificate.

162
00:23:11.000 --> 00:23:19.000
And then a certificate with ACM can just be attached to the load balancer and the load balancer can deal with all the SSL termination.

163
00:23:19.000 --> 00:23:29.000
So it becomes kind of from the user to the load balancer is HTTPS and everything else you don't necessarily have to keep doing HTTPS unless you want to, of course.

164
00:23:29.000 --> 00:23:35.000
So the things that we need to configure is create a certificate with ACM, attach the certificate to the load balancer.

165
00:23:35.000 --> 00:23:39.000
And of course, when you create the certificate, there are different ways to validate that certificate.

166
00:23:39.000 --> 00:23:45.000
You need to prove that you have control over the domain and you can do that either by email or with DNS records.

167
00:23:45.000 --> 00:23:50.000
So depending on how you are set up there, you might pick whatever way is most suitable to you.

168
00:23:50.000 --> 00:24:05.000
And finally, if you want to do auto scaling, you need to make sure that your application has a kind of an ELT check endpoint that the load balancer can use to verify that when a new instance is brought up, it's actually ready to receive requests.

169
00:24:05.000 --> 00:24:13.000
And also if the instance crashes for whatever reason, the load balancer can recognize and remove it from the pool of EC2 instances.

170
00:24:13.000 --> 00:24:17.000
And with that, you also need to configure the targets and auto scaling groups.

171
00:24:17.000 --> 00:24:21.000
So there is a little bit of extra configuration. Also, what are the scaling rules?

172
00:24:21.000 --> 00:24:31.000
Do you want to scale based on, I don't know, average CPU or number of connections? Things you can decide based on what are your expectations in terms of incoming traffic.

173
00:24:31.000 --> 00:24:40.000
OK, so that sounds like it'll set people up for a seamless switchover as long as they understand exactly what they expect in terms of what domains they're using.

174
00:24:40.000 --> 00:24:53.000
They need to think about are they using the same domain, different domain, but the important thing is to be able to test your old system and your live system, make sure they're both working and then seamlessly switch over with the no deployment steps really just to use DNS.

175
00:24:53.000 --> 00:24:57.000
That's always the safest way to do things.

176
00:24:57.000 --> 00:25:04.000
So there's at that point, right, we've got our application up and running in the cloud. Users can start using it right away.

177
00:25:04.000 --> 00:25:11.000
Existing users should have noticed no difference, maybe just a dramatic increase in performance and stability.

178
00:25:11.000 --> 00:25:22.000
And we know that we're scaled for future growth as well. So in terms of thinking about the team, people who actually have to do this work and support it, and we don't want them to lose too many sleepless nights.

179
00:25:22.000 --> 00:25:28.000
So what are the things that teams need to learn? What are the fundamentals? We talked about some of them there. Maybe we can summarize.

180
00:25:28.000 --> 00:25:46.000
Yeah, we definitely mentioned infrastructure as code as being one of the most important investments, I suppose, because if you do that right at the beginning, it's going to pay off big time as you deploy the application the first time, but then especially when you want to do changes in the future and update the application.

181
00:25:46.000 --> 00:25:59.000
So that's definitely one, and it can be a big one, I suppose. If you've never done it before, it can be a little bit overwhelming. So this is probably the one thing I would recommend to really spend your time and make sure you feel comfortable with it.

182
00:25:59.000 --> 00:26:15.000
The other one is AWS networking. You don't have to become an expert, but at least understand the basics, what are the different concepts and need to be comfortable thinking that you are not just running a server in the public internet or on premise and somehow with a public IP.

183
00:26:15.000 --> 00:26:26.000
But you literally have your own virtual network where there are different things running inside, they are connected with each other, and then how do you expose that to public facing internet?

184
00:26:26.000 --> 00:26:34.000
So just make sure you understand all the basics there and how the different AWS concepts allow you to implement that kind of architecture.

185
00:26:34.000 --> 00:26:48.000
And another thing we didn't mention, but it's probably important, is to understand AWS permission. So get yourself comfortable with IAM because, of course, we'll need to have instances that are able to read and write to S3.

186
00:26:48.000 --> 00:26:53.000
So to the very minimum, you need to be able to define the IAM policies that allow that.

187
00:26:53.000 --> 00:27:05.000
But of course, as soon as you learn IAM, that can be beneficial in general in AWS to make sure that every time you are integrating different services, all the policies are configured correctly.

188
00:27:05.000 --> 00:27:16.000
And also that's important for users logging into AWS, what kind of permissions do they get? So something to learn anyway as soon as you need to start managing that AWS account.

189
00:27:16.000 --> 00:27:34.000
And finally, how to create AMIs. There are different ways and different tools, but of course, it's something that you need to do because this is how you change, well, how you create the code in the first place that goes into every machine, but also how do you change it every time you want to do a new release.

190
00:27:34.000 --> 00:27:49.000
So I think that's a good summary of all the skills you need, and there's enough there. And if you could focus on those basics, I think after a success like this and with those skills, you've got a team that's really well set up to grow on AWS really well.

191
00:27:49.000 --> 00:28:01.000
So what's next? Once that's in place, what should the team thinking about in terms of, okay, now that we're there in AWS, where do we go from here? What are the improvements we can make? What new opportunities does this open up for us?

192
00:28:01.000 --> 00:28:10.000
Yeah, I think there will be in general some new challenges, but also new opportunities once the new system is running in the cloud.

193
00:28:10.000 --> 00:28:24.000
We mentioned already that there will be challenges in terms of observability because again, you have a lot of things happening in different systems. How do you make sense of if there is an issue, like where the issue will even be? Like where do you start looking?

194
00:28:24.000 --> 00:28:36.000
Where do you find evidence about that issue? Where do you collect more information to be able to troubleshoot and solve the issue? And all of that comes with the topic of observability and learning how to do that in the cloud and all the tooling.

195
00:28:36.000 --> 00:28:47.000
It's another skill that the team will need to start developing. And that probably requires a lot of code changes, making sure that all the information is logged correctly or metrics are being created, alarms are set.

196
00:28:47.000 --> 00:28:56.000
And then you also need to develop operational skills. How do you react to incidents? Who is going to be available? What are they going to do to address problems?

197
00:28:56.000 --> 00:29:05.000
Things that maybe you were doing to some extent with the monolithic system, but now they get to a different degree of complexity just because you have more moving parts.

198
00:29:05.000 --> 00:29:16.000
And then similar topics are testing. How do you do testing now? Because it's not just one system. How do you make sure that all the new different parts of the system work end to end?

199
00:29:16.000 --> 00:29:24.000
And with that, you can also start to think about building and deployment. Can we automate some of that stuff, even just the building part?

200
00:29:24.000 --> 00:29:34.000
But if you can even get to a point where you do full CI-CD, that's kind of even better goal to have. And again, this is a little bit of both of a challenge and an opportunity.

201
00:29:34.000 --> 00:29:47.000
But there are also other opportunities there that are very interesting because the goal that we hopefully achieved at this point is that we have an architecture that can scale and be more resilient to failure.

202
00:29:47.000 --> 00:30:00.000
There is not a single point of failure anymore. And if things fail, you can have systems in place that will automatically spin up new instances and the system can auto-ill up to some extent.

203
00:30:00.000 --> 00:30:10.000
The interesting thing is that at this point, as soon as your product grows, you have more customers, you need to develop new features, you can start to think about two options there.

204
00:30:10.000 --> 00:30:20.000
One, you can start to think about microservices so you can start to break down the existing application into individual services and then give different teams different responsibilities.

205
00:30:20.000 --> 00:30:32.000
But also you can approach that way of thinking in a more, I suppose, safe way, which is you don't necessarily have to do full monolith to microservice migration.

206
00:30:32.000 --> 00:30:40.000
You can think, okay, if we need to develop a new feature, how can we build that one feature in a way that is decoupled from the existing monolith?

207
00:30:40.000 --> 00:30:58.000
And that's something that you can do in AWS for instance, you can use ABA gateway and then Lambda as a backend and then tell the load balancer this particular feature, I don't know, slash search maybe, goes into the ABA gateway and then it's managed by Lambdas rather than being managed by the monolith application.

208
00:30:58.000 --> 00:31:09.000
So that gives you ways to experiment and get more comfortable with different tools that are available in AWS before you actually dramatically change the entire application.

209
00:31:09.000 --> 00:31:20.000
And similarly, you can experiment with SQS for instance, and Lambda to offload some of the usual things like, I don't know, sending emails, notifications, processing data in the background.

210
00:31:20.000 --> 00:31:28.000
So you can also leverage additional tools and do that as soon as you see an opportunity to do it with very small and tactical changes.

211
00:31:28.000 --> 00:31:32.000
This is great. Yeah, I think there's a number of opportunities.

212
00:31:32.000 --> 00:31:43.000
It really is a good appetizer for people who are thinking about taking this approach and I think the whole order of things and doing things simply in a managed way and then opening up these opportunities for later is good.

213
00:31:43.000 --> 00:31:51.000
You're not taking on too much too soon. If you want to learn more about the details of this particular strategy, there's a lot of detail in that really great InfoQ article.

214
00:31:51.000 --> 00:31:53.000
The link is in the show notes below.

215
00:31:53.000 --> 00:32:05.000
But if you want to know about all the different ways, Episode 18, How Do You Move to the Cloud, we're going to link to that and we'd really love your thoughts and other alternative ideas on migration strategies because there's a lot of them out there.

216
00:32:05.000 --> 00:32:08.000
So let us know what you think and we'll see you next time.

217
00:32:08.000 --> 00:32:26.000
Bye.
