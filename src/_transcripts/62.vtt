WEBVTT

1
00:00:00.000 --> 00:00:02.800
Have you been following reInvent 2022?

2
00:00:03.640 --> 00:00:06.540
If you're following this podcast, you are probably into AWS

3
00:00:06.680 --> 00:00:10.540
and aware of everything that was announced at AWS this year.

4
00:00:10.680 --> 00:00:14.540
So don't worry, today we're not going to give you another recap of reInvent.

5
00:00:14.680 --> 00:00:16.140
We're going to spare you all of that

6
00:00:16.280 --> 00:00:19.940
and just focus on three announcements that we are most excited about

7
00:00:20.080 --> 00:00:22.340
and we want to tell you exactly why we really care so much

8
00:00:22.480 --> 00:00:24.100
about this particular thing.

9
00:00:24.240 --> 00:00:27.140
So of course, this is going to be a very personal take.

10
00:00:27.280 --> 00:00:29.800
So we do look forward for disagreements

11
00:00:29.800 --> 00:00:32.300
and hearing what did you like the most instead.

12
00:00:32.440 --> 00:00:34.700
My name is Luciano and today I'm joined by Eoin

13
00:00:34.840 --> 00:00:38.760
and this is yet another episode of AWS Bites podcast.

14
00:00:46.340 --> 00:00:48.840
AWS Bites is sponsored by fourTheorem.

15
00:00:48.960 --> 00:00:51.760
fourTheorem is an AWS consulting partner offering training,

16
00:00:51.900 --> 00:00:54.600
cloud migration and modern application architecture.

17
00:00:54.740 --> 00:00:56.960
Find out more at fourtheorem.com.

18
00:00:57.100 --> 00:00:58.800
You'll find the link in the show notes.

19
00:00:58.800 --> 00:01:02.000
So, okay Eoin, let's maybe start with the first announcement.

20
00:01:02.120 --> 00:01:03.220
What did you like the most?

21
00:01:07.400 --> 00:01:10.500
I think the standout one for me was one that really heads in the right direction and I'm talking about a new addition that allows you to reduce

22
00:01:10.620 --> 00:01:13.000
the amount of glue code you have to write in your applications.

23
00:01:13.120 --> 00:01:14.700
And when you're building serverless applications

24
00:01:14.820 --> 00:01:17.660
and event-driven applications, this is really important

25
00:01:17.800 --> 00:01:20.000
because you can end up with a proliferation of Lambdas

26
00:01:20.120 --> 00:01:22.000
that don't do very much otherwise.

27
00:01:22.120 --> 00:01:24.220
So we're talking about EventBridge Pipes.

28
00:01:24.360 --> 00:01:26.600
Now we've talked a lot about EventBridge in previous episodes

29
00:01:26.720 --> 00:01:28.520
as part of our event series.

30
00:01:28.520 --> 00:01:31.180
EventBridge allows you to create event-driven applications

31
00:01:31.320 --> 00:01:34.180
by publishing messages to a broker or a boss

32
00:01:34.320 --> 00:01:37.060
and setting up pattern matching rules for consumers.

33
00:01:37.180 --> 00:01:40.080
EventBridge is also one of the fastest developing AWS services.

34
00:01:40.220 --> 00:01:44.020
So this announcement followed quickly from the release of EventBridge schedules,

35
00:01:44.160 --> 00:01:47.820
which is another really exciting pre-event announcement.

36
00:01:47.960 --> 00:01:51.720
What we like about EventBridge is that it's extremely easy to get started with it.

37
00:01:51.860 --> 00:01:53.760
The amount of setup is reasonably minimal,

38
00:01:53.880 --> 00:01:55.680
especially compared to other event services

39
00:01:55.820 --> 00:01:58.120
and you can send and receive events straight away.

40
00:01:58.120 --> 00:01:59.480
It also supports native events,

41
00:01:59.620 --> 00:02:03.780
so you can listen to other things happening in your AWS account very easily.

42
00:02:03.920 --> 00:02:06.920
So a new object was created in a bucket, you can listen to that.

43
00:02:07.040 --> 00:02:12.020
An ECS container has stopped, you can listen to that too and react to it.

44
00:02:12.140 --> 00:02:13.980
By default, by the way, you listen to an event,

45
00:02:14.120 --> 00:02:15.640
like one of these created by an EventBridge

46
00:02:15.780 --> 00:02:17.380
by creating an EventBridge rule.

47
00:02:17.520 --> 00:02:20.220
A rule is generally a pattern that allows you to capture

48
00:02:20.340 --> 00:02:22.180
all of the events that conform to that pattern

49
00:02:22.320 --> 00:02:25.820
and there's a content filtering syntax that allows you to do that.

50
00:02:25.940 --> 00:02:27.180
Then you can specify one or more targets

51
00:02:27.180 --> 00:02:29.180
that will receive that into an invocation,

52
00:02:29.300 --> 00:02:31.840
like a Lambda function, an SNS topic, a queue,

53
00:02:31.980 --> 00:02:35.580
a Kinesis data stream or a HTTP endpoint.

54
00:02:35.700 --> 00:02:38.300
So what are EventBridge Pipes and why are they so cool?

55
00:02:38.440 --> 00:02:40.340
Well, the idea with EventBridge rules

56
00:02:40.480 --> 00:02:43.140
is that you're dealing with PubSub type interactions.

57
00:02:43.280 --> 00:02:46.500
So you have one producer and multiple consumers.

58
00:02:46.640 --> 00:02:49.080
With EventBridge Pipes, they're point to point.

59
00:02:49.200 --> 00:02:50.900
So it allows you to take an event from one source

60
00:02:51.040 --> 00:02:53.780
and pass it to another with optional filtering,

61
00:02:53.900 --> 00:02:56.040
transformation and enrichment.

62
00:02:56.040 --> 00:02:59.100
So the goal here is to avoid you having to write more custom code.

63
00:02:59.240 --> 00:03:02.240
So for example, you would typically previously have to do

64
00:03:02.360 --> 00:03:04.760
a lot of Lambdas that take data from one source,

65
00:03:04.900 --> 00:03:06.700
put it into a queue.

66
00:03:06.840 --> 00:03:08.900
You don't have to do that anymore.

67
00:03:09.040 --> 00:03:10.800
So let's dive into it a little bit

68
00:03:10.940 --> 00:03:13.600
and talk about the various constructs in a pipe.

69
00:03:13.740 --> 00:03:16.540
Werner Vogels in the keynote compared this to Unix pipes

70
00:03:16.660 --> 00:03:20.760
and the Unix philosophy with standard edit and standard input

71
00:03:20.900 --> 00:03:23.300
and text as the interchange format between them.

72
00:03:23.300 --> 00:03:26.600
So it's very much along the lines of that same principle.

73
00:03:26.720 --> 00:03:28.260
So you have event sources,

74
00:03:28.400 --> 00:03:33.900
and most of the services supported by EventBridge rule

75
00:03:34.020 --> 00:03:35.720
targets are supported here.

76
00:03:35.860 --> 00:03:38.820
I think it was actually, they mentioned in the blog post

77
00:03:38.960 --> 00:03:42.220
or some of the Twitter commentary about this,

78
00:03:42.360 --> 00:03:44.620
that the event sources were very much inspired

79
00:03:44.760 --> 00:03:46.460
by Lambdas event source mappings.

80
00:03:46.600 --> 00:03:49.420
So you can take events from DynamoDB streams,

81
00:03:49.560 --> 00:03:50.860
from Kinesis data streams,

82
00:03:50.860 --> 00:03:56.520
SQS, Kafka, your own Kafka or AWS's managed Kafka,

83
00:03:56.660 --> 00:03:58.620
also Amazon MQ,

84
00:04:00.760 --> 00:04:03.160
also SQS,

85
00:04:03.280 --> 00:04:06.660
and you can then send them on to Step Functions,

86
00:04:06.780 --> 00:04:11.920
Kinesis data streams, Lambda, third party APIs, API gateway.

87
00:04:12.060 --> 00:04:15.160
And you can put a, just like with an EventBridge rule,

88
00:04:15.280 --> 00:04:16.660
you can put an input transformer.

89
00:04:16.780 --> 00:04:19.780
So you can transform the event before you send it on to the target.

90
00:04:19.780 --> 00:04:23.480
You can also filter events, which is really, really, really important.

91
00:04:24.620 --> 00:04:27.620
So you use the same syntax as you do with EventBridge rule patterns,

92
00:04:27.760 --> 00:04:30.260
and then you use that to essentially filter out

93
00:04:30.380 --> 00:04:32.760
what the subset of the events coming from that source

94
00:04:32.880 --> 00:04:34.880
that you want to forward to the target.

95
00:04:35.580 --> 00:04:36.580
So that's pretty much it.

96
00:04:36.720 --> 00:04:39.280
It's a bit like if you imagine if you're a Unix fan,

97
00:04:39.420 --> 00:04:44.360
you might cut a file, pipe it to grep to filter out some of the lines,

98
00:04:44.480 --> 00:04:48.880
and then send that on to the WC command to get a word to it.

99
00:04:48.880 --> 00:04:50.640
So it's a similar idea, right?

100
00:04:50.780 --> 00:04:53.680
You've got sources, filters, and targets.

101
00:04:55.220 --> 00:04:57.340
One of the things that you can do with EventBridge Pipes then

102
00:04:57.480 --> 00:04:59.120
is also enrichment.

103
00:04:59.240 --> 00:05:01.720
So this allows you to call out to other services or an API

104
00:05:01.840 --> 00:05:04.540
to get additional data and add it into the event.

105
00:05:04.980 --> 00:05:08.080
So you can call out your Lambda, Step Functions,

106
00:05:08.220 --> 00:05:11.080
or HTTP API or an API gateway.

107
00:05:11.920 --> 00:05:14.420
And then you can also transform the result of that too.

108
00:05:14.420 --> 00:05:18.360
The other thing I'd probably mention is that pipes also support DLQs.

109
00:05:18.500 --> 00:05:20.700
So again, this is like a fairly reliable way

110
00:05:20.820 --> 00:05:23.460
of taking data from one system, passing it on to another.

111
00:05:24.060 --> 00:05:26.220
So just to kind of summarize EventBridge rules,

112
00:05:26.360 --> 00:05:27.620
I think it's going to be very powerful.

113
00:05:27.760 --> 00:05:30.160
Hopefully, it'll allow a lot of people to delete Lambda functions

114
00:05:30.300 --> 00:05:31.820
they don't need anymore,

115
00:05:31.960 --> 00:05:34.960
and focus on using Lambda for kind of meaningful computation

116
00:05:35.100 --> 00:05:37.420
rather than just transporting data from A to B.

117
00:05:38.420 --> 00:05:40.020
The main difference is just to summarize that,

118
00:05:40.160 --> 00:05:41.220
it's point-to-point,

119
00:05:41.220 --> 00:05:45.480
with pipes, but it's pub-sub with EventBridge rules.

120
00:05:46.220 --> 00:05:49.080
With pipes, you don't have to write code to take an event from sources

121
00:05:49.220 --> 00:05:50.720
and put it into EventBridge.

122
00:05:51.720 --> 00:05:54.220
Like with EventBridge rules, you're writing a rule for an event

123
00:05:54.360 --> 00:05:55.680
that's already coming along to the bus.

124
00:05:55.820 --> 00:05:57.480
Somebody still has to put it onto the bus.

125
00:05:57.620 --> 00:06:01.360
With pipes, it's taking care of taking the data from the source for you.

126
00:06:01.480 --> 00:06:04.720
And the other difference between pipes and rules

127
00:06:04.860 --> 00:06:07.520
is that pipes have enrichment enrichment.

128
00:06:07.660 --> 00:06:10.560
So you can do that with a lot of different types of enrichment.

129
00:06:10.560 --> 00:06:12.640
Enrichment support as well.

130
00:06:12.760 --> 00:06:15.240
So what do you think? Is that your number one as well?

131
00:06:15.360 --> 00:06:18.060
I was a little bit tempted to go with that one.

132
00:06:18.200 --> 00:06:19.840
I was really excited about that one.

133
00:06:19.960 --> 00:06:21.560
But since you covered it already,

134
00:06:21.700 --> 00:06:23.640
I'm going to talk about the other one that I really liked,

135
00:06:23.760 --> 00:06:26.040
which is Step Function distributed map.

136
00:06:26.160 --> 00:06:30.840
And also Step Function is a topic that we have been talking about in the past.

137
00:06:30.960 --> 00:06:34.360
So what's so interesting about distributed map?

138
00:06:34.500 --> 00:06:38.660
So in a Step Function, you can already do a map step.

139
00:06:38.660 --> 00:06:43.920
And that map step, it's something useful

140
00:06:44.060 --> 00:06:47.100
when basically you want to take a bunch of different input.

141
00:06:47.220 --> 00:06:49.720
For instance, coming from the previous state, you have an array

142
00:06:49.860 --> 00:06:53.400
and you want to do something repeated n times

143
00:06:53.520 --> 00:06:55.600
for every item in that particular array.

144
00:06:55.720 --> 00:06:57.300
And that works really well.

145
00:06:57.420 --> 00:06:59.600
There are a lot of practical applications for that,

146
00:06:59.720 --> 00:07:01.320
but it's very limited.

147
00:07:01.460 --> 00:07:05.260
You cannot process more than 40 items concurrently.

148
00:07:05.400 --> 00:07:08.000
So where distributed map is trying to improve things

149
00:07:08.000 --> 00:07:10.480
is to try to raise that limit much, much more

150
00:07:10.600 --> 00:07:13.080
and give you a much higher throughput

151
00:07:13.200 --> 00:07:17.540
if you really have to process a large number of things concurrently.

152
00:07:17.680 --> 00:07:20.780
And it also takes a slightly different approach.

153
00:07:20.900 --> 00:07:22.080
I'm going to try to describe how.

154
00:07:22.200 --> 00:07:27.380
But the first thing worth mentioning is that where the limit is 40 for regular map,

155
00:07:27.500 --> 00:07:31.200
with distributed map, the concurrency limit is 10,000 items.

156
00:07:31.340 --> 00:07:33.000
And it's even more interesting than that

157
00:07:33.140 --> 00:07:36.940
because you can process up to 100 million items in total.

158
00:07:36.940 --> 00:07:41.940
So a full distributed map can have a maximum number of 100 million items

159
00:07:42.060 --> 00:07:44.300
and they will be processed 10,000 at a time.

160
00:07:44.440 --> 00:07:48.260
So you can imagine what's the difference in scale already.

161
00:07:48.400 --> 00:07:51.140
Now, how does it work in practice?

162
00:07:51.260 --> 00:07:54.940
Because the model is slightly different from what you would use with a regular map.

163
00:07:55.060 --> 00:07:58.760
So each map step is basically running a child Step Function

164
00:07:58.900 --> 00:08:01.600
and that Step Function has its own execution history.

165
00:08:01.740 --> 00:08:05.140
So it's kind of, in a way, an orchestrator of children Step Functions

166
00:08:05.140 --> 00:08:08.140
every time you're running that distributed map step.

167
00:08:08.280 --> 00:08:10.920
The input is taken from S3.

168
00:08:11.040 --> 00:08:12.420
This is another big difference.

169
00:08:12.540 --> 00:08:16.220
Like with regular map step, you generally can take a...

170
00:08:16.340 --> 00:08:18.540
or either the entire state of the function

171
00:08:18.680 --> 00:08:22.540
or a portion of that state if you are mapping with the JSON syntax.

172
00:08:22.680 --> 00:08:23.920
And basically you are just saying,

173
00:08:24.040 --> 00:08:28.640
take this array and repeat some other steps for every item in that array.

174
00:08:28.780 --> 00:08:32.140
Instead, with distributed map, you need to take data from S3

175
00:08:32.140 --> 00:08:36.040
and that needs to be some kind of structured file format.

176
00:08:36.180 --> 00:08:42.180
It can be a JSON, a CSV, or you can even use an API call like list objects.

177
00:08:42.300 --> 00:08:47.100
So that basically is the way that you can load a lot more data into Step Functions,

178
00:08:47.240 --> 00:08:51.700
which I think is another limitation that we have with the traditional map step,

179
00:08:51.840 --> 00:08:55.640
where you are only limited to the state, which is not a lot of data.

180
00:08:55.780 --> 00:08:59.240
With distributed map, you can actually process big data files

181
00:08:59.240 --> 00:09:02.900
and repeat that operation with very high throughput and concurrency.

182
00:09:03.040 --> 00:09:05.240
So what are some of the use cases?

183
00:09:05.360 --> 00:09:06.740
Definitely batch processing.

184
00:09:06.860 --> 00:09:09.560
So for instance, if you have a lot of files in S3,

185
00:09:09.700 --> 00:09:14.140
maybe representing some valuable piece of business information.

186
00:09:14.260 --> 00:09:17.540
I don't know, maybe something around analytics for your e-commerce.

187
00:09:17.660 --> 00:09:20.940
And maybe you can have for every product in your e-commerce,

188
00:09:21.060 --> 00:09:23.740
you might have a JSON file that tells you exactly

189
00:09:23.860 --> 00:09:26.560
all the IP addresses that look at that product.

190
00:09:26.560 --> 00:09:30.100
And you might want to do some analytics to try to figure out in which regions

191
00:09:30.220 --> 00:09:33.500
every single one of your products can be relevant for people.

192
00:09:33.620 --> 00:09:35.000
So you can do some marketing.

193
00:09:35.120 --> 00:09:37.360
That could be a use case where it could be the Step Function

194
00:09:37.500 --> 00:09:39.520
that takes all your files in parallel.

195
00:09:39.660 --> 00:09:44.000
And then every sub Step Function will be crunching all the data

196
00:09:44.120 --> 00:09:46.900
and give you some analytics about that.

197
00:09:47.020 --> 00:09:48.800
This is just to give you a random example,

198
00:09:48.920 --> 00:09:51.920
but you can come up with other examples like, I don't know, financial modeling.

199
00:09:52.060 --> 00:09:54.920
So you might be running some models over your data set

200
00:09:54.920 --> 00:09:57.880
and try to come up with some results about maybe, I don't know,

201
00:09:58.020 --> 00:10:00.580
calculating a risk score for specific deals

202
00:10:00.720 --> 00:10:02.960
that your organization is working on.

203
00:10:03.080 --> 00:10:06.580
Or another use case, which is apparently our favorite one,

204
00:10:06.720 --> 00:10:09.320
because we end up mentioning it in almost every episode,

205
00:10:09.460 --> 00:10:13.060
transforming images, maybe creating thumbnails of images

206
00:10:13.180 --> 00:10:14.580
that you have somewhere in S3,

207
00:10:14.720 --> 00:10:18.120
or maybe even just extrapolating information from those images,

208
00:10:18.260 --> 00:10:19.980
connecting with other services,

209
00:10:20.120 --> 00:10:23.260
and try maybe to do some computer vision analysis

210
00:10:23.260 --> 00:10:27.240
and then figure out, okay, what is a description for every single image?

211
00:10:27.360 --> 00:10:30.760
So you can imagine basically all these kind of orchestration workflows

212
00:10:30.900 --> 00:10:33.200
where you're starting with a lot of data from S3

213
00:10:33.340 --> 00:10:37.300
and you just want to map basically S3 files to something else.

214
00:10:37.440 --> 00:10:42.740
You can create a Step Function and use this distributed map functionality now.

215
00:10:42.860 --> 00:10:44.740
Now, there are of course also some limitations.

216
00:10:44.860 --> 00:10:48.360
So although I am very excited, I am also a little bit disappointed

217
00:10:48.500 --> 00:10:50.200
that they didn't go just a step further,

218
00:10:50.340 --> 00:10:52.560
which would have been even more amazing.

219
00:10:52.560 --> 00:10:57.200
So maybe this is my wish list for reInvent 2023 already.

220
00:10:57.320 --> 00:10:59.320
But basically what I was a bit disappointed about

221
00:10:59.460 --> 00:11:03.700
is that you can only deal with a flat list of inputs.

222
00:11:03.820 --> 00:11:06.960
So basically that means that you run,

223
00:11:07.100 --> 00:11:08.520
you can imagine the mental models,

224
00:11:08.660 --> 00:11:10.520
like there is no correlation between inputs.

225
00:11:10.660 --> 00:11:12.760
You just run everything concurrently.

226
00:11:12.900 --> 00:11:14.200
Of course, there is a concurrency limit,

227
00:11:14.320 --> 00:11:18.100
but you cannot create rules such as like a dependency graph

228
00:11:18.220 --> 00:11:21.120
where you could say, I need to run this file first,

229
00:11:21.120 --> 00:11:24.660
then I can use the output of this other file to run something else

230
00:11:24.780 --> 00:11:30.460
and create a more kind of complex orchestrated way of running the workflow,

231
00:11:30.580 --> 00:11:32.580
which can be very convenient in some cases.

232
00:11:32.720 --> 00:11:34.760
Again, I'm thinking risk modeling,

233
00:11:34.880 --> 00:11:38.880
where maybe you have data that needs to flow from one deal to another

234
00:11:39.020 --> 00:11:41.460
for that compute issue to make sense.

235
00:11:41.580 --> 00:11:46.480
And another thing is that you cannot dynamically add items to the execution run,

236
00:11:46.620 --> 00:11:48.420
which basically means that even if you wanted to have

237
00:11:48.420 --> 00:11:51.080
your own custom orchestration logic from the outside

238
00:11:51.220 --> 00:11:54.520
and push things into this pool of things to process,

239
00:11:54.640 --> 00:11:56.540
that's not really something that is supported today.

240
00:11:56.680 --> 00:11:58.520
You just need to define everything in advance

241
00:11:58.640 --> 00:12:01.140
and the Step Function is just going to take that input,

242
00:12:01.280 --> 00:12:05.280
create this kind of execution and run it,

243
00:12:05.420 --> 00:12:07.720
and then eventually you'll get your results.

244
00:12:07.840 --> 00:12:09.720
And also cost might be an issue

245
00:12:09.840 --> 00:12:13.280
because you are basically doing a huge amount of stage transitions,

246
00:12:13.420 --> 00:12:15.220
step transition in the Step Function.

247
00:12:15.220 --> 00:12:19.760
So you need to be careful and try to come up with some numbers

248
00:12:19.900 --> 00:12:22.260
to make sure that the cost is going to be reasonable for you,

249
00:12:22.400 --> 00:12:24.100
depending on the type of computation you're going to do

250
00:12:24.220 --> 00:12:26.820
and the number of files that you're going to process.

251
00:12:26.960 --> 00:12:30.620
So that's everything I have about distributed map.

252
00:12:30.760 --> 00:12:34.920
I don't know if you want to add anything that I might have missed.

253
00:12:38.320 --> 00:12:41.200
It's a bit like the first one in that it's also something that could potentially allow you to remove a huge amount of glue code

254
00:12:41.320 --> 00:12:42.320
and orchestration logic.

255
00:12:42.320 --> 00:12:45.160
So I think it's really, really a great step in the right direction.

256
00:12:45.280 --> 00:12:46.980
And I think those wish list items you mentioned

257
00:12:47.120 --> 00:12:49.520
would just really make it fantastic altogether.

258
00:12:49.660 --> 00:12:51.460
The price issue is definitely a concern

259
00:12:51.580 --> 00:12:54.380
because it's a bit like the pricing model for Step Functions

260
00:12:54.520 --> 00:12:56.880
wasn't designed for this level of scale.

261
00:12:57.020 --> 00:12:59.580
But you're still paying like two and a half cents

262
00:12:59.720 --> 00:13:02.780
for thousands state transitions in Step Functions.

263
00:13:02.920 --> 00:13:05.660
So you can imagine if you've got a million state transitions,

264
00:13:05.780 --> 00:13:08.580
it's now quite possible to reach that. That's $25.

265
00:13:08.720 --> 00:13:10.880
So if you're running that multiple times a day,

266
00:13:10.880 --> 00:13:12.340
it adds up over the month.

267
00:13:12.480 --> 00:13:14.520
So you have to work that out.

268
00:13:14.640 --> 00:13:16.640
See our previous episode on pricing.

269
00:13:16.780 --> 00:13:17.780
Absolutely.

270
00:13:17.920 --> 00:13:20.220
Okay, well, maybe we could talk about number three

271
00:13:20.340 --> 00:13:21.740
in our top three lists then.

272
00:13:21.880 --> 00:13:24.840
And it's pretty hard to choose

273
00:13:24.980 --> 00:13:27.720
because there were some pretty good announcements elsewhere.

274
00:13:27.840 --> 00:13:30.220
Code Catalyst is another one that's worth a mention.

275
00:13:30.340 --> 00:13:33.420
But we're going to talk about Application Composer.

276
00:13:33.540 --> 00:13:37.140
So Application Composer is a completely new tool in the AWS console

277
00:13:37.280 --> 00:13:39.740
for visually designing new applications.

278
00:13:39.740 --> 00:13:42.300
Or visualizing existing applications.

279
00:13:42.440 --> 00:13:43.800
So this is in preview right now.

280
00:13:43.940 --> 00:13:45.300
So it's not generally available,

281
00:13:45.440 --> 00:13:46.780
but you can try it out and give it a go.

282
00:13:46.900 --> 00:13:49.500
And I've done that and I've found it to be much,

283
00:13:49.640 --> 00:13:51.840
much better than previous attempts at this kind of thing,

284
00:13:51.980 --> 00:13:55.180
like the CloudFormation designer.

285
00:13:55.300 --> 00:13:59.680
Now, it's really focused on serverless applications right now.

286
00:13:59.800 --> 00:14:02.240
But the way it works is that you can build an application

287
00:14:02.380 --> 00:14:04.680
from scratch using a drag and drop interface.

288
00:14:04.800 --> 00:14:07.300
Visually, it looks good. It makes sense.

289
00:14:07.440 --> 00:14:09.000
It's reasonably simple to use.

290
00:14:09.000 --> 00:14:12.460
And it will generate the CloudFormation template for you

291
00:14:12.600 --> 00:14:15.460
and also generate things like IAM policies you will need.

292
00:14:15.600 --> 00:14:20.960
Now, it doesn't support all of the CloudFormation resources.

293
00:14:21.100 --> 00:14:23.960
So there's a set of about 12 or 15 services.

294
00:14:24.100 --> 00:14:27.660
So classic things you'll find in a basic serverless application,

295
00:14:27.800 --> 00:14:32.140
like an API gateway, Cognito user pools, tables in DynamoDB,

296
00:14:32.260 --> 00:14:37.760
EventBridge rules, Kinesis, Lambda, S3, SNS, SQS and Step Functions.

297
00:14:37.760 --> 00:14:43.420
And I would love if it supported the many hundreds of resources,

298
00:14:43.560 --> 00:14:45.760
there are thousands even, that you can get in CloudFormation

299
00:14:45.900 --> 00:14:48.860
and maybe we'll get there. But it's a pretty good start.

300
00:14:49.000 --> 00:14:50.820
So one of the things it can do then as well,

301
00:14:50.960 --> 00:14:53.820
if you're using Chrome or Edge browsers,

302
00:14:53.960 --> 00:14:56.600
is it can actually synchronize with your code on the file system.

303
00:14:56.720 --> 00:14:59.720
So if you're taking the approach of visualizing an existing application,

304
00:14:59.860 --> 00:15:02.000
you can point it to the directory, pick your template,

305
00:15:02.120 --> 00:15:03.520
and it will visualize that for you.

306
00:15:03.660 --> 00:15:06.520
And if you make changes, it will sync them back to the file system.

307
00:15:06.520 --> 00:15:08.580
So that's using File System API in the browser.

308
00:15:09.720 --> 00:15:12.180
It doesn't work in Firefox because Firefox doesn't support that.

309
00:15:12.320 --> 00:15:14.860
And in that case, you just have to load your template manually.

310
00:15:16.280 --> 00:15:17.620
I did try out an example.

311
00:15:17.760 --> 00:15:20.480
So I was building a recent service application.

312
00:15:20.620 --> 00:15:21.780
It had two features.

313
00:15:21.920 --> 00:15:25.380
I was using AWS SAM and this supports AWS SAM, so that was a good fit.

314
00:15:26.980 --> 00:15:29.620
My application was using nested stacks.

315
00:15:30.380 --> 00:15:33.280
And it was also using Step Functions

316
00:15:33.280 --> 00:15:37.280
where the state machine definition was loaded separately from a JSON file.

317
00:15:38.280 --> 00:15:41.280
In that case, it doesn't support nested stacks.

318
00:15:41.420 --> 00:15:42.620
I mean, it could load the file,

319
00:15:42.740 --> 00:15:44.280
but it just showed me that there were a number of stacks.

320
00:15:44.420 --> 00:15:46.740
It couldn't show me the resources within the nested stacks.

321
00:15:46.880 --> 00:15:48.440
So I thought, I said, okay, that's fine.

322
00:15:48.580 --> 00:15:50.440
So I'll just load the individual stack template.

323
00:15:50.580 --> 00:15:53.520
And I did that and I was able to load up all my Lambda functions.

324
00:15:53.640 --> 00:15:55.620
And it was able to recognize that there was a state machine,

325
00:15:55.740 --> 00:15:57.420
but it didn't parse the state machine definition.

326
00:15:57.540 --> 00:16:00.940
So it wasn't able to draw the lines between my state machine definition

327
00:16:00.940 --> 00:16:05.600
and the tasks that were invoked in the Step Function stages.

328
00:16:06.740 --> 00:16:09.180
I did try building from scratch and creating a Step Function.

329
00:16:09.300 --> 00:16:12.900
And in that case, you can put the definition in,

330
00:16:13.040 --> 00:16:16.100
in line, basically in state machine resource,

331
00:16:16.240 --> 00:16:17.740
and that seems to work fine.

332
00:16:18.380 --> 00:16:19.940
But I was thinking as I was doing that,

333
00:16:20.080 --> 00:16:21.940
wouldn't be nice if it's seamlessly integrated

334
00:16:22.080 --> 00:16:24.740
with the Step Functions Workflow Studio,

335
00:16:24.880 --> 00:16:29.380
so that you can go directly from designing your state machine

336
00:16:29.380 --> 00:16:34.460
and your CloudFormation resources and your serverless SAM resources

337
00:16:34.580 --> 00:16:37.160
directly into the actual state machine design.

338
00:16:37.280 --> 00:16:39.480
And if those two tools blended well together,

339
00:16:39.620 --> 00:16:41.220
that could be really, really powerful.

340
00:16:41.920 --> 00:16:42.920
I think this is really good thing,

341
00:16:43.060 --> 00:16:44.860
because one of the things about serverless applications

342
00:16:44.980 --> 00:16:47.580
is that they can be hard to kind of understand

343
00:16:47.720 --> 00:16:50.020
how everything fits together, because you've got lots of resources

344
00:16:50.160 --> 00:16:51.760
that are sometimes loosely coupled.

345
00:16:51.880 --> 00:16:53.360
This is a good step in the right direction.

346
00:16:53.480 --> 00:16:55.020
And I think it's going to be really useful,

347
00:16:55.160 --> 00:16:57.520
very good for people starting off, I would say as well,

348
00:16:57.660 --> 00:16:58.660
with serverless development,

349
00:16:58.660 --> 00:17:01.240
because when you're just looking at lines and lines of YAML,

350
00:17:01.360 --> 00:17:02.360
it can be a bit of a headache,

351
00:17:02.500 --> 00:17:04.840
but when you can visualize it nicely and talk through it,

352
00:17:04.960 --> 00:17:08.460
it's like having a live kind of physical architecture diagram

353
00:17:08.600 --> 00:17:09.600
for your solution.

354
00:17:10.240 --> 00:17:11.240
Yeah, totally agree.

355
00:17:11.360 --> 00:17:13.200
And I think this is one of the pain points

356
00:17:13.340 --> 00:17:17.060
that we hear the most about when talking with people in the industry

357
00:17:17.200 --> 00:17:19.760
or our customers, that it's always very hard to keep

358
00:17:19.900 --> 00:17:21.600
in sync your architecture diagrams

359
00:17:21.740 --> 00:17:24.340
with your actual architecture running on AWS.

360
00:17:24.740 --> 00:17:27.140
So this might be a step forward in that direction.

361
00:17:27.140 --> 00:17:29.020
It could be a tool that kind of gives you

362
00:17:29.140 --> 00:17:32.080
that automatic visualization of your actual stacks,

363
00:17:32.220 --> 00:17:35.420
rather than trying to keep two different things in sync.

364
00:17:35.540 --> 00:17:38.240
And you know that that's really, really hard to do it well.

365
00:17:38.840 --> 00:17:41.980
So really happy to see this being announced,

366
00:17:42.120 --> 00:17:45.120
even if it's not perfect, I think it's a great one to mention,

367
00:17:45.240 --> 00:17:46.640
and it's a step forward for sure.

368
00:17:47.780 --> 00:17:50.080
So just to try to wrap things up here,

369
00:17:50.220 --> 00:17:52.880
I want to mention that we will have the links

370
00:17:53.020 --> 00:17:56.180
for the individual announcements, EventBridge Pipes.

371
00:17:56.180 --> 00:17:57.640
Step Functions Distributed Map,

372
00:17:57.780 --> 00:17:59.800
and application composer in the show notes.

373
00:17:59.940 --> 00:18:02.640
But also there are three things, three additional things

374
00:18:02.780 --> 00:18:05.300
that we were kind of discussing,

375
00:18:05.440 --> 00:18:06.900
and they were in our shortlist as well.

376
00:18:07.040 --> 00:18:09.440
So maybe just worth a quick mention.

377
00:18:09.580 --> 00:18:11.940
So we have SNS payload message filtering,

378
00:18:12.080 --> 00:18:15.580
verified access, CloudWatch cross-account observability.

379
00:18:15.700 --> 00:18:18.080
We are not going to spend more time on those,

380
00:18:18.200 --> 00:18:20.340
but you can find the links in the show notes as well,

381
00:18:20.480 --> 00:18:22.980
if you want to deep dive on these other announcements.

382
00:18:23.100 --> 00:18:25.900
We will also have another link, which is our unofficial blog post

383
00:18:25.900 --> 00:18:28.800
which highlights all the top announcements

384
00:18:28.940 --> 00:18:32.240
of AWS reInvent 2022 directly from AWS.

385
00:18:32.360 --> 00:18:35.240
So that's another great source if you have missed something

386
00:18:35.360 --> 00:18:37.800
and you just want to see exactly what was announced

387
00:18:37.940 --> 00:18:40.240
and deep dive on what's more interesting for you.

388
00:18:40.360 --> 00:18:43.260
And with that, I think we are at the end of this episode.

389
00:18:43.400 --> 00:18:44.840
We are really curious to hear

390
00:18:44.960 --> 00:18:47.360
what are your top three favorite announcements.

391
00:18:47.500 --> 00:18:50.040
I realize that as probably our background,

392
00:18:50.160 --> 00:18:53.640
we have been mostly focused around the area of application development,

393
00:18:53.640 --> 00:18:56.080
but probably in the audience we have people that are more focused

394
00:18:56.220 --> 00:18:58.820
on networking, ML, data analytics,

395
00:18:58.940 --> 00:19:01.320
and there were a lot of announcements in those areas.

396
00:19:01.440 --> 00:19:03.480
So I'm really curious to see what you liked the most

397
00:19:03.620 --> 00:19:07.320
and if you were excited about the new things that were announced.

398
00:19:07.440 --> 00:19:10.320
So definitely leave us a comment, chat to us on Twitter,

399
00:19:10.440 --> 00:19:12.120
and let's be in touch.

400
00:19:12.120 --> 00:19:31.600
Until then, see you in the next episode. Bye.
